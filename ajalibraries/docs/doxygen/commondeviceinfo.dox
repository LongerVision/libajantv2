/**
	@page	ntv2devops		NTV2 Device Hardware Operation

	On this page:
	-	\ref ntv2devops-intro
	-	\ref devicesignalinputsoutputs
		-	\ref commonelectricalchars
		-	\ref hardwarecharacteristics
	-	\ref videooperation
		-	\ref vidop-fs
		-	\ref independentmode
		-	\ref vidop-fbaccess
		-	\ref deviceclockingandsync
		-	\ref fieldframeinterrupts
		-	\ref vidop-fbconflict
		-	\ref vidop-csc
		-	\ref vidop-lut
		-	\ref vidop-mixerkeyer
	-	\ref audiooperation
		-	\ref audiocapture
		-	\ref audioplayout
		-	\ref audiosamplecount
		-	\ref audiohidden
		-	\ref audioclobber
		-	\ref audiomixer
	-	\ref devicefirmware
		-	\ref dev-firmware-loading
		-	\ref dev-firmware-flash
		-	\ref dev-firmware-vers
		-	\ref dev-firmware-features



	<hr size="50px">
	@section	ntv2devops-intro	Introduction

	In simplest terms, NTV2 devices are essentially…
	-	a big chunk of SDRAM memory for buffering video frames and audio samples, which is tied to…
	-	an FPGA that determines what gets written or read to/from that memory (and where), plus…
	-	one or more video and/or audio signal inputs and/or outputs, and…
	-	a high-speed PCIe interface to a host computer, for rapidly reading or writing 32-bit registers,
		and transferring bulk data via DMA to/from the host.

	@image	html	hwref-fig0-blockdiagram.png

	In addition, the FPGA firmware implements “widgets“ that can process video data in a particular way
	(e.g., color correction, muxing/demuxing, etc.).

	All AJA NTV2 hardware devices minimally support the following:
	-	Capture or play to/from the host computer video and audio through at least one video connector.
	-	SD video formats: 525i 59.94fps, and 625i 50fps
	-	HD video formats: 720p 50/59.94/60, 1080i 50/59.94/60, 1080psf 23.98/24 and 1080p 23.98/24/29.97/30
	-	8-bit YCbCr or 10-bit YCbCr frame buffer formats.

	Beyond these common characteristics, AJA devices fan out into a diverse array of capabilities to suit many different applications.
	To determine the features of an AJA device, use the <b>Device Features API</b> in the \ref ajantv2 .

	Most devices can capture and play video, but some may only capture, while others may only playout.
	-	To determine if a device can capture video, call ::NTV2DeviceCanDoCapture.
	-	To determine if a device can play video, call ::NTV2DeviceCanDoPlayback.



	<hr size="50px">
	@section	devicesignalinputsoutputs		Signal Inputs & Outputs

	@par	Breakout Boxes and Cables

	On some devices, certain signal connectors are accessible only through a breakout cable or breakout box.
	-	To determine if the device can support a breakout box, call ::NTV2DeviceCanDoBreakoutBox.
	-	To determine if a breakout box is connected, call CNTV2Card::GetBreakoutHardware.

	@par	SDI Connectors

	Most AJA devices have at least one SDI connector.
	-	To determine the number of SDI input jacks the device has, call ::NTV2DeviceGetNumVideoInputs.
	-	To determine the number of SDI output jacks the device has, call ::NTV2DeviceGetNumVideoOutputs.

	Some SDI connectors are permanently configured as inputs, others as outputs, but on some devices, they’re software-configurable.
	This means your application can instruct the device to reconfigure one of its SDI jacks from an input to an output (or vice-versa).
	-	To determine if a device has software-configurable SDI connectors, call ::NTV2DeviceHasBiDirectionalSDI.
	-	If a device has bi-directional SDI connectors, the ::NTV2DeviceGetNumVideoInputs and ::NTV2DeviceGetNumVideoOutputs will reflect
		the maximum possible number of inputs and outputs.
		-	For example, the \ref io4kquad has four bi-directional SDI jacks plus an additional monitor (output-only) jack,
			so for that device, ::NTV2DeviceGetNumVideoInputs returns 4 and ::NTV2DeviceGetNumVideoOutputs returns 5.
	-	To determine if an SDI connector is currently configured to transmit, call CNTV2Card::GetSDITransmitEnable.
	-	To change an SDI connector’s function to receive or transmit, call CNTV2Card::SetSDITransmitEnable.

		@note	When changing an SDI connector from ‘transmit’ to ‘receive’, it can take a while for the device input
				to lock to the incoming signal (when there is one). It’s best to delay several frames (or more) before
				calling CNTV2Card::GetInputVideoFormat or CNTV2Card::GetSDIInputVideoFormat to obtain an accurate
				determination of what signal is present.

	All SDI connectors on NTV2 devices can receive or transmit 1.5 Gbps signals, and almost all will handle 3Gbps.
	-	To determine if its SDI spigots can handle 6Gbps or 12Gbps, call ::NTV2DeviceCanDo12GSDI.

	To determine if there’s a signal present at an SDI input connector, and if so, what format it is…
	-	Call CNTV2Card::GetInputVideoFormat, specifying an ::NTV2InputSource …
		-	Use ::NTV2_INPUTSOURCE_SDI1, ::NTV2_INPUTSOURCE_SDI2, etc.
		-	Or use the result of ::GetNTV2InputSourceForIndex.
	-	Or call CNTV2Card::GetSDIInputVideoFormat, specifying the SDI input connector as an ::NTV2Channel value.
	-	Whichever function you use, if you are expecting <b>psf</b> video, pass ‘true’ for the ‘<i>inIsProgressive</i>’ parameter.

	@par	HDMI Connectors

	Many AJA devices have HDMI connectors, some for capture, most for playout.
	-	To determine the number of HDMI inputs the device has, call ::NTV2DeviceGetNumHDMIVideoInputs.
	-	To determine the number of HDMI outputs the device has, call ::NTV2DeviceGetNumHDMIVideoOutputs.
	-	HDMI capabilities depend on the physical HDMI hardware used on the device and the supporting firmware.
		To determine which HDMI hardware is present on the device, call ::NTV2DeviceGetHDMIVersion.
		(Note that this doesn’t return an HDMI protocol version — it’s strictly an unsigned integer that indicates
		which “generation” of HDMI hardware was used on the device.
	-	HDMI hardware capabilities chart:

	@image	html	hdmichart.png

	To determine if there’s a signal present at an HDMI input connector, and if so, what format it is…
	-	Call CNTV2Card::GetInputVideoFormat, specifying an ::NTV2InputSource …
		-	Use ::NTV2_INPUTSOURCE_HDMI1, ::NTV2_INPUTSOURCE_HDMI2, etc.
		-	Or use the result of ::GetNTV2InputSourceForIndex — specify ::NTV2_INPUTSOURCES_HDMI for the ‘<i>inKinds</i>’ parameter.
		-	If you are expecting <b>psf</b> video, pass ‘true’ for the ‘<i>inIsProgressive</i>’ parameter.
	-	Or call CNTV2Card::GetHDMIInputVideoFormat, specifying the HDMI input connector as an ::NTV2Channel value.
	-	If a DVI monitor is connected to the HDMI output connector, no audio will be transmitted (since DVI doesnʼt support audio).
	-	If an HDMI monitor is connected to the HDMI output connector, and it appears to be “DVI”, this is often caused by the firmware
		not correctly reading the monitor configuration (EDID), so it falls back to DVI.  To force the HDMI output to HDMI:
		-	Call CNTV2Card::SetHDMIOutProtocol and specify <tt>NTV2_HDMIProtocolHDMI</tt>, and…
		-	Call CNTV2Card::SetHDMIOutForceConfig and specify <tt>true</tt>.

	@par	Analog Video Connectors

	Some older AJA devices have analog video connectors (remember the old RCA component-level jacks?).
	-	To determine the number of analog video inputs the device has, call ::NTV2DeviceGetNumAnalogVideoInputs.
	-	To determine the number of analog video outputs the device has, call ::NTV2DeviceGetNumAnalogVideoOutputs.

	To determine if there’s a signal present at an analog video input connector, and if so, what format it is…
	-	Call CNTV2Card::GetInputVideoFormat, specifying an ::NTV2InputSource …
		-	Use ::NTV2_INPUTSOURCE_ANALOG1.
		-	Or use the result of ::GetNTV2InputSourceForIndex — specify ::NTV2_INPUTSOURCES_ANALOG for the ‘<i>inKinds</i>’ parameter.
		-	If you are expecting <b>psf</b> video, pass ‘true’ for the ‘<i>inIsProgressive</i>’ parameter.
	-	Or call CNTV2Card::GetAnalogInputVideoFormat.

	@par	Audio Connectors

	Some AJA devices have separate connectors for audio input and/or output, even analog audio on some older devices.
	-	To determine if the device is capable of analog audio input or output, call ::NTV2DeviceCanDoAnalogAudio.
	-	To determine how many AES inputs and/or outputs a device has, call ::NTV2DeviceGetNumAESAudioInputChannels
		and/or ::NTV2DeviceGetNumAESAudioOutputChannels, respectively.
	-	To determine how many analog audio inputs and/or outputs a device has, call ::NTV2DeviceGetNumAnalogAudioInputChannels
		and/or ::NTV2DeviceGetNumAnalogAudioOutputChannels, respectively.

	@par	Reference and LTC Connectors

	Most AJA devices have a single BNC connector that can be used for reference input or for analog LTC input.
	On other devices, there are separate reference and LTC input connectors. Some devices have output connectors
	for LTC or Reference.
	-	To determine the number of reference video inputs, call ::NTV2DeviceGetNumReferenceVideoInputs.
	-	To determine the number of LTC inputs, call ::NTV2DeviceGetNumLTCInputs.
	-	To determine if the device can be configured to receive LTC on its reference input port, call ::NTV2DeviceCanDoLTCInOnRefPort.
		If the device can receive LTC from its Reference input…
		-	Call CNTV2Card::GetLTCInputEnable to determine if the input is configured to receive analog LTC from its Reference port.
		-	Call CNTV2Card::SetLTCInputEnable to configure the Reference/LTC input:
			pass <b>true</b> to have it receive analog LTC;
			pass <b>false</b> to have it receive Reference.
	-	To determine if a valid LTC signal is present at the connector, call CNTV2Card::GetLTCInputPresent.
	-	To determine the number of LTC outputs, call ::NTV2DeviceGetNumLTCOutputs.

	@par	Serial Ports (RS-422)

	Most AJA devices have a single RS-422 connector that can be used to control tape deck transports and for other purposes.
	-	To determine the number of serial ports on a device, call ::NTV2DeviceGetNumSerialPorts.
	-	To determine if the serial port is programmable (for baud rate, parity, etc.), call ::NTV2DeviceCanDoProgrammableRS422.
		-	To determine the current baud rate, call CNTV2Card::GetRS422BaudRate. To change the baud rate, call CNTV2Card::SetRS422BaudRate.
		-	To determine the current parity configuration, call CNTV2Card::GetRS422Parity. To change the baud rate, call CNTV2Card::SetRS422Parity.

	@image	html	rs422pinout400.png


	@subsection	commonelectricalchars		Common Electrical Characteristics

	Unless otherwise noted, physical and electrical characteristics of inputs and outputs — SDI, HDMI, analog video, analog audio, reference,
	LTC, etc. — are generally identical across all AJA devices.

	<b>SDI Input(s)</b>
	-	AC-coupled input terminated with 75Ω to ground
	-	SMPTE 292 compliant — 800mV peak-to-peak ±10%

	<b>SDI Output(s)</b>
	-	AC-coupled output terminated with 75Ω to ground
	-	<b>Output Level:</b>  800mV peak-to-peak ±10%, terminated into 75Ω

	<b>Video Reference Input(s)</b>
	-	Analog video reference, NTSC, PAL, or tri-level sync
	-	Input terminated by 75Ω to ground
	-	<b>Input level:</b>  0.5 Volts peak-to-peak to 2.0 Volts peak-to-peak
	-	Tri-level sync:
		-	Analog Color Black (700 mV sync nominal, plus burst)
		-	Composite Sync (700 mV sync nominal, plus burst and video)
		-	HD Tri-Level Sync (±700 mV sync)

	<b>Analog LTC Input(s)</b>
	-	Designed to work with inverted or non-inverted inputs
	-	Input impedence 75Ω, coax or other single-ended connection is recommended
	-	There is no differential termination on these inputs, so a balanced connection may not be reliable
	-	Designed to meet SMPTE spec, 0.5V to 4.5Vp-p

	<b>HDMI Input, Output</b>
	-	Connector: Type-A (unless otherwise noted)

	<b>AES Input(s)</b>
	-	DC-coupled input terminated with 75Ω to ground
	-	<b>Minimum input level:</b>  100 mV peak-to-peak

	<b>AES Output(s)</b>
	-	AC-coupled output terminated with 75Ω to ground
	-	<b>Output level:</b>  1.55 Volts peak-to-peak, +/- 10%, terminated into 75Ω

	<b>Analog Video Output(s)</b>
	-	12-bit precision DAC output
	-	<b>Luma Bandwidth:</b> 12.5 MHz (SD) or 30 MHz (HD)
	-	<b>Chroma Bandwidth:</b> 5.8 MHz (SD) or 13.75 MHz (HD)

	<b>Audio Output</b>
	-	<b>Connector:</b>  DB-25
	-	<b>Maximum Level, unclipped:</b>  +12dBu, +15dBu, +18dBu, +24dBu (selectable)


	@subsection	hardwarecharacteristics	Hardware Characteristics

	@par		PCI Interface

	All NTV2 devices utilize Peripheral Component Interconnect (PCI) or Peripheral Component Interconnect
	Express (PCIe) to communicate with the host computer system (or with other PCI/PCIe peers on the same host).

	@par		PCI Vendor ID

	All AJA NTV2 devices have the same PCI vendor ID.
	-	PCI vendor ID:  <b><tt>0xF1D0</tt></b>

	@par		Data Transfer

	Direct Memory Access (DMA) is the only supported method of moving data between host memory
	and the hardware. All NTV2 devices have at least one DMA engine.
	(Programmed Input/Output, a.k.a. PIO is no longer supported.)
	-	To determine the number of DMA engines for a device, call ::NTV2DeviceGetNumDMAEngines.

	@par		Device Frame Buffer

	All NTV2 devices have a fixed amount of Synchronous Dynamic Random Access Memory (SDRAM).
	The FPGA is the SDRAM controller, which controls the output of video (and metadata, such as
	audio and anc) from RAM, the input of video (and metadata) into RAM, the PCI interface
	to/from RAM, and RAM refresh.

	@par		Frame Buffer Layout

	The FPGA is programmed with firmware that implements a number of video I/O and signal-processing
	“widgets”, plus other programming to handle other signal and data I/O.
	-	The device’s SDRAM is logically partitioned into a number of equal-sized <b>frames</b>.
	-	The intrinsic <b>frame size</b> used for \ref vidop-fbindexing defaults to 8MB (and is doubled
		when necessary).
	-	Call ::NTV2DeviceGetActiveMemorySize to discover a device’s SDRAM complement.

	@image	html	hwref-fig1-sdramfblayout.png

	The vast majority of the SDRAM frames are used for storing video raster data.

	Audio ring buffer storage is located at the very top of SDRAM. As such, the uppermost frame(s)
	should be avoided for video. See \ref audiooperation for more information.

	Video data in the device frame buffer is always stored full-frame. Interlaced video is
	always stored in the frame buffer with the first line of Field 1 (F1L1) at the top of the
	buffer, followed by the first line of Field 2 (F2L1), then F1L2, F2L2, F1L3, F2L3, etc.,
	alternating to the end of the frame. An exception to this is NTSC SD 525i, which starts
	with Field 2 at the top of the buffer (F2L1, F1L1, F2L2, F1L2, etc.).

	@note	A very <i>very</i> long time ago, AJA had devices that stored all of F1’s lines in
			the top half of the buffer, and all of F2’s lines in the bottom half. These devices
			and buffer formats are no longer supported.

	See \ref videooperation for more details.



	<hr size="50px">
	@section	videooperation		Video System Operation

	This section describes how the Video System operates.

	@subsection	vidop-fs		FrameStore Operation

	A <b>FrameStore</b> is a device widget implemented in FPGA firmware that writes or reads video data
	to or from SDRAM, depending upon its mode (capture or playback), and uses several registers to control
	its operation. Each <b>FrameStore</b> has the following properties:
	-	<b>Enable/Disable State</b> — When <b>Disabled</b>, the widget cannot access SDRAM.
		Disabling unnecessary SDRAM access reduces memory accesses and can thereby improve performance.
		-	Call CNTV2Card::IsChannelEnabled to determine if a <b>FrameStore</b> is enabled or not.
		-	Call CNTV2Card::EnableChannel or CNTV2Card::DisableChannel to change it.
		-	If \ref aboutautocirculate is used, the <b>FrameStore</b> is automatically enabled when needed
			(but it’s not automatically disabled after use).
	-	<b>Mode</b> — This correlates to the ::NTV2Mode enumeration in the SDK.
		-	In ::NTV2_MODE_DISPLAY mode, video data is <b>read</b> from SDRAM for playout.
			-	Call ::NTV2DeviceCanDoPlayback to determine if the device is capable of playing video from SDRAM.
		-	In ::NTV2_MODE_CAPTURE mode, video data is <b>written</b> into SDRAM.
			-	Call ::NTV2DeviceCanDoCapture to determine if the device is capable of recording video into SDRAM.
		-	Call CNTV2Card::GetMode to obtain the <b>FrameStore</b>’s current ::NTV2Mode.
		-	Call CNTV2Card::SetMode to set the ::NTV2Mode.
		-	If \ref aboutautocirculate is used, the ::NTV2Mode is automatically set (but it’s not automatically
			“un-set” after use).
	-	<b>Frame Buffer Format</b> — This determines the format of the pixel data being written or read
		to or from device SDRAM (when <b>Enabled</b>), and coincides with the ::NTV2PixelFormat
		(aka ::NTV2FrameBufferFormat) enumeration in the SDK. (See \ref devicefbformats for a description of
		the various formats.)
		-	Call ::NTV2DeviceCanDoFrameBufferFormat to determine if a specific ::NTV2PixelFormat is supported
			by the device.
		-	Call CNTV2Card::GetFrameBufferFormat to determine the current ::NTV2PixelFormat setting.
		-	Call CNTV2Card::SetFrameBufferFormat to change the ::NTV2PixelFormat setting.
		-	\ref aboutautocirculate  users should configure this before calling CNTV2Card::AutoCirculateStart.
	-	<b>Video Format</b> — This determines the format of the video being received by, or transmitted to, the
		<b>FrameStore</b>. This correlates to the ::NTV2VideoFormat enumeration in the SDK, which implies a
		::NTV2FrameGeometry, ::NTV2Standard and ::NTV2FrameRate.
		-	Call ::NTV2DeviceCanDoVideoFormat to determine if a specific ::NTV2VideoFormat is supported by
			the device.
		-	Call CNTV2Card::GetVideoFormat to determine the current ::NTV2VideoFormat setting.
		-	Call CNTV2Card::SetVideoFormat to change the ::NTV2VideoFormat setting.
		-	\ref aboutautocirculate  users should configure this before calling CNTV2Card::AutoCirculateStart.
	-	<b>Input Frame</b> — A register whose unsigned integer value designates the specific Frame Buffer in SDRAM
		that will be written with video frame data (assuming the <b>FrameStore</b> is <b>Enabled</b> and its ::NTV2Mode
		is ::NTV2_MODE_CAPTURE, and a valid signal is being received at the <b>FrameStore</b>’s input crosspoint).
		See \ref vidop-fbindexing for more information.
		-	Call CNTV2Card::GetInputFrame to determine the current <b>Input Frame</b> buffer number.
		-	Call CNTV2Card::SetInputFrame to change it.
		-	\ref autocirculatecapture users should ignore this value, as it’s managed automatically.
	-	<b>Output Frame</b> — A register whose unsigned integer value designates the specific Frame Buffer in SDRAM
		that will be read (assuming the <b>FrameStore</b> is <b>Enabled</b> and its ::NTV2Mode is ::NTV2_MODE_DISPLAY).
		See \ref vidop-fbindexing for more information.
		-	The output video can be monitored <b>if</b> the <b>FrameStore</b>’s output signal is routed to a
			video output widget, and a monitor is connected to its output connector.)
		-	Call CNTV2Card::GetOutputFrame to determine the current <b>Output Frame</b> buffer number.
		-	Call CNTV2Card::SetOutputFrame to change it.
		-	\ref autocirculatecapture users should ignore this value, as it’s managed automatically.
	-	<b>VANC Mode</b> — The ::NTV2VANCMode setting determines if a “tall” or “taller” frame geometry
		is in effect. The ::NTV2_VANCMODE_TALL geometry incorporates several extra lines of video that
		precede the first visible line in the raster into the <b>FrameStore</b>’s frame buffer memory.
		::NTV2_VANCMODE_TALLER was added to firmware when it was found that additional useful ancillary
		data was found on additional lines ahead of the first line in ::NTV2_VANCMODE_TALL mode.
		-	Call CNTV2Card::GetVANCMode to determine the current ::NTV2VANCMode setting.
		-	Call CNTV2Card::SetVANCMode to change it.
	-	<b>VANC Data Shift Mode</b> — The ::NTV2VANCDataShiftMode determines if the firmware will automatically
		right-shift incoming (or left-shift outgoing) data words by 2 bits in the VANC lines in \ref fbformat8bitycbcr
		frame buffers, making it easy to read (or write) ancillary data packets in the frame buffer.
		-	Call CNTV2Card::GetVANCShiftMode to determine the current ::NTV2VANCDataShiftMode setting.
		-	Call CNTV2Card::SetVANCShiftMode to change it.
	-	<b>Frame Buffer Orientation</b> — The ::NTV2FBOrientation (a.k.a. ::NTV2FrameBufferOrientation
		a.k.a. ::NTV2VideoFrameBufferOrientation) determines the direction that firmware will write or
		read video lines into or out of SDRAM, either normal ::NTV2_FRAMEBUFFER_ORIENTATION_TOPDOWN,
		or ::NTV2_FRAMEBUFFER_ORIENTATION_BOTTOMUP (reverse, which flips the image vertically).
		-	Call CNTV2Card::GetFrameBufferOrientation to determine the current setting.
		-	Call CNTV2Card::SetFrameBufferOrientation to change it.

	In the SDK, FrameStores are identified by an ::NTV2Channel enumeration and sometimes by a zero-based
	unsigned integer value, where zero corresponds to ::NTV2_CHANNEL1.
	-	Call ::NTV2DeviceGetNumFrameStores to determine the number of FrameStores on a given device.
		This will tell you how many Channels are available for simultaneous Capture and/or Output streams.
	-	Devices having only one <b>FrameStore</b> are limited to Capturing or Playing a single stream of video at a time.
	-	Devices with more than one <b>FrameStore</b> can independently input or output more than one video stream
		simultaneously, with each <b>FrameStore</b> accessing SDRAM.
	-	A few older AJA devices (e.g. \ref corvid1corvid3g) had two <b>FrameStore</b>s, but <b>FrameStore 1</b>
		was dedicated to ::NTV2_MODE_CAPTURE, and <b>FrameStore 2</b> to ::NTV2_MODE_DISPLAY.

	@note	In NTV2 parlance, the terms <b>Channel</b> and <b>FrameStore</b> are often used interchangeably.



	@subsection	independentmode		Multi-Format / “Independent” Mode

	<b>Multi-Format Mode</b>, also known as “Independent” mode, is a device capability in which it can
	simultaneously operate more than one stream, with each having a different video format.
	Devices having this capability that are in this mode are able to use a different ::NTV2VideoFormat
	on each <b>FrameStore</b>.

	This differs from prior device capability. For example, assuming there was sufficient DMA and processor
	bandwidth on the host, the \ref corvid24 could simultaneously ingest two video streams, and playout
	another two video streams — but all four streams must have the identical ::NTV2VideoFormat.

	In <b>Multi-Format Mode</b>, for example, assuming sufficient PCIe and host processor bandwidth,
	the \ref corvid44 could simultaneously ingest ::NTV2_FORMAT_720p_5000 and ::NTV2_FORMAT_525_5994 while
	playing ::NTV2_FORMAT_1080p_2997 and ::NTV2_FORMAT_720p_5994.

	The relevant SDK calls:
	-	Call ::NTV2DeviceCanDoMultiFormat to determine if a device is capable of simultaneously streaming
		multiple, different video formats.
	-	Call CNTV2Card::GetMultiFormatMode to find out if the device is currently operating in Multi-Format
		Mode or not.
	-	Call CNTV2Card::SetMultiFormatMode to change the mode.

	@note	This “Independent Mode” doesn’t mean that the FrameStores cannot interfere with each other’s
			frame buffer memory. FrameStores have equal access to any frame buffer in device SDRAM.
			Therefore, if you use frame buffers 0…5 for Channel 1, you must take care to <i>not</i> use
			frames 0…5 for any other channel on the device (unless you have good reason to do so).
			See \ref vidop-fbconflict (below) for more information.

	@note	In <b>Multi-Format Mode</b>, because NTV2 devices only have one hardware clock for driving the
			outputs, all <i>output</i> video formats must be in the same <b>Clock Family</b>.
			Call ::IsMultiFormatCompatible(const NTV2VideoFormat, const NTV2VideoFormat) to find out if two
			video formats are multi-format compatible.
			Call ::IsMultiFormatCompatible(const NTV2FrameRate, const NTV2FrameRate) to see if two frame
			rates are multi-format compatible.
			Call ::GetFrameRateFamily to determine the <b>Clock Family</b> that a given ::NTV2FrameRate
			belongs to. See \ref deviceclockingandsync for more details (below).


	@subsection	vidop-fbaccess		Frame Buffer Access

	Data can be transferred to or from the device at any time using the DMA API in the CNTV2Card class, or
	CNTV2Card::AutoCirculateTransfer if using \ref aboutautocirculate.

	Since the host computer <b>always has unrestricted access to frame memory at any time</b>, it’s critical
	to synchronize or gate transfers to/from the host using the vertical blanking interrupt
	(e.g., CNTV2Card::WaitForOutputVerticalInterrupt, CNTV2Card::WaitForOutputFieldID,
	CNTV2Card::WaitForInputVerticalInterrupt, CNTV2Card::WaitForInputFieldID, etc.). The transfer functions
	don't wait — they immediately perform the transfer, and wonʼt return until they finish (or fail).

	@warning	Calling CNTV2Card::DMAWriteFrame at a fraction of frame time <i>after</i> the VBI to write
				the same frame on the device that’s being read for the currently-playing video frame will
				likely look torn or distorted.
				Likewise for the opposite — i.e., calling CNTV2Card::DMAReadFrame at a fraction of frame time
				after or before the VBI to read the same frame being written by the <b>FrameStore</b> from the
				incoming video frame would result in some lines having pixel data from the new, incoming frame,
				while the remaining lines would contain old pixel data.

	For extremely tight latency, <b>FrameStore 1</b> has a ::kRegLineCount register that can be monitored (via
	CNTV2Card::ReadLineCount ), so that small bands of raster lines can be transferred “ahead of” the line counter
	(for playback) or “behind” it (for capture).  However, other FrameStores (2 or higher) do not have
	<b>Line Counter</b> registers.

	There are several DMA API functions for transferring data between host memory and device SDRAM.
	They are <b>frame-centric</b> in that they all require a zero-based index number or <b>Frame Offset</b> to
	calculate where to start reading or writing in device SDRAM.

	-	Call CNTV2Card::DMAReadFrame or CNTV2Card::DMAWriteFrame to transfer frame data from or to
		device SDRAM (respectively).
	-	<b>Frame Number</b> — See \ref vidop-fbindexing (below) for details.
	-	<b>Byte Count:</b>
		-	Should be even, or evenly divisible by 4, or ideally a power of two.
		-	Small transfers can sometimes be problematic for certain DMA engine firmware in combination
			with certain host hardware and OS platforms.  To avoid this, AJA recommends transferring at
			least 4096 bytes of data. Try smaller values if necessary, but test thoroughly with the
			devices and hardware you intend to support.
		-	It can be larger than a frame. For example, if the device frame size is 8MB, and the
			requested byte count is 16MB, two frames will be transferred.
	-	CNTV2Card::DMARead and CNTV2Card::DMAWrite are similar, but also accept a <b>Byte Offset</b>,
		which…
		-	Should be even, or evenly divisible by 4, or ideally a power of two.
		-	<b>Hint:</b> All device SDRAM can be accessed by using a zero <b>Frame Number</b> and
			using any offset value needed (up to 4GB minus the <b>Byte Count</b>).

	@note	DMA transfer speeds may be affected by the amount of video data being accessed by
			the device to transmit video. If a channel is in display mode, it is always playing
			video, and therefore reading from SDRAM, consuming SDRAM bandwidth… the amount consumed
			determined by the amount of data being read from frame memory… which depends on
			\ref fbframegeometries and \ref devicefbformats. <b>In some cases, DMA speeds can be increased
			by disabling unused channels</b> (see CNTV2Card::DisableChannel). Disabling unused channels
			is especially useful when using larger video and frame buffer formats, which use significant
			SDRAM bandwidth to read frame data for playout. In addition to the fact that more data is
			moved in, say, 48-bit RGB (than YUV8), the transfer of that data may also proceed at a
			slightly slower rate.

	@warning	Accessing memory addresses that are beyond the end of device SDRAM is not recommended,
				and will result in unexpected behavior — e.g. wrapping around and continuing from the
				start of device SDRAM.

	\ref aboutautocirculate users should call CNTV2Card::AutoCirculateTransfer to transfer video, audio,
	and/or ancillary data. By default, it knows the correct frame in device SDRAM to source (for capture)
	or target (for playback).


	@subsubsection	vidop-fbindexing	Frame Buffer Indexing

	<b>FrameStore</b>s access frame data in SDRAM starting at <b>Frame Offset</b>s measured from the start of
	SDRAM (at address zero).
	-	The first byte of the first raster line of the first frame coincides with SDRAM address <tt>0x00000000</tt>.
	-	<b>Frame Offset</b>s are always multiples of the “intrinsic” frame size of the device, which defaults to
		::NTV2_FRAMESIZE_8MB (8MB).
	-	The intrinsic frame size applies globally to all FrameStores on the device.
	-	Call CNTV2Card::GetFrameBufferSize to discover the current intrinsic frame size.
	-	When any FrameStoreʼs ::NTV2FrameGeometry or ::NTV2PixelFormat changes, the intrinsic frame size can change.
		Since Frame Offsets are always multiples of the deviceʼs intrinsic frame size, this means that the Frame
		Offsets for <i>all</i> FrameStores can change whenever <i>any</i> FrameStoreʼs ::NTV2FrameGeometry or
		::NTV2PixelFormat changes.
	-	The following table shows a sampling of actual raster sizes for three pixel formats:  \ref fbformat10bitycbcr,
		\ref fbformats8bitrgb, and \ref fbformats48bitrgb.<br />
		<table>
			<tr><td>::NTV2FrameGeometry		<td>::NTV2Standard		<td>::NTV2VANCMode	<td><b>Raster</b>	<td><b>10-bit YUV</b>	<td><b>8-bit RGBA</b>	<td><b>48-bit RGB</b>
			<tr><td>::NTV2_FG_720x486		<td>SD 525i				<td>Off				<td>720×486			<td>0.89 MB				<td>1.33 MB				<td>2.00 MB
			<tr><td>::NTV2_FG_720x508		<td>SD 525i				<td>Tall			<td>720×508			<td>0.93 MB				<td>1.40 MB				<td>2.09 MB
			<tr><td>::NTV2_FG_720x514		<td>SD 525i				<td>Taller			<td>720×514			<td>0.94 MB				<td>1.41 MB				<td>2.12 MB
			<tr><td>::NTV2_FG_720x576		<td>SD 625i				<td>Off				<td>720×576			<td>1.05 MB				<td>1.58 MB				<td>2.37 MB
			<tr><td>::NTV2_FG_720x598		<td>SD 625i				<td>Tall			<td>720×598			<td>1.09 MB				<td>1.64 MB				<td>2.46 MB
			<tr><td>::NTV2_FG_720x612		<td>SD 625i				<td>Tall			<td>720×612			<td>1.12 MB				<td>1.68 MB				<td>2.52 MB
			<tr><td>::NTV2_FG_1280x720		<td>HD 720p				<td>Off				<td>1280×720		<td>2.37 MB				<td>3.52 MB				<td>5.27 MB
			<tr><td>::NTV2_FG_1280x740		<td>HD 720p				<td>Tall			<td>1280×740		<td>2.44 MB				<td>3.61 MB				<td>5.42 MB
			<tr><td>::NTV2_FG_1920x1080		<td>HD 1080				<td>Off				<td>1920×1080		<td>5.27 MB				<td>7.91 MB				<td>11.9 MB
			<tr><td>::NTV2_FG_1920x1112		<td>HD 1080				<td>Taller			<td>1920×1112		<td>5.43 MB				<td>8.14 MB				<td>12.2 MB
			<tr><td>::NTV2_FG_1920x1114		<td>HD 1080				<td>Tall			<td>1920×1114		<td>5.44 MB				<td>8.16 MB				<td>12.2 MB
			<tr><td>::NTV2_FG_2048x1080		<td>HD 2K×1080			<td>Off				<td>2048×1080		<td>5.67 MB				<td>8.44 MB				<td>12.7 MB
			<tr><td>::NTV2_FG_2048x1112		<td>HD 2K×1080			<td>Tall			<td>2048×1112		<td>5.84 MB				<td>8.69 MB				<td>13.0 MB
			<tr><td>::NTV2_FG_2048x1114		<td>HD 2K×1080			<td>Taller			<td>2048×1114		<td>5.85 MB				<td>8.70 MB				<td>13.1 MB
		</table>
	-	After a geometry and/or pixel format change, when the required raster size of <i>any</i> FrameStore exceeds 8MB,
		the firmware automatically increases the intrinsic frame size to 16MB.
		-	After switching to 16MB, note that the frame buffer capacity of the device is cut in half.
			For example, if a device could store 100 × 8MB frames, after the bump to 16MB, it will only hold 50 frames.
			-	<b>WARNING:</b> This can adversely affect \ref aboutautocirculate streaming. For example, if frame buffers
				45 thru 55 were used for \ref autocirculatecapture using 8MB offsets, after the switch to 16MB, frames 50
				thru 55 would be invalid, and “out of bounds”, resulting in undefined behavior.
	-	Conversely, when no FrameStores require 16MB frame sizes, the firmware automatically reverts the intrinsic frame
		size to 8MB. (However, on some devices, this behavior can be changed. See below.)
	-	Most devices automatically switch to the larger 16MB size whenever ::NTV2VANCMode is enabled (i.e. “tall” or “taller”)
		on any FrameStore.
	-	<b>WARNING:</b> On devices with more than one FrameStore, if any other FrameStores are streaming video in their
		respective frame buffer ranges when the instrinsic frame size changed, there will be a noticeable glitch in their
		captured or outgoing video streams.
		-	Most devices can be pre-set and locked to 16MB to avoid Frame Size switching (and prevent video glitching).
		-	Call ::NTV2DeviceSoftwareCanChangeFrameBufferSize to determine if the device supports this 16MB pre-set/lock
			feature.
		-	Call <tt>CNTV2Card::SetFrameBufferSize(NTV2_CHANNEL1, ::NTV2_FRAMESIZE_16MB);</tt> to set the larger size in
			advance.
	-	<b>UHD/4K and UHD2/8K Frame Offsets</b>
		-	<b>UHD/4K</b> — Frame Offsets are 4 times the 8MB/16MB intrinsic frame size. This means that, from the
			FrameStoreʼs point of view, the deviceʼs frame capacity drops by ¼ when configured for UHD/4K video.
		-	<b>UHD2/8K</b> — Frame Offsets are 16 times the 8MB/16MB intrinsic frame size. This means that, from the
			FrameStoreʼs point of view, the deviceʼs frame capacity drops by a factor of 16 when configured for UHD2/8K video.
	-	<b>Frame Range Considerations When Streaming Both SD/HD and UHD/4K/8K</b>
		-	It can be tricky to determine frame ranges for SD/HD, UHD/4K, and/or UHD2/8K streams that won't interfere with each other.
		-	UHD/4K frame offsets are 4 times larger than the intrinsic SD/HD offsets.
		-	UHD2/8K frame offsets are 16 times larger than the intrinsic SD/HD offsets.
		-	<b>Example:</b> A device with SDRAM for up to 120 × 8MB frames must operate three streams, each with a 10-frame latency:
			-	<b>Channel 1:</b> continuous playout of UHDp60 from 8-bit ARGB;
			-	<b>Channel 2:</b> Capture various, intermittent video signals up to 1080p as 48-bit RGBA;  the signals come and go;
			-	<b>Channel 3:</b> Non-stop capture of continuous 525i SD signal as 10-bit YCbCr;
			-	<b>Solution:</b>
				-	The intrinsic frame size of 8MB is too small to accommodate 1080p rasters at 48-bit RGB (11.9MB).
					Therefore, to avoid glitches, the device will be pre-set to 16MB before starting any streams.
					The deviceʼs frame capacity is now only 60 × 16MB frames.
				-	On <b>Channel 1</b>, \ref autocirculateplayout UHD frames 0 thru 9.
					Because each UHD frame uses 4 intrinsic frames, the first available 16MB frame after this channelʼs
					buffers is frame 40.
				-	On <b>Channel 2</b>, when a valid signal is received, \ref autocirculatecapture frames 40 thru 49.
				-	On <b>Channel 3</b>, \ref autocirculatecapture frames 50 thru 59.
		-	\ref usingntv2watcher has a \ref memmapdlog that helps visualize device memory utilization.<br />
			@image	html	watcher-tool-memmap.png


	@subsubsection  vidop-fblocking		Host Buffer Locking

	A DMA transfer using CNTV2Card::AutoCirculateTransfer, CNTV2Card::DMAReadFrame, CNTV2Card::DMAWriteFrame, etc.
	requires the NTV2 device driver to perform these operations (ignoring some OS-dependent variations):
	-#	map the host buffer into kernel memory address space;
	-#	map and lock those pages into physical memory, where they must remain for the duration of the transfer;
	-#	build the segment list (or scatter-gather list) of memory segments for the DMA transfer (which also must remain
		in physical memory for the duration of the transfer);
	-#	perform the DMA transfer;
	-#	unmap/unlock all pages from physical (and kernel) memory.

	The mapping, locking and segment list construction steps can consume a substantial portion of the \ref autocirctimebudget,
	especially with larger rasters and/or pixel formats, which can contribute to frame-drops.

	In most use cases, client applications re-use the same host buffers over and over again. A substantial time savings can be
	realized if those host buffers are pre-locked and wired down into physical memory before entering the frame-processing
	loop (where CNTV2Card::AutoCirculateTransfer or CNTV2Card::DMAReadFrame or CNTV2Card::DMAWriteFrame are called).

	Starting in SDK 16.0, new DMA API functions were added for this purpose:
	-	CNTV2Card::DMABufferLock — maps and locks down a host buffer into physical memory.
		-	Starting with SDK 16.0.1, an optional parameter was added to also have the driver pre-build
			and cache the segment map (SGL) from the pre-locked buffer.
	-	CNTV2Card::DMABufferUnlock — unlocks and unmaps a host buffer that was previously locked.
		-	Starting in SDK 16.0.1, this also frees any previously cached segment map (SGL).


	@subsection	deviceclockingandsync		Device Clocking and Synchronization

	-	NTV2 devices have <i>one</i> output clock that drives <i>all</i> SDI outputs.
	-	When SDI output(s) are routed and connected, then device/output synchronization <i>must</i> be considered.

	@subsubsection  devclock-capture	“Capture-Only”

	On multiformat-capable devices (see ::NTV2DeviceCanDoMultiFormat) in <b>Capture</b> mode, the device firmware will calculate each input
	signal’s timing independently. If these signals are routed to FrameStores that are operating in
	<b>Capture</b> mode, the FrameStores will each signal VBIs independently at the correct time.
	For example:
	@image	html	hwref-inputtiming.png
	-	Repeated calls to <tt>CNTV2Card::WaitForInputVerticalInterrupt(NTV2_CHANNEL2)</tt> will occur at 50Hz;
	-	Repeated calls to <tt>CNTV2Card::WaitForInputVerticalInterrupt(NTV2_CHANNEL3)</tt> will occur at 24Hz.

	On older, uniformat devices, the input signals can still be captured independently, but they must be
	in the same frame rate “family” (i.e. <b>Clock Family</b>) as the overall device video format:<br>
	<b>Related Clock Families:</b>
	-	24 / 48
	-	25 / 50 (PAL)
	-	29.97 / 59.94 (NTSC)
	-	30 / 60 / 120

	@subsubsection  devclock-inout		“Capture &amp; Playout”

	Add a route from FrameStore4 to SDIOut4, configuring the <b>FrameStore</b> for 1080i2997 playout:
	@image	html	hwref-inputoutputsync.png
	In this scenario, there are now three output synchronization options:
	-#	Clock the output signal independently of the inputs and any other reference using the device’s
		internal clock. In this case, call CNTV2Card::SetReference with ::NTV2_REFERENCE_FREERUN.
	-#	Sync the outputs to a 29.97Hz (or 59.94Hz) external reference. For this case, call
	 	CNTV2Card::SetReference with ::NTV2_REFERENCE_EXTERNAL.
	-#	Sync the outputs to one of the SDI inputs. But note that this option is not viable in this
		example, because none of the input signals have 2997 or 5994 timing.

	If multiple input signals from the same <b>Clock Family</b> are feeding the device, it’s probably
	impossible to lock to them all, unless they’re all sync’d to a common timebase (often called “house
	reference”) … otherwise, the signals will all drift over time with respect to each other.
	For example, one signal may just be starting a new frame, while another is already half-way through
	its frame. Since the device clock can’t lock to more than one of them, ::NTV2_REFERENCE_FREERUN must
	be used, to clock the outputs from the device’s own internal clock source. Note that setting “free
	run” isn’t technically necessary — the application would run just as well locked to one of the input
	signals, with the only difference being when the output signals would actually come out of the BNCs.

	@subsubsection  devclock-ee			“End-to-End” (“E-E”)

	Add a route from SDIIn2 to SDIOut4 (assume this route is actually implemented in the firmware):
	@image	html	hwref-ee-sync.png
	This can be done either directly, as shown, or indirectly (for example, through a Mixer/Keyer widget).
	This requires the device’s output timing to be locked to the input signal. In this case, call
	CNTV2Card::SetReference with ::NTV2_REFERENCE_INPUT2.

	When the reference source is set to an SDI input, the output signal(s) will be locked to the same
	timebase as that of the designated source’s signal. For this to work, the output video format must
	have a frame rate in the same <b>Clock Family</b> as that being received at the SDI input. The actual
	output signal will exit the BNCs with about 2~3 lines of delay due to signal propagation through
	device circuitry, but the important point is that the phase relationship between the reference
	input signal and the output signal will be fixed, and will not drift.

	@note	For historical reasons, if SDI Input 1 is used for input and a signal is present,
			its signal frame rate dictates the <b>Clock Family</b> for all SDI outputs. When operating
			the device in multiformat mode, it’s therefore best to always use NTV2_CHANNEL1 as
			an output/playout channel, and use the other channels for input, as they don’t have
			the <b>Clock Family</b> restriction or any effect on the outputs.

	@subsubsection  devclock-extern		External Reference

	If the device’s output(s) must have a given timing (e.g., to feed a switcher), then applications
	can pass ::NTV2_REFERENCE_EXTERNAL to CNTV2Card::SetReference, which will lock the device to an
	analog or tri-level sync signal connected to the device’s external reference input.

	To determine the video format of the signal being applied to the reference input, call
	CNTV2Card::GetReferenceVideoFormat.

	@note	When configured for ::NTV2_REFERENCE_EXTERNAL, the device output will internally revert
			to Free-Run if the reference signal disappears or is incompatible with the output video
			format. When there’s no signal detected at the external reference connector, AJA
			recommends setting the device reference to ::NTV2_REFERENCE_FREERUN.


	@subsection	fieldframeinterrupts	Field/Frame Interrupts

	Many device hardware registers are updated on the video frame sync (i.e. the VBI associated with
	the start of a new frame). This is determined by the <b>FrameStore</b>’s ::NTV2RegisterWriteMode and is
	normally set to ::NTV2_REGWRITE_SYNCTOFRAME.

	For example, CNTV2Card::SetInputFrame is called by the client application to instruct the device’s
	<b>FrameStore</b> to write the next video frame that arrives into a specific frame buffer number in device
	memory. The function call immediately changes the <b>FrameStore</b>’s <b>Input Frame</b> register, but internally,
	the device firmware ensures that the <b>FrameStore</b> uses the new frame number value at the next ::NTV2_FIELD0
	(first field in time) sync pulse. (To avoid a race condition, though, the client application must wait
	for the VBI, which gives it an entire frame time to update hardware registers and configure the
	device widget settings that are required for the next frame to be processed.)

	For interlaced video, where the frame is transmitted as two fields, each field contains every other line
	of the frame. For HD video, the first field in time contains the first active line of the frame (i.e. the
	“top field” <i>a.k.a.</i> ::NTV2_FIELD0 <i>a.k.a.</i> <b>F1</b>); the second field contains the last
	active line of the frame (i.e. the “bottom field” <i>a.k.a.</i> ::NTV2_FIELD1 <i>a.k.a.</i> <b>F2</b>).
	Each field starts with a video sync — however, normally, in ::NTV2_REGWRITE_SYNCTOFRAME mode, the hardware
	registers are only updated at the ::NTV2_FIELD0 sync. Each of the syncs (::NTV2_FIELD0 and ::NTV2_FIELD1 )
	signals an interrupt to the driver, but CNTV2Card::WaitForInputFieldID (or CNTV2Card::WaitForOutputFieldID)
	check a hardware register and return only when the requested ::NTV2FieldID is detected.

	The <b>FrameStore</b> can alternatively be configured for <b>Field Mode</b> by passing ::NTV2_REGWRITE_SYNCTOFIELD
	into CNTV2Card::SetRegisterWriteMode, which causes calls to CNTV2Card::SetInputFrame or CNTV2Card::SetOutputFrame
	to take effect at the next <b>field</b> interrupt. In this mode of operation, the client application must wait
	for the next field interrupt – not frame interrupt – which gives it half the frame time to prepare/configure
	the device for the next field to be processed.

	For progressive video, all syncs are flagged by the hardware as ::NTV2_FIELD0 syncs, so registers
	are updated for the next frame and the CNTV2Card::WaitForInputFieldID (or CNTV2Card::WaitForOutputFieldID)
	work as expected.

	To wait for an event (such as a VBI) from a particular <b>FrameStore</b>, your application should subscribe
	to it by calling CNTV2Card::SubscribeInputVerticalEvent or CNTV2Card::SubscribeOutputVerticalEvent.

	Once subscribed, to efficiently wait for an input vertical interrupt, call CNTV2Card::WaitForInputFieldID or
	CNTV2Card::WaitForInputVerticalInterrupt, referencing the <b>FrameStore</b> that’s configured for capture,
	and that’s routed (directly or indirectly) from an input that has a valid video signal.

	To efficiently wait for an output vertical interrupt, call CNTV2Card::WaitForOutputFieldID or
	CNTV2Card::WaitForOutputVerticalInterrupt, referencing the <b>FrameStore</b> that’s configured for playout.

	The number of input or output vertical events that have successfully been waited on and fired can be obtained
	by calling CNTV2Card::GetInputVerticalEventCount or CNTV2Card::GetOutputVerticalEventCount.
	By calling either of these methods before and after calling the “wait for input/output” function, you
	can determine if indeed the interrupt event actually triggered. Call CNTV2Card::SetInputVerticalEventCount
	or CNTV2Card::SetOutputVerticalEventCount to reset the tally counter.

	Normally it’s not necessary to explicitly unsubscribe the CNTV2Card instance’s event subscriptions, as
	its destructor automatically calls CNTV2Card::Close.

	@note	On the <b>Windows</b> platform, the AJA NTV2 driver supplies a finite number of event subscription handles
			to client applications, which get consumed when subscribed (via CNTV2Card::SubscribeInputVerticalEvent,
			CNTV2Card::SubscribeOutputVerticalEvent, CNTV2Card::SubscribeEvent). They’re made available
			again to other clients when unsubscribed (via CNTV2Card::UnsubscribeInputVerticalEvent,
			CNTV2Card::UnsubscribeOutputVerticalEvent, CNTV2Card::UnsubscribeEvent), and automatically when
			the CNTV2Card object is closed or destroyed (via CNTV2Card::Close). However, abnormal program
			terminations, crashes, or force-quitting from a debugger will prevent this handle clean-up,
			which, after many repetitions of this, can result in their exhaustion. The are three ways to
			recover from this: 1) Reboot the machine. 2) Manually disabling and re-enabling the AJA driver
			(after closing all running NTV2 client applications, including the AJA Service. 3) Set virtual
			register kVRegClearAllSubscriptions to a non-zero value (this can be easily done in \ref usingntv2watcher
			tool’s \ref inspectorregs ).


	@subsection	vidop-fbconflict	When FrameStores Access the Same Frame Buffer Memory

	Note that it’s possible (and quite easy) to have two or more FrameStores accessing the same
	frame buffer memory.

	Here’s an example where this would be really bad:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signals at SDI Inputs 1 and 2
			//	(same video format, different content)...
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.SetInputFrame(NTV2_CHANNEL1, 0);	//	Write FrameStore 1 video into frame buffer 0

			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_CAPTURE);	//	Set FrameStore 2 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL2, false);	//	Set SDI connector 2 to capture
			device.Connect(NTV2_XptFrameBuffer2Input, NTV2_XptSDIIn2);	//	Connect SDI In 2 to FrameStore 2
			device.SetInputFrame(NTV2_CHANNEL2, 0);	//	Write FrameStore 2 video into frame buffer 0
		}
	@endcode
	In this case, there are two video signals fighting to write video rasters into the same frame memory on the device.
	If this frame were to be transferred to host memory, the image would look torn, a bad mixture of frames from SDI inputs 1 and 2.

	On the other hand, FrameStores sharing the same frame buffer memory can be beneficial, for example, as a <b>Frame Synchronizer</b>.
	Here’s an example of how to synchronize an SDI signal with the AJA device’s free-running output clock:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has a valid video signal at SDI Input 1:
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.SetInputFrame(NTV2_CHANNEL1, 0);	//	Write FrameStore 1 video into frame buffer 0

			device.SetReference(NTV2_REFERENCE_FREERUN);	//	Free run the outputs
			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_DISPLAY);	//	Set FrameStore 2 to playout mode
			device.SetOutputFrame(NTV2_CHANNEL2, 0);	//	Read FrameStore 2 video from frame buffer 0
			device.SetSDITransmitEnable(NTV2_CHANNEL3, true);	//	Set SDI connector 3 to output
			device.Connect(NTV2_XptSDIOut3Input, NTV2_XptFrameBuffer2YUV);	//	Connect FrameStore 2’s output to SDI Out 3
		}
	@endcode

	When AutoCirculate is used, AutoCirculate manages the <b>FrameStore</b>’s <b>Input Frame</b> register (capture) or <b>Output Frame</b> register (playout),
	repeatedly circulating it from the <b>Start Frame</b> to the <b>End Frame</b> (e.g., 0 thu 6).
	Another <b>FrameStore</b> can very easily write into any of the frames involved in another <b>FrameStore</b>’s AutoCirculate frame range.
	For example:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signals at SDI Inputs 1 and 2
			//	(same video format, different content)...
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.AutoCirculateInitForInput(NTV2_CHANNEL1, 0, NTV2_AUDIOSYSTEM_INVALID, 0, 1, 0, 6);	//	AutoCirculate capture into FBs 0/1/2/3/4/5/6
			device.AutoCirculateStart(NTV2_CHANNEL1);	//	Start AutoCirculate (assume another thread calls AutoCirculateTransfer)

			//	UH-OH:  This code block will cause 1 of every 7 frames captured via AutoCirculate
			//			on NTV2_CHANNEL1 to be corrupted by video from SDI Input 2...
			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_CAPTURE);	//	Set FrameStore 2 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL2, false);	//	Set SDI connector 2 to capture
			device.Connect(NTV2_XptFrameBuffer2Input, NTV2_XptSDIIn2);	//	Connect SDI In 2 to FrameStore 2
			device.SetInputFrame(NTV2_CHANNEL2, 3);	//	Write FrameStore 2 video into frame buffer 3
		}
	@endcode


	<hr size="50px">
	@subsection	vidop-csc		Color Space Converter Operation

	A <b>Color Space Converter</b> (a.k.a. <b>CSC</b>) is a device widget implemented in FPGA firmware that converts YCbCr values
	into RGB[A] values, or vice-versa. It uses several registers to configure its conversion properties.

	-	Generally, there is one CSC for every SDI connector. ::NTV2DeviceGetNumCSCs can be used to determine the number
		of CSCs on a given device, which should match ::NTV2DeviceGetNumVideoInputs or ::NTV2DeviceGetNumVideoOutputs (whichever is larger).
	-	CSC widgets are identified by ::NTV2_WgtCSC1, ::NTV2_WgtCSC2, etc.,
		but are normally identified in SDK calls by an ::NTV2Channel value that represents a zero-based index number.
	-	Each CSC has two inputs:
		-	<b>Video Input</b>:  This input should be routed to another widget’s output that produces…
			-	YCbCr video — in which case the CSC will produce valid RGB[A] data at its <b>RGB Video</b> output.
			-	RGB[A] video — in which case the CSC will produce valid YCbCr video at its <b>YUV Video</b> output,
				and alpha channel video at its <b>Key YUV</b> output.
		-	<b>Key Input</b>:  This supplies alpha channel data for the CSC’s <b>RGB Video</b> output. When used,
			it should always be sourced with YCbCr video (never RGB).
	-	Each CSC has 3 outputs:
		-	<b>YUV Video</b>:  This produces valid YCbCr video data only when the CSC’s <b>Video Input</b> is receiving RGB[A] video.
		-	<b>RGB Video</b>: This produces valid RGB[A] video data only when the CSC’s <b>Video Input</b> is receiving YCbCr video.
		-	<b>Key YUV</b>:  This produces valid YCbCr key data only when the CSC’s <b>Video Input</b> is receiving RGB[A] video.
	-	Routing instructions are in the \ref widget_csc section in the \ref ntv2signalrouting section.
	-	The CSC’s conversion coefficients are adjusted based on “SMPTE” versus “Full” range.
		-	The conversion range is represented in the SDK as the ::NTV2RGBBlackRange or ::NTV2_CSC_RGB_Range data types.
		-	Full range is represented by the ::NTV2_CSC_RGB_RANGE_FULL or ::NTV2_RGBBLACKRANGE_0_0x3FF enumerations.
			-	8-bit Full Range has 256 possible values (0 thru 255)
			-	10-bit Full Range has 1024 possible values (0 thru 1023).
		-	SMPTE range is represented by the ::NTV2_CSC_RGB_RANGE_SMPTE or ::NTV2_RGBBLACKRANGE_0x40_0x3C0 enumerations.
			-	8-bit SMPTE-range has 220 possible values (16 thru 235).
			-	10-bit SMPTE-range has 877 possible values (64 thru 940).
		-	Call CNTV2Card::GetColorSpaceRGBBlackRange to determine the current range setting for a CSC.
		-	Call CNTV2Card::SetColorSpaceRGBBlackRange to change a CSC’s range setting.
	-	The CSC’s conversion matrix can be set to “Rec. 601” (SD) or “Rec. 709” (HD).
		-	The conversion matrix type is represented in the SDK by the ::NTV2ColorSpaceMatrixType data type.
		-	Rec. 601 is represented by the ::NTV2_Rec601Matrix enumeration constant.
		-	Rec. 709 is represented by the ::NTV2_Rec709Matrix enumeration constant.
		-	Call CNTV2Card::GetColorSpaceMatrixSelect to determine the current matrix selection for a CSC.
		-	Call CNTV2Card::SetColorSpaceMatrixSelect to change a CSC’s matrix selection.

	@par	YCbCr to RGB Conversion

	-	When the CSC’s <b>Video Input</b> is connected to a YUV video source, it will convert and provide RGB data on
		its “RGB” output crosspoint.
	-	In addition to the YCbCr-to-RGB value conversion, the CSC also performs the necessary 4:2:2 up-sampling to fill the
		“missing” pixels in the outgoing RGB raster.
	-	The CSC will produce an <i>opaque</i> alpha channel by default.
	-	It can produce alpha channel data from YCbCr video supplied to its <b>Key Input</b> (using just the luma channel) —
		provided it’s configured to do so:
		-	Call CNTV2Card::GetColorSpaceMakeAlphaFromKey to determine if the CSC will use its <b>Key Input</b> to generate
			alpha channel data.
		-	Call CNTV2Card::SetColorSpaceMakeAlphaFromKey to enable or disable the setting.
		-	When “Make Alpha From Key” is enabled, call CNTV2Card::GetColorSpaceVideoKeySyncFail to query if the CSC’s
			<b>Key Input</b> is synchronized with its <b>Video Input</b>. Sync failure will occur if the Key and Video
			signals have unrelated frame rates, or are significantly out of phase with each other.

	The conversion formulæ:
	@code{.cpp}
		// Full-range 8-bit “Rec 601” (SD) conversion:
		R = 1.164384 * y  +  0.000000 * cb  +  1.596027 * cr;
		G = 1.164384 * y  -  0.391762 * cb  -  0.812968 * cr;
		B = 1.164384 * y  +  2.017232 * cb  +  0.000000 * cr;

		// SMPTE-range 8-bit “Rec 601” (SD) conversion:
		R = 1.000000 * y  +  0.000000 * cb  +  1.370705 * cr;
		R = 1.000000 * y  -  0.336455 * cb  -  0.698196 * cr;
		R = 1.000000 * y  +  1.732446 * cb  +  0.000000 * cr;

		// Full-range 10-bit “Rec 601” (SD) conversion:
		R = 1.167808 * y  +  0.000000 * cb  +  1.600721 * cr;
		G = 1.167808 * y  -  0.392915 * cb  -  0.815359 * cr;
		B = 1.167808 * y  +  2.023165 * cb  +  0.000000 * cr;

		// SMPTE-range 10-bit “Rec 601” (SD) conversion:
		R = 1.0000008 * y  +  0.000000 * cb  +  1.370705 * cr;
		G = 1.0000008 * y  -  0.336455 * cb  -  0.698196 * cr;
		B = 1.0000008 * y  +  1.732446 * cb  +  0.000000 * cr;

		// Full-range 10-bit “Rec 709” (HD) conversion:
		R = 1.167808 * y  +  0.000000 * cb  +  1.798014 * cr;
		G = 1.167808 * y  -  0.213876 * cb  -  0.534477 * cr;
		B = 1.167808 * y  +  2.118615 * cb  +  0.000000 * cr;

		// SMPTE-range 10-bit “Rec 709” (HD) conversion:
		R = 1.000000 * y  +  0.000000 * cb  +  1.539648 * cr;
		G = 1.000000 * y  -  0.183143 * cb  -  0.457675 * cr;
		B = 1.000000 * y  +  1.814180 * cb  +  0.000000 * cr;
	@endcode

	@note	The 8-bit and 10-bit coefficients are NOT the same, since the RGB 10-bit white point (1023)
			is not simply 4 × the 8-bit RGB white point (255).

	@par	RGB to YCbCr Conversion

	-	When the CSC’s <b>Video Input</b> is fed RGB[A] video, it will convert and provide YUV data on
		its “Video” and “Key” output crosspoints.
	-	In addition to the RGB-to-YCbCr value conversion, it also performs the necessary 4:2:2 down-sampling
		(implemented as a low-pass filter) for the fewer samples in the outgoing YUV raster.
	-	The <b>Key Output</b> luma channel data is scaled appropriately from the incoming alpha channel data.
		Its outgoing Cb and Cr component values are fixed at <tt>0x200</tt>.

	The conversion formulæ:
	@code{.cpp}
		// Full-range 10-bit “Rec 601” (SD) conversion:
		Y  =  0.25604 * r  +  0.50265 * g  +  0.09762 * b;
		Cb = -0.14779 * r  -  0.29014 * g  +  0.43793 * b;
		Cr =  0.43793 * r  -  0.36671 * g  -  0.07122 * b;

		// SMPTE-range 10-bit “Rec 601” (SD) conversion:
		Y  =  0.29900 * r  +  0.58700 * g  +  0.11400 * b;
		Cb = -0.17259 * r  -  0.33883 * g  +  0.51142 * b;
		Cr =  0.51142 * r  -  0.42825 * g  -  0.08317 * b;

		// Full-range 10-bit “Rec 709” (HD) conversion:
		Y  =  0.18205 * r  +  0.61243 * g  +  0.06183 * b;
		Cb = -0.10035 * r  -  0.33758 * g  +  0.43793 * b;
		Cr =  0.43793 * r  -  0.39777 * g  -  0.04016 * b;

		// SMPTE-range 10-bit “Rec 709” (HD) conversion:
		Y  =  0.21260 * r  +  0.71520 * g  +  0.07220 * b;
		Cb = -0.11719 * r  -  0.39423 * g  +  0.51142 * b;
		Cr =  0.51142 * r  -  0.46452 * g  -  0.04689 * b;
	@endcode

	@par	Enhanced CSCs

	Some AJA devices support “enhanced” CSC firmware that is used to override the default Rec 601 and Rec 709 conversion
	offsets and coefficients.  Call ::NTV2DeviceCanDoEnhancedCSC to determine if the device has the enhanced CSC firmware.


	<hr size="50px">
	@subsection	vidop-lut		LUT Operation

	A color <b>Look Up Table</b> (a.k.a. <b>LUT</b>) is a device widget implemented in FPGA firmware that converts specific
	input RGB values into other corresponding RGB values. It uses several registers to configure its conversion properties
	and a contiguous bank of registers for reading or writing the conversion table.

	@note	<b>LUT</b>s only work with RGB video, not YCbCr.

	-	For devices that have <b>LUT</b>s, there is usually one <b>LUT</b> for every <b>FrameStore</b> and/or SDI Input (or Output).
		Call ::NTV2DeviceGetNumLUTs to obtain the number of available <b>LUT</b>s.
	-	<b>LUT</b> widgets are identified by ::NTV2_WgtLUT1, ::NTV2_WgtLUT2, …, but are normally identified in SDK calls
		by ::NTV2Channel, a zero-based, unsigned index number.
	-	Each <b>LUT</b> widget has one input that only accepts RGB video.
	-	Each <b>LUT</b> widget has two outputs — <b>YUV</b> and <b>RGB</b> — that carry the converted video.
		The <b>YUV</b> output carries the luminance of the converted video in the <b>Y</b> channel.
	-	The ::NTV2DeviceGetLUTVersion function returns the version number of the <b>LUT</b> widget firmware implementation.
	-	The conversion is performed on a per-component basis using 10 bits of precision.
	-	The 10-bit Red, Green, or Blue component value (<tt>0x000</tt> thru <tt>0x3FF</tt>) is used as the index into
		the respective R, G, or B table to fetch the converted output value, another 10-bit value in the range
		<tt>0x000</tt> thru <tt>0x3FF</tt>.
	-	<b>LUT</b>s have two independent banks, only one of which is actively converting input video.
		-	A bank is identified by an integer value — <b>0</b> or <b>1</b>.
		-	To determine which bank is currently active for a given LUT, call CNTV2Card::GetColorCorrectionOutputBank.
		-	To switch the active LUT bank, call CNTV2Card::SetColorCorrectionOutputBank.
	-	There is currently no API call that reads the Red, Green and/or Blue conversion table values for a particular bank
		of a given LUT. (It can be done, but a control register must be configured before and after calling CNTV2Card::ReadLUTTables.)
	-	To change the Red, Green and/or Blue conversion table values for a particular bank:
		-	Build a 1,024-element <tt>std::vector</tt> of <b>UWord</b> or <b>double</b> values for each R, G and/or B
			component. Each value in the array should be in the range <tt>0 - 1023</tt> or <tt>0.00 - 1023.00</tt>, respectively.
		-	Call CNTV2Card::DownloadLUTToHW. The array values will automatically be clamped to the legal range <tt>0x000</tt>
			thru <tt>0x3FF</tt> prior to being written to the device.
	-	Some newer device firmware supports 12-bit LUTs. In 12-bit mode, the LUT table is expanded in size to 4,096 values
		per component, and the legal (output) values assume the range <tt>0x000 - 0xFFF</tt>.
	-	See \ref widget_lut for a discussion on how to route signals to and from <b>LUT</b> widgets.
	-	The \ref usingntv2watcher tool’s \ref inspectorlut can be used to inspect and/or modify <b>LUT</b> configuration.

	@note	The reading and writing of any 10-bit “version 2” LUT bank table data flows through registers 512-2047,
			with host access controlled by register 376 (<tt>kRegLUTV2Control</tt>). There is no software mutex
			guarding access to this register, so calls to read or write the tables are not thread-safe.

	<hr size="50px">
	@subsection	vidop-mixerkeyer		Mixer/Keyer Operation

	A <b>Mixer/Keyer</b> is a device widget implemented in FPGA firmware that mixes or “keys” YCbCr video.
	It uses a pair of registers for configuring its mixing/keying properties.

	@note	Mixer/Keyer widgets can only process YCbCr video — not RGB[A].

	-	Generally, there is one mixer/keyer for every 2 FrameStores and/or SDI Inputs (or SDI Outputs).
		Call ::NTV2DeviceGetNumMixers to obtain the number of Mixer/Keyer widgets that are available.
	-	Mixer/Keyer widgets are identified by ::NTV2_WgtMixer1, ::NTV2_WgtMixer2, …,
		but are normally identified in SDK calls by a zero-based, unsigned 16-bit index number.
	-	Each Mixer/Keyer has two outputs — <b>Video</b> and <b>Key</b> — that contain the mixed/keyed output video.
	-	Each Mixer/Keyer has four inputs:
		-	two <b>Foreground</b> inputs — <b>Video</b> and <b>Key</b> — and…
		-	two <b>Background</b> inputs — <b>Video</b> and <b>Key</b>.
		-	<b>Key Input</b>s only utilize Y-channel data — the Cb and Cr components are ignored.
		-	<b>IMPORTANT:</b> The Mixer’s foreground and background inputs must be closely synchronized
			or the Mixer won’t be able to mix them. If the Mixer is unlocked, its outputs will send unclocked
			(garbage) video.
			-	Call CNTV2Card::GetMixerSyncStatus to determine if the Mixer is locked to both of its inputs,
				and therefore if its output is valid.
	-	Each Mixer/Keyer has the following configuration parameters:
		-	::NTV2MixerKeyerMode — Primary operating mode:
			-	Use ::NTV2MIXERMODE_FOREGROUND_ON to exclusively pass the <b>foreground</b> video and key to the Mixer output.
			-	Use ::NTV2MIXERMODE_FOREGROUND_OFF to exclusively pass the <b>background</b> video and key to the Mixer output.
			-	Use ::NTV2MIXERMODE_MIX to overlay the foreground video on top of the background video. Foreground or background
				<b>Flat Matte</b> (see below), if enabled, will be mixed instead of its respective input raster.
			-	Call CNTV2Card::GetMixerMode to determine the Mixer’s current mode.
			-	Call CNTV2Card::SetMixerMode to change its mode.
		-	::NTV2MixerKeyerInputControl — input control mode, one for foreground input, one for background input:
			-	::NTV2MIXERINPUTCONTROL_FULLRASTER ignores the input key.
			-	::NTV2MIXERINPUTCONTROL_SHAPED uses the input key as a mask.
			-	Call CNTV2Card::GetMixerFGInputControl to discover the foreground input’s current control value.
			-	Call CNTV2Card::SetMixerFGInputControl to change the foreground input’s control value.
			-	Call CNTV2Card::GetMixerBGInputControl to discover the background input’s current control value.
			-	Call CNTV2Card::SetMixerBGInputControl to change the background input’s control value.
		-	<b>Mix Coefficient</b> — an unsigned, 16-bit integer that determines the transparency of the foreground mask/key.
			-	Call CNTV2Card::GetMixerCoefficient to determine the current mix coefficient value.
			-	Call CNTV2Card::SetMixerCoefficient to change its value.
		-	<b>Output VANC Source</b> — The Mixer’s output video VANC can be sourced from the foreground
			or background input video.
			-	Call CNTV2Card::GetMixerVancOutputFromForeground to determine if the output VANC is currently
				being sourced from the foreground video input.
			-	Call CNTV2Card::SetMixerVancOutputFromForeground to change the output VANC source.
		-	<b>Flat Matte</b> — The Mixer’s foreground or background raster can be set to a flat matte of any
			10-bit YCbCr color. This matte will override any respective video input to the Mixer.
				-	Call CNTV2Card::GetMixerFGMatteEnabled to determine if the foreground matte is enabled or not.
				-	Call CNTV2Card::SetMixerFGMatteEnabled to enable or disable using the foreground matte.
				-	Call CNTV2Card::GetMixerBGMatteEnabled to determine if the background matte is enabled or not.
				-	Call CNTV2Card::SetMixerBGMatteEnabled to enable or disable using the background matte.
				-	Do not enable <b>Flat Matte</b> on both foreground and background — use one or the other, or neither.
				-	Call CNTV2Card::GetMixerMatteColor to determine the current matte color.
				-	Call CNTV2Card::SetMixerMatteColor to change the matte color.
				-	Note that to retain sync and enable its video output, the Mixer still requires a foreground
					video source if background matte is enabled, or a background video source if foreground
					matte is enabled.
	-	For information on how to route signals to and from the Mixer, see \ref widget_mixkey.
	-	The \ref usingntv2watcher tool’s \ref inspectormixerkeyer allows you to interactively view each Mixer/Keyer
		widget’s current configuration, as well as make changes to it.



	<hr size="50px">
	@section	audiooperation		Audio System Operation

	<b>Firmware Implementation</b>
	-	An <b>Audio System</b> consists of:
		-	A Record engine that operates the <b>Capture</b> aspect of the <b>Audio System</b> (if ::NTV2DeviceCanDoCapture returns \c true):
			-	when <i>Running</i>, continually writes audio samples into its 4MB input audio buffer region in device SDRAM, wrapping as necessary.
			-	obtains audio samples from a designated source FIFO (see CNTV2Card::SetAudioSystemInputSource).
		-	A Playback engine that operates the <b>Playout</b> aspect of the <b>Audio System</b> (if ::NTV2DeviceCanDoPlayback returns \c true):
			-	when <i>Running</i>, continually reads audio samples from its 4MB output audio buffer region in device SDRAM, wrapping as necessary.
			-	can drive destination/output/sink FIFO(s);
			-	always sends silence (zeroes) when <i>Stopped</i>.
		-	Several firmware registers are used to monitor and control each <b>Audio System</b>.
	-	Audio sources (inputs) and destinations (outputs) have FIFOs associated with them that pipe/stream their audio data to/from other sinks/sources.
		-	A source FIFO can drive an <b>Audio System</b>’s Record engine (for writing into device SDRAM),
			or it can feed another audio destination’s FIFO.
		-	A destination (sink) FIFO can pull audio from an <b>Audio System</b>’s Playout engine (reading from device SDRAM),
			or it can pull from another audio source’s FIFO.
		-	Depending on the transport chipset, they accommodate 2, 4, 8 or 16 channels of audio. Some are configurable (e.g. 2 or 8 channel HDMI audio).
		-	<b>SDI</b>:
			-	SDI inputs each have an <b>audio de-embedder</b> to decode incoming SMPTE 272M/299M HANC packets found in the input SDI stream,
				pushing audio into its (source) FIFO.
			-	SDI outputs each have an <b>audio embedder</b> to encode and insert SMPTE 272M/299M HANC packets into the SDI stream,
				pulling audio from its (sink) FIFO.
				-	The SDI <b>audio embedder</b> can be turned off, if desired.
				-	“Loopback” audio play-through is implemented by tying an output FIFO to an input FIFO (see CNTV2Card::SetAudioLoopBack).
		-	<b>HDMI</b>, <b>AES/EBU</b> and <b>Analog</b> audio are handled similarly.
			-	Inputs <i>receive</i> audio, and <i>push</i> the samples into their associated source FIFO(s).
			-	Outputs <i>transmit</i> audio, <i>pull</i>ing from their associated sink FIFO(s).
		-	There are bits in certain control registers that control where a destination/sink FIFO pulls its audio from.

	@note	NTV2 devices with custom ancillary data extractors/inserters (see ::NTV2DeviceCanDoCustomAnc) make it possible to capture
			(and on some devices with special firmware, playback) SDI audio without using an <b>Audio System</b>, instead using the
			\ref anccapture or \ref ancplayout capabilities. Also note the \ref ancillarydata facility won’t work for HDMI, AES/EBU
			or Analog transports — the <b>Audio System</b> facility must be used.

	<b>Audio Systems</b>
	-	NTV2-compatible devices have a minimum of one <b>Audio System</b> (sometimes referred to in the past as an <b>Audio Engine</b>).
	-	An <b>Audio System</b> can stream audio, whether in <b>Capture</b> (Record) mode, or <b>Playout</b> mode, or both.
	-	Call ::NTV2DeviceGetNumAudioSystems to determine the number of <b>Audio System</b>s on a device.

	<b>Audio Channels</b>
	-	Each <b>Audio System</b> can accommodate at least 8 channels of audio.
	-	Call ::NTV2DeviceGetMaxAudioChannels to determine the maximum number of audio channels that a device’s
		<b>Audio System</b>s can handle.
	-	Call CNTV2Card::GetNumberAudioChannels to determine how many audio channels a device <b>Audio System</b>
		is currently configured for.
		-	Modern AJA devices will accommodate up to 16 channels.
		-	Very old AJA devices defaulted to 6 channels at power-up — these should be configured to use 8 channels.
	-	Call CNTV2Card::SetNumberAudioChannels to change the number of audio channels a device <b>Audio System</b>
		is configured to use.
		@note	AJA recommends configuring the <b>Audio System</b> to use the maximum number of audio channels the
				device is capable of.
	-	<b>HDMI Audio</b> — The HDMI standard supports a minimum baseline of 2 audio channels up to a maximum of 8.
	-	<b>AES/EBU Audio</b> — The AES/EBU connectors (on cables or breakout boxes) support 8 audio channels.
	-	<b>Analog Audio</b> — Analog audio connectors (on cables or breakout boxes) support 4 or 8 audio channels.
	-	<b>Monitor Audio</b> — Audio monitoring (RCA and/or headphone jacks) supports 2 audio channels.
	-	The firmware automatically ensures that excess unused audio channels will capture silence or be ignored for
		playout. For example, an <b>Audio System</b> that’s been configured for 16 channels and is recording 2 HDMI
		audio channels will carry the HDMI audio in channels 1 and 2, and contain silence in channels 3 thru 16.
	-	Note that some SDI video formats have substantially reduced HANC capacity, and thus can only carry 8 audio
		channels (e.g. 2K×1080@2997, 2K×1080@30, 4K@29.97, 4K@30). Again, the <b>Audio System</b> can still operate
		in 16-channel mode, but will capture and/or playout silence in channels 9-16.



	<b>Audio Sample Rate</b>
	-	The <b>Sample Rate</b> on all AJA devices is fixed at 48 kHz.
	-	All NTV2 devices implement a 48 kHz <b>Audio Clock</b> that can be sampled through the ::kRegAud1Counter register.
		-	This register is reset to zero at power-on and PCIe reset, and increments every 20.833… µs.
		-	It’s used by \ref aboutautocirculate for precise timing purposes in FRAME_STAMP::acAudioClockTimeStamp,
			FRAME_STAMP::acAudioClockCurrentTime, AUTOCIRCULATE_STATUS::acAudioClockStartTime
			and AUTOCIRCULATE_STATUS::acAudioClockCurrentTime.

	<b>Audio Buffers</b>
	-	Each <b>Audio System</b> uses an 8 MB contiguous block of memory located in the upper part of SDRAM:
		@image	html	hwref-fig2-audiobuffers.png
	-	An NTV2 device will use one of these two memory configurations for its <b>Audio System</b>s’ buffers:
		-	“Stacked” — The first <b>Audio System</b>’s 8 MB chunk starts at the very top of SDRAM,
			such that the last byte of <b>Audio System</b> 1’s <b>Input Buffer</b> coincides with the last addressable
			byte of SDRAM. Subsequent Audio Systems’ buffers stack downward from there, 8 MB each.
		-	“Non-stacked” — These devices use the last one or two video frames for audio storage.
			The first byte of the last <b>Audio System</b>’s <b>Output Buffer</b> coincides with the first byte
			of the last frame buffer in device memory. Previous <b>Audio System</b> buffers, if any, start
			at the next-lower 8MB frame buffer.
	-	Call ::NTV2DeviceCanDoStackedAudio to determine if the device uses the “stacked” arrangement or not.
	-	The first (lower address) 4 MB of the <b>Audio System</b>’s 8 MB chunk is for <b>Audio Output</b>.
	-	The last (higher address) 4 MB of the <b>Audio System</b>’s 8 MB chunk is used for <b>Audio Input</b>.
	-	Each Output or Input aspect of the <b>Audio System</b> operate independently, each being in one of two states:
		-	<b>Stopped</b> — a.k.a. the “Reset” state.
		-	<b>Running</b> — When the Input or Output aspect of the <b>Audio System</b> is Running,
			eight or sixteen channels (see CNTV2Card::GetNumberAudioChannels) of audio are always
			written/read to/from this memory, regardless of whether all 8 or 16 channels are used.
	-	See \ref audioformats for details on the format of the audio data in the buffer.

	@warning	It is easy to write video data into an audio buffer and vice-versa, which leads to noisy,
				garbled audio and/or bad video frame(s). SDK clients must take precautions to ensure that frame
				buffers used by your application never coincide with any of the audio buffers.

	@note	The \ref usingntv2watcher tool’s \ref inspectoraudio allows you to monitor each Audio System’s
			capture or playout buffer, as well as inspect or change its current configuration.

	@warning	A fixed 4MB audio buffer necessarily places a maximum time limit … and therefore an upper limit on the number of 
				frames of audio that can be buffered.  For example, 4MB will hold up to 1.37 seconds of 16-channel audio, or
				2.73 seconds of 8-channel audio. At 60 fps, that’s 82 or 164 frames, respectively;  or at 29.97 fps, that’s
				41 or 82 frames. Modern NTV2 devices have a large enough SDRAM complement such that it’s easy to buffer hundreds
				of video frames on the device, which can readily exceed the maximum frames of audio that can be buffered.
				CNTV2Card::AutoCirculateInitForInput or CNTV2Card::AutoCirculateInitForOutput will emit a warning in
				\ref usingajalogger or the \ref usinglogreader if the requested number of video frames to buffer exceeds the
				audio buffering capacity. (Be sure to enable the <tt>AutoCirculate_39</tt> message group to see these messages.)


	<hr size="50px">
	@subsection	audiocapture		Audio Capture

	For devices that are capable of capturing video, each <b>Audio System</b> constantly extracts audio samples from its
	<b>Input Source</b> (assuming the source is locked to a valid signal). If there’s no input signal, the <b>Audio System</b>
	invents zero values (silence) across all audio channels.
	-	Generally, the <b>Input Source</b> is selectable, to receive samples from any of the device’s video (and possibly audio)
		<b>Input Source</b>s, including embedded SDI, HDMI, external AES and analog inputs.
		-	Call CNTV2Card::GetAudioSystemInputSource to determine the <b>Audio System</b>’s current <b>Input Source</b>.
		-	Call CNTV2Card::SetAudioSystemInputSource to change the <b>Audio System</b>’s <b>Input Source</b>.
	-	<b>SDI Sources:</b>  Audio samples are de-embedded from incoming audio HANC packets:
		-	<b>HD:</b> follows SMPTE 299M: Each audio sample consists of 24 bits of sample data (normally PCM).
		-	<b>SD:</b> follows SMPTE 272M: Each audio sample consists of 20 bits of PCM sample data — audio extended packets are ignored.
		-	For devices that support 3Gb Level B inputs, the audio can be taken from data stream 1 or 2.
		-	Missing Embedded Audio Group packets (each containing two audio channel pairs) in the data stream result in silence (zeroes)
			for their respective audio channels.
		-	The firmware continually notes which Embedded Audio Group packets are present and which are missing, and coalesces this
			information into a hardware register. Call CNTV2Card::GetDetectedAudioChannelPairs to query this information.
	-	<b>HDMI Sources:</b>  Audio samples are pulled from the HDMI input hardware.
		-	Call CNTV2Card::GetHDMIInputAudioChannels to determine if the HDMI input is supplying 2 or 8 channels of audio.
		-	Call CNTV2Card::SetHDMIInputAudioChannels to change the HDMI audio input configuration.
	-	<b>AES:</b>  Audio samples are obtained from the AES inputs.
		-	Call CNTV2Card::GetDetectedAESChannelPairs to determine which audio channel pairs have valid sample data.
	-	<b>Analog:</b>
		-	Call ::NTV2DeviceGetNumAnalogAudioInputChannels to determine if the device can capture analog audio, and if so, the maximum
			number of audio channels.
		-	On devices that support 2 channels of analog audio, audio samples for audio channels 1&amp;2 are obtained from the analog
			video input.
		-	Some devices that support analog audio input through a breakout box or cable (see ::NTV2DeviceCanDoBreakoutBox
			and ::NTV2DeviceGetNumAnalogAudioInputChannels functions) have bi-directional analog XLR connectors.
			Call ::NTV2DeviceHasBiDirectionalAnalogAudio to determine if this is true, and if so:
			-	Call CNTV2Card::GetAnalogAudioTransmitEnable to discover if a given XLR quad (::NTV2Audio4ChannelSelect) is configured for output or input.
			-	Call CNTV2Card::SetAnalogAudioTransmitEnable to configure a given XLR quad (::NTV2Audio4ChannelSelect) for input by passing <i>false</i> for <i>inEnable</i>.

	When the <b>Audio System</b> is running, each 24-bit sample is copied as-is into the most-significant 3 bytes of each 4-byte
	sample word in the <b>Audio Input Buffer</b> in device memory at the address specified by the <b>Audio System</b>’s Audio Input
	Last Address register (i.e., the <b>Record Head</b> or “write head”).
	-	On older (non-stacked-audio) devices, this sample-copying process is done in 128-byte chunks.
	-	On newer (stacked-audio) devices, 512-byte chunks are used.
	-	Call CNTV2Card::IsAudioInputRunning to determine if the capture side of the <b>Audio System</b> is running or not.
	-	Call CNTV2Card::StartAudioInput to start the capture aspect of the <b>Audio System</b> running.
	-	Call CNTV2Card::StopAudioInput to stop the capture aspect of the <b>Audio System</b> running.
	-	Call CNTV2Card::SetAudioCaptureEnable to enable or disable writing into the <b>Audio System</b>’s <b>Input Buffer</b> memory.
		Note that <b>Input Buffer</b> writing can be disabled while the <b>Audio System</b> is running — the <b>Audio System</b>
		will continue to go through the motions of Capture, advancing the <b>Record Head</b> as needed, but the <b>Input Buffer</b>’s
		contents won’t change.

	Call CNTV2Card::ReadAudioLastIn to obtain the current <b>Record Head</b> position. Audio data continues to be written into the
	<b>Input Buffer</b> until filled, whereupon the <b>Record Head</b> wraps back to the start of the buffer, where writing
	continues. The least-significant byte of each 32-bit sample word in the <b>Audio Input Buffer</b> is always set to zero.
	(Note that for SD, because extended packets are ignored, an extra 4-bit nibble in each 32-bit sample word will also be zero.)

	@image	html	hwref-fig3-audiorecordplay.png

	Audio data can be transferred from the <b>Audio Input Buffer</b> in device memory to a host audio buffer via DMA
	by calling CNTV2Card::DMAReadAudio.  While the offset to the Input portion of the device Audio Buffer is typically
	fixed at 4 MB, to be absolutely safe should this ever change, call CNTV2Card::GetAudioReadOffset to obtain the
	actual offset being used by the driver and SDK.

	@note	If \ref aboutautocirculate is used for capture, \ref aboutautocirculate completely and automatically runs the <b>Audio System</b> —
			there is no need to call CNTV2Card::StartAudioInput or CNTV2Card::SetAudioCaptureEnable. When CNTV2Card::AutoCirculateInitForInput
			is called with a valid ::NTV2AudioSystem, and CNTV2Card::AutoCirculateStart is subsequently called, \ref aboutautocirculate starts
			the <b>Audio System</b>. CNTV2Card::AutoCirculateTransfer automatically transfers the correct number of captured audio samples
			from the device Audio System’s <b>Input Buffer</b> that are associated with the video frame being transferred.
			AUTOCIRCULATE_TRANSFER::GetCapturedAudioByteCount will return the exact number of transferred audio bytes for the frame that was just
			transferred to the host. See \ref autocirculatecapture for more information.

	Upstream equipment may indicate one or more audio channel pairs is not carrying PCM data (e.g., Dolby-E) via certain bits in the AES
	header in the audio stream. On newer AJA devices (see ::NTV2DeviceCanDoPCMDetection), the <b>Audio System</b>’s de-embedder makes this
	information available in a hardware register, and client software can query it by calling CNTV2Card::GetInputAudioChannelPairsWithoutPCM
	or CNTV2Card::InputAudioChannelPairHasPCM.

	@note	<b>Dolby AC-3</b>, for example, per SMPTE ST-337, is transported as non-PCM data in the SDI AES stream.
			The AC-3 data is located in the PCM audio sample words of a channel pair — see \ref audioformats .
			The formatting of the AC-3 data into the channel pairs is quite flexible, but usually a channel pair (e.g. 5&amp;6) is considered a single AC-3 stream.
			The specification allows AC-3 data to be carried in 16, 20 or 24 bits of the PCM sample.
			This flexibility requires the application to know how the source has formatted the data into the AES samples.

	Newer AJA hardware firmware implements an adjustable input delay that can be applied while samples are being written into the
	<b>Audio Input Buffer</b>. Call ::NTV2DeviceCanDoAudioDelay to determine if this feature is available. Call CNTV2Card::GetAudioInputDelay
	to obtain the current delay value. Call CNTV2Card::SetAudioInputDelay to change it.

	Audio input clocking for the running <b>Audio System</b> is ordinarily obtained from the input signal being used (SDI, HDMI, Analog, etc.).
	AJA’s older devices, however, derived the audio input clock from the Device Reference by default (see ::NTV2ReferenceSource) and had to be
	explicitly configured to use the input signal by passing ::NTV2_EMBEDDED_AUDIO_CLOCK_VIDEO_INPUT to CNTV2Card::SetEmbeddedAudioClock.
	If this wasn’t done, and the board reference was ::NTV2_REFERENCE_FREERUN or some other timebase that differed from the input video signal,
	the audio would eventually drift from the video. (See also ::NTV2DeviceCanChangeEmbeddedAudioClock.)


	<hr size="50px">
	@subsection	audioplayout		Audio Playout

	If the device supports SDI playout, each <b>Audio System</b> has an output embedder that generates audio packets (per SMPTE 299M for HD
	and SMPTE 272M for SD) and inserts them into the HANC area of the outgoing SDI data stream.
	-	Audio channels 1 & 2 are transmitted on Embedded Group 1, channels 1 & 2.
	-	Audio channels 3 & 4 are transmitted on Embedded Group 1, channels 3 & 4.
	-	Audio channels 5 & 6 are transmitted on Embedded Group 2, channels 1 & 2.
	-	Audio channels 7 & 8 are transmitted on Embedded Group 2, channels 3 & 4.
	-	In 16-channel mode (see CNTV2Card::GetNumberAudioChannels), the remaining 8 channels are distributed in Embedded Groups 3 and 4
	in a similar fashion.

	There is currently no provision for enabling or disabling specific audio groups.

	The SDI output embedder always inserts audio packets unless it’s been disabled (see CNTV2Card::SetAudioOutputEmbedderState).

	Call CNTV2Card::IsAudioOutputRunning to determine if the playout side of the <b>Audio System</b> is running or not.
	Call CNTV2Card::StartAudioOutput to start the playout side of the <b>Audio System</b> running.
	Call CNTV2Card::StopAudioOutput to stop the playout side of the <b>Audio System</b> running.

	When the <b>Audio System</b> is stopped, the output embedder will either embed silence (zeroes) into the data stream, or,
	if ::NTV2AudioLoopBack mode is enabled, it will embed audio samples obtained (through a FIFO) from its input de-embedder
	(see CNTV2Card::SetAudioLoopBack).

	When the <b>Audio System</b> is running, each 24-bit audio sample is copied from the most-significant 3 bytes of each 32-bit longword
	in the device audio buffer (the least-significant byte is ignored). Note, however, for <b>SD</b>, only the most-significant 20 bits
	are used (since the embedder does not create extended audio packets).

	During playout, the output embedder pulls audio samples from the <b>Audio Output Buffer</b> in device memory at the address
	specified by the <b>Audio System</b>’s <b>Audio Output Last Address</b> register (i.e., the <b>Play Head</b> or “read head”).
	On older, non-stacked-audio devices, this is done in 128-byte chunks. On newer, stacked-audio devices, it’s done in 512-byte chunks.

	Call CNTV2Card::ReadAudioLastOut to get the current <b>Play Head</b> position. Audio data continues to be read from the
	<b>Output Buffer</b> until the end is reached, whereupon the <b>Play Head</b> wraps back to the start of the buffer, where
	reading continues.

	<b>Startup Delay:</b> Ordinarily, when playout starts, the Audio System immediately starts pulling samples from the
	<b>Audio Output Buffer</b>, encoding them into audio packets and embedding those first several packets into the current
	outgoing video frame, often mid-frame, preceded by a number of packets containing silence. This makes it difficult for
	applications to precisely determine the location of frame breaks in the <b>Audio Output Buffer</b>. Starting in SDK 15.6,
	and using newer AJA hardware and firmware (see CNTV2Card::CanDoAudioWaitForVBI), CNTV2Card::StartAudioOutput has an optional
	“<i>waitForVBI</i>” parameter that if set <tt>True</tt>, causes the firmware to delay starting Audio Playout until the next
	output VBI, so that the first samples from the <b>Audio Output Buffer</b> end up in the first audio packets in the next
	outgoing video frame.

	<b>Output Delay:</b> Newer AJA hardware firmware implements an adjustable <b>Output Delay</b> that can be applied while samples are
	being read from the <b>Audio Output Buffer</b>. Call ::NTV2DeviceCanDoAudioDelay to determine if this feature is available.
	Call CNTV2Card::GetAudioOutputDelay to obtain the current delay value. Call CNTV2Card::SetAudioOutputDelay to change it.

	<b>Erase Mode:</b> The playout engine has an optional <b>Erase Mode</b>, in which it will automatically clear (zero) the
	<b>Output Buffer</b> memory immediately behind the <b>Play Head</b> as it runs. If the host application fails to transfer
	new samples into the <b>Audio Output Buffer</b>, the buffer will eventually contain all zeroes, and the output embedder
	will thereafter only transmit silence. Use the CNTV2Card::SetAudioOutputEraseMode function to configure this feature.

	<b>DMA Transfer:</b> Audio data can be transferred from the host to the device audio buffer via DMA by calling
	CNTV2Card::DMAWriteAudio. The last address written into the <b>Audio Output Buffer</b> (via DMA) is latched and
	available for readback at <b>Audio Output Last Address</b> (within 256 bytes). If the output hardware <b>Play Head</b>
	pointer catches up to the <b>Audio Output Last Address</b>, the buffer will wrap, and audio/video synchronization will be lost.

	If \ref autocirculateplayout is being used, AutoCirculate completely and automatically runs the <b>Audio System</b>.
	When CNTV2Card::AutoCirculateInitForOutput is called with a valid ::NTV2AudioSystem, and then CNTV2Card::AutoCirculateStart
	is called, AutoCirculate starts the <b>Audio System</b>. Youʼll need to transfer the correct number of audio samples via
	AUTOCIRCULATE_TRANSFER::SetAudioBuffer or AUTOCIRCULATE_TRANSFER::acAudioBuffer before calling CNTV2Card::AutoCirculateTransfer.
	See \ref audiosamplecount (below) on how to calculate the correct number of audio samples for the current outgoing frame.

	<b>SDI Output:</b> SDI output embedders can ordinarily be driven by any <b>Audio System</b>.
	-	Call CNTV2Card::GetSDIOutputAudioSystem to determine which Audio System is currently driving Data Stream 1.
	-	Call CNTV2Card::SetSDIOutputAudioSystem to change DS1’s Audio System.
	-	On devices that have 3G/6G/12G SDI connectors that support Dual Link output:
		-	Call CNTV2Card::GetSDIOutputDS2AudioSystem to determine the Audio System that’s currently driving Data Stream 2.
		-	Call CNTV2Card::SetSDIOutputDS2AudioSystem to change DS2’s Audio System.

	<b>HDMI Output:</b> The HDMI standard supports a minimum baseline of 2 audio channels up to a maximum of 8.
	If the NTV2 device has an HDMI output (see ::NTV2DeviceGetNumHDMIVideoOutputs ), it can be configured
	to transmit audio from any <b>Audio System</b>:
	-	To transmit 2 audio channels, call CNTV2Card::SetHDMIOutAudioSource2Channel :
		-	Specify the ::NTV2AudioSystem that will drive the HDMI outputʼs audio;
		-	Specify the ::NTV2AudioChannelPair that will determine which two of the
			Audio Systemʼs 8 (or 16) audio channels will be used.
	-	To transmit 8 audio channels, call CNTV2Card::SetHDMIOutAudioSource8Channel :
		-	Specify the ::NTV2AudioSystem that will drive the HDMI outputʼs audio;
		-	Specify the ::NTV2Audio8ChannelSelect that will determine which group of 8
			contiguous channels will be used from the Audio Systemʼs (presumably) 16 channels.

	<b>AES/EBU Output:</b> For devices that support AES/EBU output through a breakout box or cable (see ::NTV2DeviceCanDoBreakoutBox
	and ::NTV2DeviceGetNumAESAudioOutputChannels functions), the output BNCs will automatically carry the same per-audio-channel
	samples being played/embedded from <b>Audio Sytem 1</b> (::NTV2_AUDIOSYSTEM_1).  This can be changed to use a different
	set of 4 audio channels, even from a different <b>Audio System</b> (if available).
	-	Call CNTV2Card::GetAESOutputSource to determine the current ::NTV2AudioSystem and ::NTV2Audio4ChannelSelect
		(a contiguous band of 4 audio channels) being used for a given set of 4 AES audio channels.
	-	Call CNTV2Card::SetAESOutputSource to set the 4 audio channels and/or ::NTV2AudioSystem to be used for a given set
		of 4 AES audio channels.

	<b>Analog Output:</b> For devices that support analog audio output through a breakout box or cable (see ::NTV2DeviceCanDoBreakoutBox
	and ::NTV2DeviceGetNumAnalogAudioOutputChannels functions), the output XLRs follow whatʼs being carried by the <b>AES/EBU Output</b>s
	(above).
	-	Call ::NTV2DeviceGetNumAnalogAudioOutputChannels to determine if the device can output analog audio, and if so, the maximum
		number of audio channels it supports.
	-	Some devices have bi-directional analog XLR connectors.  Call ::NTV2DeviceHasBiDirectionalAnalogAudio to determine if this is true.
		For these bi-directional XLRs:
		-	Call CNTV2Card::GetAnalogAudioTransmitEnable to discover if a given XLR quad (::NTV2Audio4ChannelSelect) is configured for output or input.
		-	Call CNTV2Card::SetAnalogAudioTransmitEnable to configure a given XLR quad (::NTV2Audio4ChannelSelect) for output or input.

	<b>Monitor Output:</b> For devices that support analog audio monitoring through two RCA jacks on a breakout box
	(see ::NTV2DeviceHasAudioMonitorRCAJacks and ::NTV2DeviceCanDoBreakoutBox) and/or a headphone jack (see ::NTV2DeviceHasHeadphoneJack),
	by default, the monitor output will carry audio channels 1 & 2 (::NTV2_AudioChannel1_2) from <b>Audio Sytem 1</b> (::NTV2_AUDIOSYSTEM_1).
	-	Call CNTV2Card::GetAudioOutputMonitorSource to determine which ::NTV2AudioChannelPair and ::NTV2AudioSystem is currently providing
		samples to the audio monitor output.
	-	Call CNTV2Card::SetAudioOutputMonitorSource to change which ::NTV2AudioChannelPair and ::NTV2AudioSystem will provide samples to
		the audio monitor output.

	<b>Non-PCM Data:</b><br>

	Downstream equipment can be told that the outgoing audio is not carrying PCM data, by setting the non-PCM indicator in the AES header.
	Older AJA devices can only do this on an audio-system-wide basis — i.e., all outgoing audio groups are marked PCM or non-PCM.
	Use the simpler form of the CNTV2Card::SetAudioPCMControl function for these devices.

	Newer AJA devices can mark individual audio channel pairs as non-PCM (the ::NTV2DeviceCanDoPCMControl function returns true for
	devices that support this capability). Use one of the overloaded versions of CNTV2Card::SetAudioPCMControl that accepts either a
	single ::NTV2AudioChannelPair or an ::NTV2AudioChannelPairs set.

	<b>AES Sync-Mode Bit:</b><br>

	By default, the embedder clears the <b>Sync Mode bit</b> in the <b>AES header</b> in the <b>Audio Control Packet</b>s, which tells
	downstream equipment that the outgoing audio is <b>asynchronous</b>, even though overall, the correct total number of audio samples
	over a span of several frames always get transmitted. This is particularly relevant for 29.97/59.94 frame rates, in which the number
	of 48 kHz audio samples varies with each frame … yet is constant/fixed over a 5-frame sequence.

	If downstream equipment expects <b>synchronous</b> audio, and is alarming about the <b>asynchronous</b> audio, the output embedder
	can be told to set the <b>Sync Mode bit</b>, but note that this is “fibbing”:
	-	Call CNTV2Card::GetAudioOutputAESSyncModeBit to see if the device is setting the Sync Mode bit.
	-	Call CNTV2Card::SetAudioOutputAESSyncModeBit to change the setting.

	@note	When the embedder is configured to “fib” — i.e. set the <b>Sync Mode bit</b> in the <b>AES header</b> in the <b>Audio
			Control Packet</b> — audio and video are synchronized in time, but the resulting audio doesn’t exactly follow the
			definition of “synchronized” in SMPTE 299 § 7.2.1.3, because the embedder doesn’t set the <b>Frame Sequence Number</b>
			in the <b>AES header</b>. SMPTE 299, however, stipulates that receivers should correctly receive audio even from
			equipment that doesn’t fully conform to § 7.2.1.3.

	The \ref usingntv2watcher tool has a \ref tonegenerator that can be used to fill any Audio System’s output buffer, either statically
	(one-time data fill) or dynamically (continuously).


	<hr size="50px">
	@subsection	audiosamplecount	Correlating Audio Samples to Video Frames

	Because AJA devices use fixed audio sample rates (i.e. 48000 samples per second), some video frame rates will necessarily result
	in some frames having more audio samples than others. For example, the NTSC frame rate is exactly 30000/1001 frames per second — so by
	converting frames to samples, the expected number of audio samples at any given frame time can be calculated. This is what
	the ::GetAudioSamplesPerFrame utility function is for:
	@code{.cpp}
		//	Print the audio sample count cadence for NTSC 2997...
		for (ULWord frame(0);  frame < 60;  )
		{
			std::cout << DEC(::GetAudioSamplesPerFrame(NTV2_FRAMERATE_2997, NTV2_AUDIO_48K, frame));
			if (++frame < 60)
				std::cout << ", ";
			if (!(frame % 5))
				std::cout << std::endl;
		}
	@endcode

	-	<b>Capture</b>
		-	<b>Without AutoCirculate</b> — the number of audio samples to associate with the current frame is provided by the
			hardware’s <b>Record Head</b>. Just compare its new position with its old position from the previous frame.
		-	<b>With AutoCirculate</b> — Use the AUTOCIRCULATE_TRANSFER::GetCapturedAudioByteCount function.
	-	<b>Playout</b>
		-	<b>Without AutoCirculate</b> — ::GetAudioSamplesPerFrame will return the <i>recommended</i> number of samples to write
			for the current frame. It’s important to transfer samples ahead of the <b>Play Head</b> (yet not so far or so many as
			to overrun it).
		-	<b>With AutoCirculate</b> — Use ::GetAudioSamplesPerFrame to calculate the number of audio samples to write for
			the current frame. Transferring more or fewer samples than this number may impel AutoCirculate to reset the audio.


	<hr size="50px">
	@subsection	audiomultilink	Multi-Link Audio (32, 48, 64 Audio Channels)

	By default, per SMPTE standard, up to 16 independent audio channels are supported by a single 3G SDI signal (except for 2K
	and 4K formats, which only support up to 8 channels, as previously noted, due to reduced HANC space).

	SDK 16.2 introduced the capability of adding an additional bank of 16 audio channels with each additional SDI link of multi-link
	video input or output:
	-	For dual-link 3G, 6G or 12G configurations, up to 32 audio channels are supported.
	-	For quad-link 3G, 6G or 12G (UHD2/8K) configurations, 32, 48 or 64 audio channels are supported.

	@note	This feature requires newer firmware and driver version 16.2 or later.

	Essentially, it gangs together 2 to 4 Audio Systems, and operates the higher-numbered ones as “slaves” by the lowest-numbered one –
	i.e. the “master” – to record (or play) samples through them all simultaneously.

	Each controlled Audio System uses its same 4MB of device memory for buffering audio samples. The driver automatically handles
	redirecting each link’s samples during the DMA (CNTV2Card::AutoCirculateTransfer).

	@note	This capability currently only works with AutoCirculate channels ::NTV2_CHANNEL1 or ::NTV2_CHANNEL3.

	To enable and use this feature:
	-	Be sure the device being used has the firmware capability by calling ::NTV2DeviceCanDoMultiLinkAudio.
		@code{.cpp}
			if (::NTV2DeviceCanDoMultiLinkAudio(device.GetDeviceID()))
			{
				//	Has multi-link audio feature
			}
		@endcode
	-	During set-up:
		-	In the call to CNTV2Card::AutoCirculateInitForInput or CNTV2Card::AutoCirculateInitForOutput, bitwise-OR into the
			<i>inOptionFlags</i> parameter the appropriate <tt>AUTOCIRCULATE_WITH_MULTILINK_AUDIO</tt> constant(s) for each
			additional SDI link (and therefore additional bank of 16 audio channels) that are desired.
			-	For example, in a quad-link (UHD or 4K) configuration, to capture 48 channels of audio from the first three SDI links:
				@code{.cpp}
					device.AutoCirculateInitForInput (NTV2_CHANNEL1,  7,  NTV2_AUDIOSYSTEM1,
							AUTOCIRCULATE_WITH_AUDIO | AUTOCIRCULATE_WITH_MULTILINK_AUDIO1 | AUTOCIRCULATE_WITH_MULTILINK_AUDIO2);
				@endcode
		-	For each ::NTV2AudioSystem associated with each SDI link:
			-	Call CNTV2Card::SetAudioSystemInputSource with <tt>::NTV2_AUDIO_EMBEDDED</tt> and the appropriate <tt>NTV2_EMBEDDED_AUDIO_INPUT_VIDEO_n</tt>.
			-	Call CNTV2Card::SetNumberAudioChannels with the maximum (16).
			-	Call CNTV2Card::SetAudioRate (normally with <tt>NTV2_AUDIO_48K</tt>).
			-	Call CNTV2Card::SetAudioBufferSize (with <tt>NTV2_AUDIO_BUFFER_BIG</tt>).
			-	Call CNTV2Card::SetAudioLoopBack with <tt>NTV2_AUDIO_LOOPBACK_OFF</tt>.
		-	The per-frame audio buffer used in AUTOCIRCULATE_TRANSFER::SetBuffers or AUTOCIRCULATE_TRANSFER::SetAudioBuffer should be a
			multiple of the size of a normal buffer used for a single link with 16-channels. The multiplier should be 2 for dual-link SDI
			(32 channels),  3 for three links (48 channels), or 4 for quad-link (64 channels).
	-	While running:
		-	For playback, before CNTV2Card::AutoCirculateTransfer is called, be sure the audio buffer contains all of the audio samples
			intended for each SDI link in ascending link order in the buffer, with each link’s data matching that shown in \ref audfmt-16chan.
			That is, put the first link’s samples in the host buffer first, followed by the second link’s, and so on, with no gaps between
			each link’s samples. The 32, 48 or 64 channel samples are not interleaved — only the 16-channel samples are interleaved per-link.
		-	For capture, after CNTV2Card::AutoCirculateTransfer returns, the host audio buffer will have all of the audio samples for each SDI
			link in ascending order in the buffer, with each link’s data matching that shown in \ref audfmt-16chan.
			That is, the first link’s samples will be in the host buffer first, followed by the second link’s, and so on, with no gaps between
			each link’s samples. The 32, 48 or 64 channel samples are not interleaved — only the 16-channel samples are interleaved per-link.
	-	Examples — a new <tt>--audioLinks</tt> option was added to these \ref demoapps …
		-	\ref ntv2capture4k
		-	\ref ntv2player4k
		-	\ref ntv2player8k

	@bug	At this time, there is no API to support multi-link audio for low-latency (non-AutoCirculate) applications.


	<hr size="50px">
	@subsection	audiohidden		“Hidden” Audio Systems

	Modern AJA devices intended for “retail” markets, particularly newer \ref ntv2hwkona and \ref ntv2hwio, may have firmware that
	implements additional “hidden” <b>Audio System</b>s that aren’t reported by the ::NTV2DeviceGetNumAudioSystems function:
	-	A <b>Host Audio System</b> for audio input/output to/from the host operating system (see ::NTV2DeviceGetHostAudioSystem);
	-	A “phantom” <b>Mixer Audio System</b> that uses only FIFOs (no audio buffer memory) in order to implement an \ref audiomixer
		(see CNTV2Card::DeviceCanDoAudioMixer and ::NTV2DeviceGetAudioMixerSystem).

	These additional <b>Audio System</b>s help support AJA’s “retail” software (i.e. Adobe, Avid, Apple, Telestream, etc. plug-ins,
	AJA ControlRoom, etc).

	The <b>Host Audio System</b> is used to continuously deliver…
	-	SDI/HDMI/AES audio from the AJA KONA/Io device as input to the host computer’s primary audio system.
		For example, this would enable an audio capture program running on the host (e.g. Audacity) to capture audio from an SDI input signal on the KONA/Io device.
	-	Host audio output from the host OS’s primary system audio to the KONA/Io device’s SDI/HDMI/AES output.
		For example, this would enable audio from a web browser running on the host computer to playout through a KONA/Io device’s SDI output.

	The <b>Host Audio System</b> is started and operated by the AJA kernel driver in conjunction with the host computer system’s audio control panel.
	It allows host audio to operate independently of other <b>Audio System</b>s on the device that may be used by AutoCirculate or other
	SDK client software.

	Since the <b>host audio system</b> uses audio buffer memory in device SDRAM, it’s susceptible to \ref audioclobber if an excessively
	large video buffer number is used by an active <b>FrameStore</b>.


	<hr size="50px">
	@subsection	audioclobber	Audio Buffer Corruption

	It’s possible (and quite easy) to configure a <b>FrameStore</b> to write video into audio buffer memory.
	For example:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signal at SDI Input 1
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1

			//	Which video frame is the first to contain audio system audio?
			//	You could just start incrementing frame numbers until you start getting bad audio.
			//	But here’s how to really do it...
			NTV2FrameGeometry		fg;
			NTV2FrameBufferFormat	fbf;
			device.GetFrameGeometry(fg, NTV2_CHANNEL1);
			device.GetFrameBufferFormat(NTV2_CHANNEL1, fbf);
			ULWord firstAudioFrameNum = ::NTV2DeviceGetNumberFrameBuffers(device.GetDeviceID(), fg, fbf);
			if (::NTV2DeviceCanDoStackedAudio(device.GetDeviceID()))
			{
				ULWord			chan1CtrlBits(0);
				mDevice.ReadRegister(kRegCh1Control, &chan1CtrlBits);
				ULWord			frameSizeMB (1 << (((chan1CtrlBits & kK2RegMaskFrameSize) >> 20) + 1));
				if (frameSizeMB < 8)
					frameSizeMB = 8;	//	No 2MB mode!
				const ULWord	maxRamBytes(::NTV2DeviceGetActiveMemorySize(device.GetDeviceID()));
				const ULWord	numAudioSystems(::NTV2DeviceGetNumAudioSystems(device.GetDeviceID()));
				const ULWord	totalAudioBytes(numAudioSystems * 8ULL*1024ULL*1024*ULL);	//	8MB per audio system
				firstAudioFrameNum = (maxRamBytes - totalAudioBytes) / frameSizeMB;
			}

			//	UH-OH:  This will cause video to be written into the audio buffers...
			device.SetInputFrame(NTV2_CHANNEL1, firstAudioFrameNum);	//	Write FrameStore 1 video into audio area
		}
	@endcode

	In the above example…
	-	On “stacked audio” devices, this will write video into the last <b>Audio System</b>’s buffer memory.
	-	On older “non-stacked audio” devices, this will write video into the first <b>Audio System</b>’s buffer memory.
	-	To notice the corruption, the affected <b>Audio System</b> will need to be running (playout and/or capture).
	-	It’s more likely to be noticed in audio playout, since the output audio buffer starts at the top of the frame.
	-	Small frame geometries and pixel formats (e.g., 8-bit YUV 525i) are less likely to touch the audio capture
		buffer that starts 4MB into the frame.

	It’s also possible (and quite easy) to configure a <b>FrameStore</b> to playout SDI/HDMI video that’s been corrupted by
	audio-in-the-video. This would happen if the <b>FrameStore</b> is set for playout and it’s using a frame buffer that’s
	also being used by a running <b>Audio System</b>.


	<hr size="50px">
	@subsection	audiomixer		Audio Mixer

	Some newer NTV2 devices have firmware that implements a three-multichannel-input <b>Audio Mixer</b>.
	-	To determine if a device supports this feature, call ::NTV2DeviceCanDoAudioMixer.
	-	To determine if the device actually has this feature in its running firmware, call CNTV2Card::DeviceCanDoAudioMixer.
	-	To determine the ::NTV2AudioSystem of the mixer, call ::NTV2DeviceGetAudioMixerSystem.

	The <b>Audio Mixer</b> firmware supports up to three two-channel (stereo) audio inputs:
	-	<b>Main</b> — can utilize any audio channel pair from any <b>Audio System</b>:
	-	<b>Auxiliary 1</b> — the first two audio channels from any <b>Audio System</b>:
	-	<b>Auxiliary 2</b> — the first two audio channels from any <b>Audio System</b>:
	-	To discover which <b>Audio System</b>’s output is feeding any given mixer input,
		call CNTV2Card::GetAudioMixerInputAudioSystem. To change it, call CNTV2Card::SetAudioMixerInputAudioSystem.
	-	To discover which audio channel pair is currently feeding any given mixer input,
		call CNTV2Card::GetAudioMixerInputChannelSelect. To change it, call CNTV2Card::SetAudioMixerInputChannelSelect.

	The resulting mixed audio is inserted onto the audio channel pair selected for the mix from the Main input,
	and the rest of that <b>Audio System</b>’s channel pairs are passed through to that same <b>Audio System</b>’s output
	(unless they’ve been muted).

	Any of the <b>Audio Mixer</b>’s inputs can be disabled (muted) or enabled (unmuted).
	-	Call CNTV2Card::GetAudioMixerInputChannelsMute to determine which audio channels of
		an <b>Audio Mixer</b>’s input are enabled or muted.
	-	Call CNTV2Card::SetAudioMixerInputChannelsMute to change them.

	Each <b>Audio Mixer</b> input has a gain control.
	-	Call CNTV2Card::GetAudioMixerInputGain to determine an input’s current gain setting.
	-	Call CNTV2Card::SetAudioMixerInputGain to change the setting.

	Each audio channel of the <b>Audio Mixer</b>’s output (up to 16 channels) can be individually muted.
	-	Call CNTV2Card::GetAudioMixerOutputChannelsMute to discover which mixer output audio channels are muted/disabled,
		and which are enabled/unmuted.
	-	Call CNTV2Card::SetAudioMixerOutputChannelsMute to mute or unmute the output audio channels.

	The <b>Audio Mixer</b>’s audio levels can be monitored:
	-	Call CNTV2Card::GetAudioMixerInputLevels to get the current levels of any specific audio channels of an input.
	-	The sample count the firmware uses for calculating audio levels is configurable:
		-	Call CNTV2Card::GetAudioMixerLevelsSampleCount to get the current sample count in use.
		-	Call CNTV2Card::SetAudioMixerLevelsSampleCount to change the setting.



	<hr size="50px">
	@section	devicefirmware		Firmware

	NTV2 devices have an EEPROM (non-volatile memory) that stores its FPGA programming.
	This flash memory is commonly divided into a minimum of two logical partitions:
	-	the “main” partition — for the normal FPGA bitfile image;
	-	the “failsafe” boot — for a fallback FPGA bitfile image.

	Some AJA devices — like the \ref konaip — have, in addition to the normal FPGA hardware, a microprocessor, which requires
	an additional, separate firmware bitfile that bootstraps and operates it. This extra firmware is bundled into a “package” that is
	also stored in (and loaded from) a separate partition in the EEPROM.

	Traditionally, the FPGA is only loaded from flash memory upon power-up.
	The “failsafe” bitfile loads if…
	-	the board’s “failsafe” button is held down while power is applied to the board;
	-	the “main” FPGA bitfile image was invalid or otherwise failed to load.

	All NTV2 devices have two on-board LEDs that indicate readiness:
	-#	<b>Power</b> — If the board has power, this will indicate <b>Green</b>; otherwise it won’t be lit.
	-#	<b>FPGA Load State:</b>
		-	<b>Green</b> — Normal firmware bitfile loaded successfully.
		-	<b>Amber</b> — Fail-safe firmware bitfile loaded.
		-	<b>Red</b> — FPGA not programmed; firmware load failed.

	When operating normally, both LEDs will be <b>Green</b>.

	@note	On the Io and T-Tap products, the LEDs are hidden inside the chassis and can’t be seen.
 
	<hr size="50px">
	@subsection	dev-firmware-loading	Loading Firmware

	Loading the FPGA from EEPROM after power-up takes a finite amount of time.
	If this exceeds the amount of time allotted by the BIOS for PCIe devices to become ready, the AJA device
	won’t be detected by the BIOS, and thus won’t be probed by — or matched to — any device drivers.
	-	On Windows PCs, this is shown as an “<i>Unknown device</i>” in the Windows <b>Device Manager</b>.
	-	On Linux PCs, the ‘<b>lspci</b>’ command can help diagnose these issues.
		For example, here’s what ‘<b>lspci</b>’ should normally show when looking for devices with AJA’s PCIe vendor
		ID of \c 0xF1D0 (e.g. for a Corvid88):
		@code{.sh}
			$ lspci -d f1d0:
			03:00.0 Multimedia video controller: AJA Video Device eb0d
			$ lspci -n  -d f1d0:
			03:00.0 0400: f1d0:eb0d
			$ lspci -nn  -d f1d0:
			03:00.0 Multimedia video controller [0400]: AJA Video Device [f1d0:eb0d]
		@endcode

	<b>Disable Fast-Boot Option:</b><br />
	On PCs running Windows or Linux, be sure to disable all fast-boot options in the BIOS.

	<b>Disable Power-Saving Modes:</b><br />
	AJA’s NTV2 devices do not support PCIe power management.
	-	Be sure to disable any and all Energy-Saving features in the OS,
		particularly PCIe “Link State Power Management” (LSPM).
	-	<b>Windows</b> — This is in “Advanced Power Settings” ==≻ “Power Options” ==≻
		“PCI Express” ==≻ “Link State Power Management” ==≻ <b>Off</b>.
	-	<b>Linux</b> — Use the \c lspci command:
		@code{.sh}
			$ sudo lspci -vvv  -d f1d0:
		@endcode
		… and confirm that “LnkCtl: ASPM Disabled” is shown for each AJA device.
	-	On some motherboards, power management is controlled by the BIOS, in which case,
		try <b>disabling ASPM</b> under the BIOS’ <b>power options</b>.

	If, even after disabling “fast-boot”, the AJA device fails to show up, …
	-	Try “warm-booting” the PC. If the device is recognized after a warm-boot, then it’s likely a firmware load-time issue.
	-	Try installing the AJA board into a different PCIe slot on the motherboard. Some manufacturers employ chips that perform
		intermediate buffering on certain specific PCIe slots that can sometimes cause detection issues. Also beware that some
		manufacturers use a custom BIOS that has options for configuring PCIe slots, so be sure to check those BIOS settings
		and adjust them if needed.
	-	If the device still fails to show up, please <a href="https://sdksupport.aja.com/index.php?/Tickets/Submit">submit a Ticket</a>.

	<b>“Warm Boot” Reload</b><br />
	Some newer AJA devices are capable of reloading the FPGA upon a <b>PCIe Reset</b> — aka a “warm boot”.
	-	To test if the device can do a “warm boot” FPGA reload, call CNTV2Card::CanWarmBootFPGA.
	-	Note that AJA devices with Thunderbolt ports (e.g. \ref io4kplus ), or AJA boards installed on Thunderbolt PCIe
		card-cages receive a <b>PCIe Reset</b> when the Thunderbolt cable is unplugged and subsequently reconnected.


	<hr size="50px">
	@subsection	dev-firmware-flash		“Flashing” Firmware

	AJA provides two ways to “flash” — i.e. update — new firmware into the device’s EEPROM storage:
	-#	Using the <a href="https://sdksupport.aja.com/index.php?/Knowledgebase/Article/View/129">ntv2firmwareinstaller</a>
		command-line utility, described in \ref toolsandutilities.
	-#	Using the <b>AJA ControlPanel</b>, which is part of the “retail” software that can be downloaded from https://www.aja.com/.

	Once the new firmware has been written into the device EEPROM storage, it won’t “run” until the device FPGA gets reloaded
	(see \ref dev-firmware-loading above).


	<hr size="50px">
	@subsection	dev-firmware-vers		Determining Firmware Version

	@note	The <b>currently-running firmware</b> could be different from the <b>currently-installed firmware</b> that’s stored
			in the EEPROM’s main partition. This can happen if the device wasn’t power-cycled after a firmware update installation,
			or if the device was booted using its “failsafe” firmware.

	There are three ways to determine what firmware is installed, and/or which firmware is running on an AJA device:
	-	the <a href="https://sdksupport.aja.com/index.php?/Knowledgebase/Article/View/129">ntv2firmwareinstaller</a> command line
		utility, using its <b>--info</b> option;
	-	the “Info” or “Firmware” panels of the <b>AJA ControlPanel</b> application (in AJA’s “retail” software);
	-	programmatically using certain SDK API calls (described below).

	Newer AJA devices (starting with the \ref corvid88) report their <b>currently-running firmware date</b> in register 88,
	which is made available as numeric date components or a <tt>std::string</tt> by calling CNTV2Card::GetRunningFirmwareDate.

	Older AJA devices prior to the introduction of the \ref corvid88 have no way of reporting their <b>currently-running firmware date</b>
	— they can only report the running firmware’s <i>revision number</i> (which was stored in a portion of register 48 and made
	available by the CNTV2Card::GetRunningFirmwareRevision function. To correlate the revision number to a date, it must be looked
	up on the device’s firmware page on the
	<a href="https://sdksupport.aja.com/index.php?/Knowledgebase/List/Index/25/ntv2-firmware">AJA SDK support site’s KnowledgeBase</a>
	(not very convenient).

	-	To determine if a device is capable of reporting its <b>currently-running firmware date</b>, call ::NTV2DeviceCanReportRunningFirmwareDate.
	-	To determine the <b>currently-installed firmware</b> date, call CNTV2Card::GetInstalledBitfileInfo.
	-	To test if the fail-safe firmware is currently loaded, call CNTV2Card::IsFailSafeBitfileLoaded.


	<hr size="50px">
	@subsection	dev-firmware-features	Determining Firmware Features

	NTV2, being an old and rather crude architecture, has no automatically-enforced linkage between the firmware and the SDK —
	i.e. the SDK is neither generated from the firmware, nor is the firmware generated from the SDK.
	Thus, the SDK cannot simply “query the board” to find out how many of a particular widget a device’s running firmware implements,
	or if a new widget or feature is present (by simply reading registers).
	Unfortunately, this puts the burden of feature inquiry entirely into software, and onto the authors of NTV2 client applications.

	The \ref libajantv2-devicefeatures functions cover 95% of all hardware and firmware feature variations on all NTV2 devices.
	There are, however, a few features that can only be determined by querying the running device itself. Here are two examples:
	-	The \ref io4kplus and <a href="https://www.avid.com/products/avid-artist-io/features#Avid-Artist-DNxIV">Avid DNxIV</a> use
		identical firmware, but only the Avid device has an XLR microphone input on its front panel.
		Thus, CNTV2Card::DeviceHasMicInput is the only way to differentiate between the two devices.
	-	CNTV2Card::HasCanConnectROM is the only way to tell if a given firmware has the ROM feature used by
		CNTV2Card::CanConnect to determine if a given connection is actually implemented in the firmware.

	AJA will do its best to ensure that the “NTV2DeviceCanDo…”, “NTV2DeviceHas…” and “NTV2DeviceGetNum…” functions are correct
	for the specific set of firmware bitfiles that have been qualified for a given SDK release. The release notes on the SDK
	download page will point out any firmware features added (or removed).



	<hr size="50px">
	@subsection	dev-bitfile-switching	Fast Bitfile Switching

	New 8K and 12-bit workflows have made it extremely difficult to simultaneously fit FrameStores, CSCs, LUTs, and Mixers into
	even the much larger modern FPGAs. This has made it necessary to enable the ability to rapidly switch between different
	workflow-based bitfiles.

	There’s a new API in the CNTV2Card class that adds support for this capability:
	-	To determine if the device supports fast dynamic loading of bitfiles, call CNTV2Card::IsDynamicDevice.
	-	To determine what device IDs are available for fast dynamic loading on the current device, call CNTV2Card::GetDynamicDeviceIDs.
	-	To determine if a particular ::NTV2DeviceID can be loaded on the current device, call CNTV2Card::CanLoadDynamicDevice.
	-	To quickly and dynamically load a specific ::NTV2DeviceID bitfile onto the current device, call CNTV2Card::LoadDynamicDevice.
	-	To add a specific bitfile to the cache of known bitfiles, call CNTV2Card::AddDynamicBitfile.
	-	To add multiple bitfiles inside a host file directory (folder) to the cache of known bitfiles, call CNTV2Card::AddDynamicDirectory.

	These new API calls make use of a new ::CNTV2BitfileManager singleton class that caches and manages the available bitfiles for
	various AJA devices. It can be used if finer control is needed over the basic functionality in CNTV2Card.
**/
