/**
	@page	ntv2devops		NTV2 Device Hardware Operation

	On this page:
	-	\ref ntv2devops-intro
	-	\ref devicesignalinputsoutputs
		-	\ref commonelectricalchars
		-	\ref hardwarecharacteristics
	-	\ref videooperation
		-	\ref vidop-fs
		-	\ref independentmode
		-	\ref vidop-fbaccess
		-	\ref deviceclockingandsync
		-	\ref fieldframeinterrupts
		-	\ref vidop-fbconflict
	-	\ref audiooperation
	-	\ref devicefirmware
		-	\ref dev-firmware-vers



	<hr size="50px">
	@section	ntv2devops-intro	Introduction

	In simplest terms, NTV2 devices are essentially…
	-	a big chunk of SDRAM memory for buffering video frames and audio samples, which is tied to…
	-	an FPGA that determines what gets written or read to/from that memory (and where), plus…
	-	one or more video and/or audio signal inputs and/or outputs, and…
	-	a high-speed PCIe interface to a host computer, for rapidly reading or writing 32-bit registers,
		and transferring bulk data via DMA to/from the host.

	@image	html	hwref-fig0-blockdiagram.png

	In addition, the FPGA firmware implements “widgets“ that can process video data in a particular way
	(e.g., color correction, muxing/demuxing, etc.).

	All AJA NTV2 hardware devices minimally support the following:
	-	Capture or play to/from the host computer video and audio through at least one video connector.
	-	SD video formats: 525i 59.94fps, and 625i 50fps
	-	HD video formats: 720p 50/59.94/60, 1080i 50/59.94/60, 1080psf 23.98/24 and 1080p 23.98/24/29.97/30
	-	8-bit YCbCr or 10-bit YCbCr frame buffer formats.

	Beyond these common characteristics, AJA devices fan out into a diverse array of capabilities to suit many different applications.
	To determine the features of an AJA device, use the \ref ntv2devicefeatures.

	Most devices can capture and play video, but some may only capture, while others may only playout.
	-	To determine if a device can capture video, call ::NTV2DeviceCanDoCapture.
	-	To determine if a device can play video, call ::NTV2DeviceCanDoPlayback.



	<hr size="50px">
	@section	devicesignalinputsoutputs		Signal Inputs & Outputs

	@par	Breakout Boxes and Cables

	On some devices, certain signal connectors are accessible only through a breakout cable or breakout box.
	-	To determine if the device can support a breakout box, call ::NTV2DeviceCanDoBreakoutBox.
	-	To determine if a breakout box is connected, call CNTV2Card::GetBreakoutHardware.

	@par	SDI Connectors

	Most AJA devices have at least one SDI connector.
	-	To determine the number of SDI input jacks the device has, call ::NTV2DeviceGetNumVideoInputs.
	-	To determine the number of SDI output jacks the device has, call ::NTV2DeviceGetNumVideoOutputs.

	Some SDI connectors are permanently configured as inputs, others as outputs, but on some devices, they’re software-configurable.
	This means your application can instruct the device to reconfigure one of its SDI jacks from an input to an output (or vice-versa).
	-	To determine if a device has software-configurable SDI connectors, call ::NTV2DeviceHasBiDirectionalSDI.
	-	If a device has bi-directional SDI connectors, the ::NTV2DeviceGetNumVideoInputs and ::NTV2DeviceGetNumVideoOutputs will reflect
		the maximum possible number of inputs and outputs.
		-	For example, the \ref io4kquad has four bi-directional SDI jacks plus an additional monitor (output-only) jack,
			so for that device, ::NTV2DeviceGetNumVideoInputs returns 4 and ::NTV2DeviceGetNumVideoOutputs returns 5.
	-	To determine if an SDI connector is currently configured to transmit, call CNTV2Card::GetSDITransmitEnable.
	-	To change an SDI connector’s function to receive or transmit, call CNTV2Card::SetSDITransmitEnable.

	All SDI connectors on NTV2 devices can receive or transmit 1.5 Gbps signals, and almost all will handle 3Gbps.
	-	To determine if its SDI spigots can handle 6Gbps or 12Gbps, call ::NTV2DeviceCanDo12GSDI.

	@par	Analog Video Connectors

	Some older AJA devices have analog video connectors (remember the old RCA component-level jacks?).
	-	To determine the number of analog video inputs the device has, call ::NTV2DeviceGetNumAnalogVideoInputs.
	-	To determine the number of analog video outputs the device has, call ::NTV2DeviceGetNumAnalogVideoOutputs.

	@par	HDMI Connectors

	Many AJA devices have HDMI connectors, some for capture, most for playout.
	-	To determine the number of HDMI inputs the device has, call ::NTV2DeviceGetNumHDMIVideoInputs.
	-	To determine the number of HDMI outputs the device has, call ::NTV2DeviceGetNumHDMIVideoOutputs.
	-	HDMI capabilities depend on the physical HDMI hardware used on the device and the supporting firmware.
		To determine which HDMI hardware is present on the device, call ::NTV2DeviceGetHDMIVersion.
		(Note that this doesn’t return an HDMI protocol version — it’s strictly an unsigned integer that indicates
		which “generation” of HDMI hardware was used on the device.
	-	HDMI hardware capabilities chart:

	@image	html	hdmichart.png

	@par	Audio Connectors

	Some AJA devices have separate connectors for audio input and/or output, even analog audio on some older devices.
	-	To determine if the device is capable of analog audio input or output, call ::NTV2DeviceCanDoAnalogAudio.
	-	To determine how many AES inputs and/or outputs a device has, call ::NTV2DeviceGetNumAESAudioInputChannels
		and/or ::NTV2DeviceGetNumAESAudioOutputChannels, respectively.
	-	To determine how many analog audio inputs and/or outputs a device has, call ::NTV2DeviceGetNumAnalogAudioInputChannels
		and/or ::NTV2DeviceGetNumAnalogAudioOutputChannels, respectively.

	@par	Reference and LTC Connectors

	Most AJA devices have a single BNC connector that can be used for reference input or for analog LTC input.
	On other devices, there are separate reference and LTC input connectors. Some devices have output connectors
	for LTC or Reference.
	-	To determine the number of reference video inputs, call ::NTV2DeviceGetNumReferenceVideoInputs.
	-	To determine if the device can be configured to receive LTC on its reference port, call ::NTV2DeviceCanDoLTCInOnRefPort.
	-	To determine the number of LTC inputs, call ::NTV2DeviceGetNumLTCInputs.
	-	To determine the number of LTC outputs, call ::NTV2DeviceGetNumLTCOutputs.

	@par	Serial Ports (RS-422)

	Most AJA devices have a single RS-422 connector that can be used to control tape deck transports and for other purposes.
	-	To determine the number of serial ports on a device, call ::NTV2DeviceGetNumSerialPorts.
	-	To determine if the serial port is programmable (for baud rate, parity, etc.), call ::NTV2DeviceCanDoProgrammableRS422.
		-	To determine the current baud rate, call CNTV2Card::GetRS422BaudRate. To change the baud rate, call CNTV2Card::SetRS422BaudRate.
		-	To determine the current parity configuration, call CNTV2Card::GetRS422Parity. To change the baud rate, call CNTV2Card::SetRS422Parity.

	@image	html	rs422pinout400.png


	@subsection	commonelectricalchars		Common Electrical Characteristics

	Unless otherwise noted, physical and electrical characteristics of inputs and outputs -- SDI, HDMI, analog video, analog audio, reference,
	LTC, etc. -- are generally identical across all AJA devices.

	<b>SDI Input(s)</b>
	-	AC-coupled input terminated with 75 ohms to ground

	<b>SDI Output(s)</b>
	-	AC-coupled output terminated with 75 ohms to ground
	-	<b>Output Level:</b>  800 mV peak-to-peak +/- 10%, terminated into 75 ohms

	<b>Video Reference Input(s)</b>
	-	Analog video reference, NTSC, PAL, or tri-level sync
	-	Active loop-through, input terminated by 75 ohms to ground
	-	<b>Input level:</b>  0.5 Volts peak-to-peak to 2.0 Volts peak-to-peak

	<b>Analog LTC Input(s)</b>
	-	Designed to work with inverted or non-inverted inputs
	-	Input impedence 75Ω, coax or other single-ended connection is recommended
	-	There is no differential termination on these inputs, so a balanced connection may not be reliable
	-	Designed to meet SMPTE spec, 0.5V to 4.5Vp-p

	<b>HDMI Input, Output</b>
	-	Connector: Type-A (unless otherwise noted)

	<b>AES Input(s)</b>
	-	DC-coupled input terminated with 75 ohms to ground
	-	<b>Minimum input level:</b>  100 mV peak-to-peak

	<b>AES Output(s)</b>
	-	AC-coupled output terminated with 75 ohms to ground
	-	<b>Output level:</b>  1.55 Volts peak-to-peak, +/- 10%, terminated into 75 ohms

	<b>Analog Video Output(s)</b>
	-	12-bit precision DAC output
	-	<b>Luma Bandwidth:</b> 12.5 MHz (SD) or 30 MHz (HD)
	-	<b>Chroma Bandwidth:</b> 5.8 MHz (SD) or 13.75 MHz (HD)

	<b>Audio Output</b>
	-	<b>Connector:</b>  DB-25
	-	<b>Maximum Level, unclipped:</b>  +12dBu, +15dBu, +18dBu, +24dBu (selectable)


	@subsection	hardwarecharacteristics	Hardware Characteristics

	@par		PCI Interface

	All NTV2 devices utilize Peripheral Component Interconnect (PCI) or Peripheral Component Interconnect Express (PCIe) to communicate with the host
	computer system (or with other PCI/PCIe peers on the same host).

	@par		PCI Vendor ID

	All AJA NTV2 devices have the same PCI vendor ID.
	-	PCI vendor ID:  <b>0xF1D0</b>

	@par		Data Transfer

	Direct Memory Access (DMA) is the only supported method of moving data between host memory
	and the hardware. All NTV2 devices have at least one DMA engine.
	(Programmed Input/Output, a.k.a. PIO is no longer supported.)
	-	To determine the number of DMA engines for a device, call ::NTV2DeviceGetNumDMAEngines.

	@par		Device Frame Buffer

	All NTV2 devices have a fixed amount of Synchronous Dynamic Random Access Memory (SDRAM).
	The FPGA is the SDRAM controller, which controls the output of video (and audio and anc)
	from RAM, the input of video (and audio and anc) into RAM, the PCI interface to/from RAM,
	and RAM refresh.

	@par		Frame Buffer Layout

	The device’s SDRAM is partitioned into a number of equal-sized video <b>frames</b>. The video
	<b>frame size</b> is always a multiple of 8MB — i.e. 8MB, 16MB or 32MB. On older devices, it’s
	automatically set by the firmware based on ::NTV2VideoFormat, ::NTV2FrameBufferFormat and
	::NTV2VANCMode. This legacy behavior is retained in newer devices, but can be overridden
	programmatically.
	-	To determine if the ::NTV2Framesize can be changed programmatically,
		call ::NTV2DeviceSoftwareCanChangeFrameBufferSize.
	-	To determine the SDRAM that the device has for storing video and audio data,
		call ::NTV2DeviceGetActiveMemorySize.
	-	To determine the current ::NTV2Framesize for the device,
		call CNTV2Card::GetFrameBufferSize. The returned ::NTV2Framesize can be converted
		into a byte count using ::NTV2FramesizeToByteCount.
	-	To change (override) the current ::NTV2Framesize for the device,
		call CNTV2Card::SetFrameBufferSize.

	@image	html	hwref-fig1-sdramfblayout.png

	Video frames are indexed using a zero-based index number. The first byte of the first frame
	(frame zero) starts at the lowest SDRAM address, and subsequent frames are located at higher
	addresses from there, as a byte-multiple of the current ::NTV2Framesize. Obviously, larger
	rasters (e.g. ::NTV2_FG_1920x1080 versus ::NTV2_FG_720x486) and/or deeper frame buffer formats
	(e.g. ::NTV2_FBF_48BIT_RGB versus ::NTV2_FBF_8BIT_YCBCR) will necessarily result in half as many
	available frame buffers … while 4K/UHD frames will result in a fourth as many frames.
	-	To determine the minimum number of 8MB chunks to safely accommodate a given ::NTV2FrameGeometry
		and ::NTV2FrameBufferFormat, call ::Get8MBFrameSizeFactor.

	@warning	On multi-channel devices, changing a Frame Store’s ::NTV2FrameBufferFormat and/or
				::NTV2VideoFormat (and/or ::NTV2VANCMode) that results in a 8MB/16MB frame size
				change (or vice-versa) while another channel is ingesting or playing video will
				result in at least one bad frame of video in the stream once the device’s memory
				layout is changed. It can even cause the “start” and “end” frames being
				AutoCirculated to refer to frames that no longer exist on the device. To prevent
				this, call CNTV2Card::SetFrameBufferSize to pre-configure the device to use the
				largest expected ::NTV2Framesize when your application starts.

	Video data in the device frame buffer is always stored full-frame. Interlaced video is
	always stored in the frame buffer with the first line of Field 1 (F1L1) at the top of the
	buffer, followed by the first line of Field 2 (F2L1), then F1L2, F2L2, F1L3, F2L3, etc.,
	alternating to the end of the frame. An exception to this is NTSC SD 525i, which starts
	with Field 2 at the top of the buffer (F2L1, F1L1, F2L2, F1L2, etc.).

	@note	A very <i>very</i> long time ago, AJA had devices that stored all of F1’s lines in
			the top half of the buffer, and all of F2’s lines in the bottom half. These devices
			and buffer formats are no longer supported.



	<hr size="50px">
	@section	videooperation		Video System Operation

	This section describes how the Video System operates.

	@subsection	vidop-fs		Frame Store Operation

	A <b>Frame Store</b> is a device widget implemented in FPGA firmware that uses several
	registers to monitor and control its principal properties:
	-	<b>Enable/Disable State</b> — When <b>Disabled</b>, the widget will not access SDRAM.
		Call CNTV2Card::IsChannelEnabled to determine if a Frame Store is enabled or not.
		Calling CNTV2Card::EnableChannel or CNTV2Card::DisableChannel will change it.
		Note that AutoCirculate sets this for you, but won’t “un-set” it.
	-	<b>Mode</b> — This correlates to the ::NTV2Mode enumeration in the SDK.
		In ::NTV2_MODE_DISPLAY, it will <b>read</b> video data for playout from SDRAM;
		in ::NTV2_MODE_CAPTURE, it will <b>write</b> video data into SDRAM. Call CNTV2Card::GetMode
		to obtain the Frame Store’s current mode;  calling CNTV2Card::SetMode will set it.
		Note that AutoCirculate sets this for you, but doesn’t “un-set” it.
	-	<b>Frame Buffer Format</b> — This coincides with the ::NTV2FrameBufferFormat enumeration
		in the SDK. Call CNTV2Card::GetFrameBufferFormat to determine the current format;
		calling CNTV2Card::SetFrameBufferFormat will change it. See \ref devicefbformats for details.
		AutoCirculate users must set this.
	-	<b>Video Format</b> — This correlates to the ::NTV2VideoFormat enumeration in the SDK,
		and implies a ::NTV2FrameGeometry, ::NTV2Standard and ::NTV2FrameRate.
		Call CNTV2Card::GetVideoFormat to determine the current format;
		call CNTV2Card::SetVideoFormat to change it.
		AutoCirculate users must set this.
	-	<b>Input Frame</b> — This is a zero-based index number that identifies the specific Frame
		Buffer in SDRAM that will be continually written with video frame data <b>if</b>…
		-	the Frame Store is Enabled;
		-	its Mode is Capture;
		-	and a signal is routed to its input crosspoint(s).
	
		Call CNTV2Card::GetInputFrame to determine the current <b>Input Frame</b> buffer number.
		Call CNTV2Card::SetInputFrame to change it.
		Note that AutoCirculate manages this for you.
	-	<b>Output Frame</b> — This is a zero-based index number that identifies the specific Frame
		Buffer in SDRAM that will continuously be read from <b>if</b>…
		-	the Frame Store is Enabled;
		-	its Mode is Display. (The output video can be monitored <b>if</b> the Frame Store’s
			output signal is routed to a video output widget, and a monitor is connected to that
			output connector.)
		
		Call CNTV2Card::GetOutputFrame to determine the current <b>Output Frame</b> buffer number.
		Call CNTV2Card::SetOutputFrame to change it.
		Note that AutoCirculate manages this for you.
	-	<b>VANC Mode</b> — The ::NTV2VANCMode setting determines if a “tall” or “taller” frame geometry
		is in effect. The ::NTV2_VANCMODE_TALL geometry incorporates several extra lines of video that
		precede the first visible line in the raster into the Frame Store’s frame buffer memory.
		::NTV2_VANCMODE_TALLER was added to firmware when it was found that additional useful ancillary
		data was found on additional lines ahead of the first line in ::NTV2_VANCMODE_TALL mode.
		Call CNTV2Card::GetVANCMode to determine the current <b>VANC Mode</b> setting.
		Call CNTV2Card::SetVANCMode to change it.
	-	<b>VANC Data Shift Mode</b> — The ::NTV2VANCDataShiftMode determines if the firmware will automatically
		shift incoming or outgoing video data in the VANC lines (that precede the first visible line)
		by 2 bits, effectively discarding the least-significant two bits of the 10-bit Y/C values.
		When used with an ::NTV2_FBF_8BIT_YCBCR frame buffer format, this makes it very easy to parse
		ancillary data packets in the frame buffer.
		Call CNTV2Card::GetVANCShiftMode to determine the current <b>VANC Data Shift Mode</b> setting.
		Call CNTV2Card::SetVANCShiftMode to change it.
	-	<b>Frame Buffer Orientation</b> — The ::NTV2FBOrientation (a.k.a. ::NTV2FrameBufferOrientation
		a.k.a. ::NTV2VideoFrameBufferOrientation) determines the direction that firmware will write or
		read video lines into or out of SDRAM, either normal ::NTV2_FRAMEBUFFER_ORIENTATION_TOPDOWN,
		or ::NTV2_FRAMEBUFFER_ORIENTATION_BOTTOMUP (reverse). 
		Call CNTV2Card::GetFrameBufferOrientation to determine the current <b>Frame Buffer Orientation</b>
		setting. Call CNTV2Card::SetFrameBufferOrientation to change it.

	Some AJA devices have only one Frame Store, so that device is limited to Capturing or Playing
	one single stream of video at a time.

	Some older AJA devices with two Frame Stores dedicate the first to ::NTV2_MODE_CAPTURE and the other
	to ::NTV2_MODE_DISPLAY.

	@note	In NTV2 parlance, the terms <b>Channel</b> and <b>Frame Store</b> are often used interchangeably.

	Multi-channel devices can simultaneously and independently ingest or playout video, and have
	independent control of which SDRAM frame(s) will be read or writen with video.

	In the SDK, Frame Stores are identified by an ::NTV2Channel enumeration and sometimes by a zero-based
	unsigned integer value, where zero corresponds to ::NTV2_CHANNEL1.
	-	Call ::NTV2DeviceGetNumFrameStores to determine the number of Frame Stores on a given device.
		This will tell you how many Channels are available for simultaneous Capture and/or Playout streams.


	@subsection	independentmode		Multi-Format / “Independent” Mode

	<b>Multi-Format Mode</b>, also known as “Independent” mode, is a device capability in which it can
	simultaneously operate more than one stream, with each having a different video format.
	Devices having this capability that are in this mode are able to use a different ::NTV2VideoFormat
	on each Frame Store.

	This differs from prior device capability. For example, assuming there was sufficient DMA and processor
	bandwidth on the host, the \ref corvid24 could simultaneously ingest two video streams, and playout
	another two video streams — but all four streams must have the identical ::NTV2VideoFormat.

	In <b>Multi-Format Mode</b>, for example, assuming sufficient PCIe and host processor bandwidth,
	the \ref corvid44 could simultaneously ingest ::NTV2_FORMAT_720p_5000 and ::NTV2_FORMAT_525_5994 while
	playing ::NTV2_FORMAT_1080p_2997 and ::NTV2_FORMAT_720p_5994.

	The relevant SDK calls:
	-	Call ::NTV2DeviceCanDoMultiFormat to determine if a device is capable of simultaneously streaming
		multiple, different video formats.
	-	Call CNTV2Card::GetMultiFormatMode to find out if the device is currently operating in Multi-Format
		Mode or not.
	-	Call CNTV2Card::SetMultiFormatMode to change the mode.

	@note	In <b>Multi-Format Mode</b>, because NTV2 devices only have one hardware clock for driving the
			outputs, all playout video formats must be in the same clock family.
			Call ::IsMultiFormatCompatible(const NTV2VideoFormat, const NTV2VideoFormat) to find out if two
			video formats are multi-format compatible.
			Call ::IsMultiFormatCompatible(const NTV2FrameRate, const NTV2FrameRate) to see if two frame
			rates are multi-format compatible.
			Call ::GetFrameRateFamily to determine the frame-rate “family” that a given ::NTV2FrameRate
			belongs to. See \ref deviceclockingandsync for more details (below).


	@subsection	vidop-fbaccess		Frame Buffer Access

	Data can be transferred to or from the device at any time using the DMA API in the CNTV2Card class.

	Remember that <b>the host computer always has access to frame memory</b>. Therefore
	it’s important to synchronize or gate transfers to/from the host using the vertical blanking
	interrupt (e.g., CNTV2Card::WaitForOutputVerticalInterrupt, CNTV2Card::WaitForOutputFieldID,
	CNTV2Card::WaitForInputVerticalInterrupt, CNTV2Card::WaitForInputFieldID, etc.).

	The device’s current line counter could also be used (i.e., by monitoring the ::kRegLineCount register
	via CNTV2Card::ReadLineCount), but that value reflects the read/write line position of Frame Store 1.
	Other Frame Stores do not have Line Counters.

	There are several DMA API functions for transferring data between host memory and device SDRAM.
	They are <b>frame-centric</b> in that they all require a zero-based frame number to calculate
	where to start reading or writing in device SDRAM. The actual byte offset into device SDRAM
	depends on the device’s current <b>Frame Size</b> — whether 8MB, 16MB, or larger.

	-	Call CNTV2Card::DMAReadFrame or CNTV2Card::DMAWriteFrame to transfer frame data from or to
		device SDRAM (respectively).
	-	<b>Frame Number</b> — If non-zero, it will index into device SDRAM by ::NTV2Framesize frames.
		See the <b>Frame Buffer Layout</b> discussion in the \ref hardwarecharacteristics
		section for more information.
	-	<b>Byte Count:</b>
		-	Should be even, or evenly divisible by 4, or ideally a power of two.
		-	Small transfers can sometimes be problematic for certain DMA engine firmware in combination
			with certain host hardware and OS platforms.  To avoid this, AJA recommends transferring at
			least 4096 bytes of data. Try smaller values if necessary, but test thoroughly with the
			devices and hardware you intend to support.
		-	It can be larger than a frame. For example, if the device frame size is 8MB, and the
			requested byte count is 16MB, two frames will be transferred.
	-	CNTV2Card::DMARead and CNTV2Card::DMAWrite are similar, but also accept a <b>Byte Offset</b>,
		which…
		-	Should be even, or evenly divisible by 4, or ideally a power of two.
		-	<b>Hint:</b> All device SDRAM can be accessed by using a zero <b>Frame Number</b> and
			using any offset value needed (up to 4GB minus the <b>Byte Count</b>).

	@warning	Calling CNTV2Card::DMAWriteFrame at a fraction of frame time <i>after</i>
				the VBI to write the same frame on the device that’s being read for the currently-playing
				video frame will likely look torn or distorted.
				Likewise for the opposite — i.e., calling CNTV2Card::DMAReadFrame at a
				fraction of frame time after or before the VBI to read the same frame being written
				by the Frame Store from the currently incoming video frame would result in some lines
				having pixel data from the new, incoming frame, while the remaining lines would contain
				old pixel data.

	@note	DMA transfer speeds may be affected by the amount of video data being accessed by
			the device to transmit video. If a channel is in display mode, it is always playing
			video, and therefore reading from SDRAM, consuming SDRAM bandwidth… the amount consumed
			determined by the amount of data being read from frame memory… which depends on Frame
			Buffer Format and Frame Geometry. <b>In some cases, DMA speeds can be increased by
			disabling unused channels</b> (see CNTV2Card::DisableChannel). Disabling unused channels
			is especially useful when using larger video & frame buffer formats, which use significant
			SDRAM bandwidth to read frame data for playout. In addition to the fact that more data is
			moved in, say, 48-bit RGB (than YUV8), the transfer of that data may also proceed at a
			slightly slower rate.

	@warning	Accessing memory addresses that are beyond the end of device SDRAM is not recommended,
				and will result in unexpected behavior — e.g. wrapping around and continuing from the
				start of device SDRAM.


	@subsection	deviceclockingandsync		Device Clocking and Synchronization

	All SDI outputs on NTV2 devices are synchronized (clocked) to one of these three different
	clock sources:
	-	the device’s on-board crystal oscillator (a.k.a. “free run”);
	-	an SDI input (unavailable on playout-only devices);
	-	an external timing reference signal (devices with external reference inputs only).

	The SDK’s CNTV2Card::SetReference function is used to specify which clock source should
	be used to generate timing for the device’s outputs. When CNTV2Card::SetReference is called
	with ::NTV2_REFERENCE_INPUT1, the device’s outputs will be locked to the same timebase as
	that of input channel 1. Note that the actual output will be delayed a couple of lines due
	to propagation delays through the device’s circuitry, but the important point is that the
	phase relationship between the input and the output will be fixed and will not drift. This
	form of output clocking is best suited to end-to-end (E-E) routing, where an input is routed
	to an output, directly, or indirectly (e.g., through a Mixer/Keyer) without any mediation
	through a pair of Frame Stores.

	However, if two inputs are feeding the device, it’s probably impossible to lock to both
	sources. Unless the sources are synced to a common timebase (often called “house reference”),
	then the two signals will drift over time with respect to each other. One channel may just
	be starting a new frame, while the other is already half way through its frame. Since a
	client application can’t lock to both signals at the same time, ::NTV2_REFERENCE_FREERUN
	should be used, to clock the outputs from the device’s own internal clock source. Note that
	even setting “free run” isn’t technically necessary — the application would run just as
	well locked to an input, with the only difference being when the signals would actually
	come out of the BNC connectors.

	If the device’s output(s) must have a given timing (e.g., to feed a switcher), then
	applications can pass ::NTV2_REFERENCE_EXTERNAL to CNTV2Card::SetReference, which will
	lock the device to an analog or tri-level sync signal connected to the device’s external
	reference input. You can determine the video format of the signal being applied to the
	reference input by calling CNTV2Card::GetReferenceVideoFormat. Note that even when
	configured to sync its outputs to ::NTV2_REFERENCE_EXTERNAL, the device output will
	internally revert to Free-Run if the reference signal disappears or is incompatible with
	the output video format.

	@note	AJA recommends setting the device reference to ::NTV2_REFERENCE_FREERUN when
			there is no signal at the external reference connector.


	@subsection	fieldframeinterrupts	Field/Frame Interrupts

	Many device hardware registers are updated on the video frame sync (i.e. the VBI associated with
	the start of a new frame). For example, CNTV2Card::SetInputFrame is called by the client
	application to instruct the device’s Frame Store to write the next video frame that arrives
	into a specific frame buffer number in device memory. The function call immediately changes
	the Frame Store’s input frame register, but internally, the device firmware ensures that the
	Frame Store uses the new frame number value at the next “Field0” (first field in time) sync pulse.
	To avoid a race condition, though, the client application needs to wait for (synchronize with)
	the VBI, which gives it an entire frame time to update hardware registers and configure the
	device widget settings that are required for the next frame to be processed.

	For interlaced video, where the frame is transmitted as two fields, each field contains every
	other line of the frame. For HD video, the first field in time contains the first active line
	of the frame (i.e. the “top field” or “field0”), the second field contains the last active
	line of the frame (i.e. the “bottom field” or “field1”). Each field starts with a video sync —
	however, the hardware registers are only updated at the “field0” (first field in time) sync.
	Each of the syncs (“field0” and “field1”) produces an interrupt to the driver,
	but CNTV2Card::WaitForInputFieldID (or CNTV2Card::WaitForOutputFieldID) check a hardware register
	and return only when “field0” is detected (not “field1”). For progressive video, all syncs are
	flagged by the hardware as “field0” syncs, so registers are updated for the next frame and the
	CNTV2Card::WaitForInputFieldID (or CNTV2Card::WaitForOutputFieldID) work as expected.

	To wait for an event (such as a VBI) from a particular Frame Store, your application should
	subscribe to it by calling CNTV2Card::SubscribeInputVerticalEvent or CNTV2Card::SubscribeOutputVerticalEvent.

	Once subscribed, to efficiently wait for an input vertical interrupt, call CNTV2Card::WaitForInputFieldID or
	CNTV2Card::WaitForInputVerticalInterrupt, referencing the Frame Store that’s configured for capture,
	and that’s routed (directly or indirectly) from an input that has a valid video signal.

	To efficiently wait for an output vertical interrupt, call CNTV2Card::WaitForOutputFieldID or
	CNTV2Card::WaitForOutputVerticalInterrupt, referencing the Frame Store that’s configured for playout.

	You can inquire as to the number of input or output vertical events that have successfully been waited
	on and fired by calling CNTV2Card::GetInputVerticalEventCount or CNTV2Card::GetOutputVerticalEventCount.
	By calling either of these methods before and after calling the “wait for input/output” function, you
	can determine if indeed the interrupt event actually triggered. Call CNTV2Card::SetInputVerticalEventCount
	or CNTV2Card::SetOutputVerticalEventCount to reset the tally counter.

	Normally it’s not necessary to explicitly unsubscribe the CNTV2Card instance’s event subscriptions, as
	its destructor automatically calls CNTV2Card::Close, but it’s considered a good practice.

	@note	On <b>Windows</b>, the AJA NTV2 driver supplies a finite number of event subscription handles
			to client applications, which get consumed when subscribed (via CNTV2Card::SubscribeInputVerticalEvent,
			CNTV2Card::SubscribeOutputVerticalEvent, CNTV2Card::SubscribeEvent). They’re made available
			again to other clients when unsubscribed (via CNTV2Card::UnsubscribeInputVerticalEvent,
			CNTV2Card::UnsubscribeOutputVerticalEvent, CNTV2Card::UnsubscribeEvent), and automatically when
			the CNTV2Card object is closed or destroyed (via CNTV2Card::Close). However, abnormal program
			terminations, crashes, or force-quitting from a debugger will prevent this handle clean-up,
			which can result in their exhaustion. The only recovery at this point is to close all running
			NTV2 client applications (including the AJA Service, if the “retail” software is installed and
			running), then manually disabling and re-enabling the AJA driver. (Of course you can always
			recover by restarting the machine.)

	@subsection	vidop-fbconflict	When Frame Stores Access the Same Frame Buffer Memory

	Note that it’s possible (and quite easy) to have two or more Frame Stores accessing the same
	frame buffer memory.

	Here’s an example where this would be really bad:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signals at SDI Inputs 1 and 2
			//	(same video format, different content)...
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.SetInputFrame(NTV2_CHANNEL1, 0);	//	Write FrameStore 1 video into frame buffer 0

			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_CAPTURE);	//	Set FrameStore 2 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL2, false);	//	Set SDI connector 2 to capture
			device.Connect(NTV2_XptFrameBuffer2Input, NTV2_XptSDIIn2);	//	Connect SDI In 2 to FrameStore 2
			device.SetInputFrame(NTV2_CHANNEL2, 0);	//	Write FrameStore 2 video into frame buffer 0
		}
	@endcode
	In this case, there are two video signals fighting to write video rasters into the same frame memory on the device.
	If this frame were to be transferred to host memory, the image would look torn, a bad mixture of frames from SDI inputs 1 and 2.

	On the other hand, Frame Stores sharing the same frame buffer memory can be beneficial, for example, as a <b>Frame Synchronizer</b>.
	Here’s an example of how to synchronize an SDI signal with the AJA device’s free-running output clock:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has a valid video signal at SDI Input 1:
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.SetInputFrame(NTV2_CHANNEL1, 0);	//	Write FrameStore 1 video into frame buffer 0

			device.SetReference(NTV2_REFERENCE_FREERUN);	//	Free run the outputs
			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_DISPLAY);	//	Set FrameStore 2 to playout mode
			device.SetOutputFrame(NTV2_CHANNEL2, 0);	//	Read FrameStore 2 video from frame buffer 0
			device.SetSDITransmitEnable(NTV2_CHANNEL3, true);	//	Set SDI connector 3 to output
			device.Connect(NTV2_XptSDIOut3Input, NTV2_XptFrameBuffer2YUV);	//	Connect FrameStore 2’s output to SDI Out 3
		}
	@endcode

	When AutoCirculate is used, AutoCirculate manages the Frame Store’s InputFrame register (capture) or OutputFrame register (playout),
	repeatedly circulating it from the <b>Start Frame</b> to the <b>End Frame</b> (e.g., 0 thu 6).
	Another Frame Store can very easily write into any of the frames involved in another Frame Store’s AutoCirculate frame range.
	For example:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signals at SDI Inputs 1 and 2
			//	(same video format, different content)...
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.AutoCirculateInitForInput(NTV2_CHANNEL1, 0, NTV2_AUDIOSYSTEM_INVALID, 0, 1, 0, 6);	//	AutoCirculate capture into FBs 0/1/2/3/4/5/6
			device.AutoCirculateStart(NTV2_CHANNEL1);	//	Start AutoCirculate (assume another thread calls AutoCirculateTransfer)

			//	UH-OH:  This code block will cause 1 of every 7 frames captured via AutoCirculate
			//			on NTV2_CHANNEL1 to be corrupted by video from SDI Input 2...
			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_CAPTURE);	//	Set FrameStore 2 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL2, false);	//	Set SDI connector 2 to capture
			device.Connect(NTV2_XptFrameBuffer2Input, NTV2_XptSDIIn2);	//	Connect SDI In 2 to FrameStore 2
			device.SetInputFrame(NTV2_CHANNEL2, 3);	//	Write FrameStore 2 video into frame buffer 3
		}
	@endcode


	<hr size="50px">
	@subsection	vidop-csc		Color Space Converter Operation

	A <b>Color Space Converter</b> (a.k.a. <b>CSC</b>) is a device widget implemented in FPGA firmware that converts YCbCr values
	into RGB[A] values, or vice-versa. It uses several registers to configure its conversion properties.

	-	Generally, there is one CSC for every SDI connector. ::NTV2DeviceGetNumCSCs can be used to determine the number
		of CSCs on a given device, which should match ::NTV2DeviceGetNumVideoInputs or ::NTV2DeviceGetNumVideoOutputs (whichever is larger).
	-	CSC widgets are identified by ::NTV2_WgtCSC1, ::NTV2_WgtCSC2, etc.,
		but are normally identified in SDK calls by an ::NTV2Channel value that represents a zero-based index number.
	-	Each CSC has two inputs:
		-	<b>Video Input</b>:  This input should be routed to another widget’s output that produces…
			-	YCbCr video — in which case the CSC will produce valid RGB[A] data at its <b>RGB Video</b> output.
			-	RGB[A] video — in which case the CSC will produce valid YCbCr video at its <b>YUV Video</b> output,
				and alpha channel video at its <b>Key YUV</b> output.
		-	<b>Key Input</b>:  This supplies alpha channel data for the CSC’s <b>RGB Video</b> output. When used,
			it should always be sourced with YCbCr video (never RGB).
	-	Each CSC has 3 outputs:
		-	<b>YUV Video</b>:  This produces valid YCbCr video data only when the CSC’s <b>Video Input</b> is receiving RGB[A] video.
		-	<b>RGB Video</b>: This produces valid RGB[A] video data only when the CSC’s <b>Video Input</b> is receiving YCbCr video.
		-	<b>Key YUV</b>:  This produces valid YCbCr key data only when the CSC’s <b>Video Input</b> is receiving RGB[A] video.
	-	Routing instructions are in the \ref widget_csc section in the \ref ntv2signalrouting section.
	-	The CSC’s conversion coefficients are adjusted based on “SMPTE” versus “Full” range.
		-	The conversion range is represented in the SDK as the ::NTV2RGBBlackRange or ::NTV2_CSC_RGB_Range data types.
		-	Full range is represented by the ::NTV2_CSC_RGB_RANGE_FULL or ::NTV2_RGBBLACKRANGE_0_0x3FF enumerations.
			-	8-bit Full Range has 256 possible values (0 thru 255)
			-	10-bit Full Range has 1024 possible values (0 thru 1023).
		-	SMPTE range is represented by the ::NTV2_CSC_RGB_RANGE_SMPTE or ::NTV2_RGBBLACKRANGE_0x40_0x3C0 enumerations.
			-	8-bit SMPTE-range has 220 possible values (16 thru 235).
			-	10-bit SMPTE-range has 877 possible values (64 thru 940).
		-	Call CNTV2Card::GetColorSpaceRGBBlackRange to determine the current range setting for a CSC.
		-	Call CNTV2Card::SetColorSpaceRGBBlackRange to change a CSC’s range setting.
	-	The CSC’s conversion matrix can be set to “Rec. 601” (SD) or “Rec. 709” (HD).
		-	The conversion matrix type is represented in the SDK by the ::NTV2ColorSpaceMatrixType data type.
		-	Rec. 601 is represented by the ::NTV2_Rec601Matrix enumeration constant.
		-	Rec. 709 is represented by the ::NTV2_Rec709Matrix enumeration constant.
		-	Call CNTV2Card::GetColorSpaceMatrixSelect to determine the current matrix selection for a CSC.
		-	Call CNTV2Card::SetColorSpaceMatrixSelect to change a CSC’s matrix selection.

	@par	YCbCr to RGB Conversion

	-	When the CSC’s <b>Video Input</b> is connected to a YUV video source, it will convert and provide RGB data on
		its “RGB” output crosspoint.
	-	In addition to the YCbCr-to-RGB value conversion, the CSC also performs the necessary 4:2:2 up-sampling to fill the
		“missing” pixels in the outgoing RGB raster.
	-	The CSC will produce an <i>opaque</i> alpha channel by default.
	-	It can produce alpha channel data from YCbCr video supplied to its <b>Key Input</b> (using just the luma channel) —
		provided it’s configured to do so:
		-	Call CNTV2Card::GetColorSpaceMakeAlphaFromKey to determine if the CSC will use its <b>Key Input</b> to generate
			alpha channel data.
		-	Call CNTV2Card::SetColorSpaceMakeAlphaFromKey to enable or disable the setting.
		-	When “Make Alpha From Key” is enabled, call CNTV2Card::GetColorSpaceVideoKeySyncFail to query if the CSC’s
			<b>Key Input</b> is synchronized with its <b>Video Input</b>. Sync failure will occur if the Key and Video
			signals have unrelated frame rates, or are significantly out of phase with each other.

	The conversion formulæ:
	@code{.cpp}
		// Full-range 8-bit “Rec 601” (SD) conversion:
		R = 1.164384 * y  +  0.000000 * cb  +  1.596027 * cr;
		G = 1.164384 * y  -  0.391762 * cb  -  0.812968 * cr;
		B = 1.164384 * y  +  2.017232 * cb  +  0.000000 * cr;

		// SMPTE-range 8-bit “Rec 601” (SD) conversion:
		R = 1.000000 * y  +  0.000000 * cb  +  1.370705 * cr;
		R = 1.000000 * y  -  0.336455 * cb  -  0.698196 * cr;
		R = 1.000000 * y  +  1.732446 * cb  +  0.000000 * cr;

		// Full-range 10-bit “Rec 601” (SD) conversion:
		R = 1.167808 * y  +  0.000000 * cb  +  1.600721 * cr;
		G = 1.167808 * y  -  0.392915 * cb  -  0.815359 * cr;
		B = 1.167808 * y  +  2.023165 * cb  +  0.000000 * cr;

		// SMPTE-range 10-bit “Rec 601” (SD) conversion:
		R = 1.0000008 * y  +  0.000000 * cb  +  1.370705 * cr;
		G = 1.0000008 * y  -  0.336455 * cb  -  0.698196 * cr;
		B = 1.0000008 * y  +  1.732446 * cb  +  0.000000 * cr;

		// Full-range 10-bit “Rec 709” (HD) conversion:
		R = 1.167808 * y  +  0.000000 * cb  +  1.798014 * cr;
		G = 1.167808 * y  -  0.213876 * cb  -  0.534477 * cr;
		B = 1.167808 * y  +  2.118615 * cb  +  0.000000 * cr;

		// SMPTE-range 10-bit “Rec 709” (HD) conversion:
		R = 1.000000 * y  +  0.000000 * cb  +  1.539648 * cr;
		G = 1.000000 * y  -  0.183143 * cb  -  0.457675 * cr;
		B = 1.000000 * y  +  1.814180 * cb  +  0.000000 * cr;
	@endcode

	@note	The 8-bit and 10-bit coefficients are NOT the same, since the RGB 10-bit white point (1023)
			is not simply 4 × the 8-bit RGB white point (255).

	@par	RGB to YCbCr Conversion

	-	When the CSC’s <b>Video Input</b> is fed RGB[A] video, it will convert and provide YUV data on
		its “Video” and “Key” output crosspoints.
	-	In addition to the RGB-to-YCbCr value conversion, it also performs the necessary 4:2:2 down-sampling
		(implemented as a low-pass filter) for the fewer samples in the outgoing YUV raster.
	-	The <b>Key Output</b> luma channel data is scaled appropriately from the incoming alpha channel data.
		Its outgoing Cb and Cr component values are fixed at <tt>0x200</tt>.

	The conversion formulæ:
	@code{.cpp}
		// Full-range 10-bit “Rec 601” (SD) conversion:
		Y  =  0.25604 * r  +  0.50265 * g  +  0.09762 * b;
		Cb = -0.14779 * r  -  0.29014 * g  +  0.43793 * b;
		Cr =  0.43793 * r  -  0.36671 * g  -  0.07122 * b;

		// SMPTE-range 10-bit “Rec 601” (SD) conversion:
		Y  =  0.29900 * r  +  0.58700 * g  +  0.11400 * b;
		Cb = -0.17259 * r  -  0.33883 * g  +  0.51142 * b;
		Cr =  0.51142 * r  -  0.42825 * g  -  0.08317 * b;

		// Full-range 10-bit “Rec 709” (HD) conversion:
		Y  =  0.18205 * r  +  0.61243 * g  +  0.06183 * b;
		Cb = -0.10035 * r  -  0.33758 * g  +  0.43793 * b;
		Cr =  0.43793 * r  -  0.39777 * g  -  0.04016 * b;

		// SMPTE-range 10-bit “Rec 709” (HD) conversion:
		Y  =  0.21260 * r  +  0.71520 * g  +  0.07220 * b;
		Cb = -0.11719 * r  -  0.39423 * g  +  0.51142 * b;
		Cr =  0.51142 * r  -  0.46452 * g  -  0.04689 * b;
	@endcode

	@par	Enhanced CSCs

	Some AJA devices support “enhanced” CSC firmware that is used to override the default Rec 601 and Rec 709 conversion
	offsets and coefficients.  Call ::NTV2DeviceCanDoEnhancedCSC to determine if the device has the enhanced CSC firmware.


	<hr size="50px">
	@subsection	vidop-mixerkeyer		Mixer/Keyer Operation

	A <b>Mixer/Keyer</b> is a device widget implemented in FPGA firmware that mixes or “keys” YCbCr video.
	It uses a pair of registers for configuring its mixing/keying properties.

	@note	Mixer/Keyer widgets can only process YCbCr video — not RGB[A].

	-	Generally, there is one mixer/keyer for every 2 Frame Stores and/or SDI Inputs (or SDI Outputs).
		Call ::NTV2DeviceGetNumMixers to obtain the number of Mixer/Keyer widgets that are available.
	-	Mixer/Keyer widgets are identified by ::NTV2_WgtMixer1, ::NTV2_WgtMixer2, …,
		but are normally identified in SDK calls by a zero-based, unsigned 16-bit index number.
	-	Each Mixer/Keyer has two outputs — <b>Video</b> and <b>Key</b> — that contain the mixed/keyed output video.
	-	Each Mixer/Keyer has four inputs:
		-	two <b>Foreground</b> inputs — <b>Video</b> and <b>Key</b> — and…
		-	two <b>Background</b> inputs — <b>Video</b> and <b>Key</b>.
		-	<b>Key Input</b>s only utilize Y-channel data — the Cb and Cr components are ignored.
		-	<b>IMPORTANT:</b> The Mixer’s foreground and background inputs must be closely synchronized
			or the Mixer won’t be able to mix them. If the Mixer is unlocked, its outputs will send unclocked
			(garbage) video.
			-	Call CNTV2Card::GetMixerSyncStatus to determine if the Mixer is locked to both of its inputs,
				and therefore if its output is valid.
	-	Each Mixer/Keyer has the following configuration parameters:
		-	::NTV2MixerKeyerMode — Primary operating mode:
			-	Use ::NTV2MIXERMODE_FOREGROUND_ON to exclusively pass the <b>foreground</b> video and key to the Mixer output.
			-	Use ::NTV2MIXERMODE_FOREGROUND_OFF to exclusively pass the <b>background</b> video and key to the Mixer output.
			-	Use ::NTV2MIXERMODE_MIX to overlay the foreground video on top of the background video. Foreground or background
				<b>Flat Matte</b> (see below), if enabled, will be mixed instead of its respective input raster.
			-	Call CNTV2Card::GetMixerMode to determine the Mixer’s current mode.
			-	Call CNTV2Card::SetMixerMode to change its mode.
		-	::NTV2MixerKeyerInputControl — input control mode, one for foreground input, one for background input:
			-	::NTV2MIXERINPUTCONTROL_FULLRASTER ignores the input key.
			-	::NTV2MIXERINPUTCONTROL_SHAPED uses the input key as a mask.
			-	Call CNTV2Card::GetMixerFGInputControl to discover the foreground input’s current control value.
			-	Call CNTV2Card::SetMixerFGInputControl to change the foreground input’s control value.
			-	Call CNTV2Card::GetMixerBGInputControl to discover the background input’s current control value.
			-	Call CNTV2Card::SetMixerBGInputControl to change the background input’s control value.
		-	<b>Mix Coefficient</b> — an unsigned, 16-bit integer that determines the transparency of the foreground mask/key.
			-	Call CNTV2Card::GetMixerCoefficient to determine the current mix coefficient value.
			-	Call CNTV2Card::SetMixerCoefficient to change its value.
		-	<b>Output VANC Source</b> — The Mixer’s output video VANC can be sourced from the foreground
			or background input video.
			-	Call CNTV2Card::GetMixerVancOutputFromForeground to determine if the output VANC is currently
				being sourced from the foreground video input.
			-	Call CNTV2Card::SetMixerVancOutputFromForeground to change the output VANC source.
		-	<b>Flat Matte</b> — The Mixer’s foreground and/or background raster can be set to a flat matte of any
			10-bit YCbCr color. This matte will override any respective video input to the Mixer.
				-	Call CNTV2Card::GetMixerFGMatteEnabled to determine if the foreground matte is enabled or not.
				-	Call CNTV2Card::SetMixerFGMatteEnabled to enable or disable using the foreground matte.
				-	Call CNTV2Card::GetMixerBGMatteEnabled to determine if the background matte is enabled or not.
				-	Call CNTV2Card::SetMixerBGMatteEnabled to enable or disable using the background matte.
				-	Do not enable <b>Flat Matte</b> on both foreground and background — use one or the other, or neither.
				-	Call CNTV2Card::GetMixerMatteColor to determine the current matte color.
				-	Call CNTV2Card::SetMixerMatteColor to change the matte color.
				-	Note that to retain sync and enable its video output, the Mixer still requires a foreground
					video source if background matte is enabled, or a background video source if foreground
					matte is enabled.
	-	For information on how to route signals to and from the Mixer, see \ref widget_mixkey.



	<hr size="50px">
	@section	audiooperation		Audio System Operation

	NTV2-compatible devices have a minimum of one <b>Audio System</b> (sometimes referred to as an <b>Audio Engine</b>).
	Call ::NTV2DeviceGetNumAudioSystems to determine the number of Audio Systems on a device.

	An <b>Audio System</b> is implemented in FPGA firmware using several hardware registers, which together perform the following functions:
	-	If it has any SDI, HDMI, analog, or AES inputs (see ::NTV2DeviceCanDoCapture):
		-	It continually de-embeds 20/24-bit AES audio samples. For SDI inputs, these will come from SMPTE 272M/299M HANC packets
			detected in the SDI input stream.
		-	If its capture side is running, it will write the de-embedded audio samples into its input audio buffer in device SDRAM.
		-	The audio samples can always be piped through a FIFO to source an <b>Audio System</b>’s output audio embedder for
			“loopback” play-through.
	-	If it has an SDI output (see ::NTV2DeviceCanDoPlayback):
		-	Unless its embedder is disabled, it will continually embed 20/24-bit AES audio samples into SMPTE 272M/292M HANC packets
			into its SDI output stream.
		-	When its playout side is running, it will read from its output audio buffer in device SDRAM the audio samples to be embedded.
		-	When its playout side is not running…
			-	If configured for “loopback” play-through, it obtains audio samples from an <b>Audio System</b>’s input audio de-embedder.
			-	It will otherwise embed silence (audio packets that contain all-zero sample values).

	Each <b>Audio System</b> can accommodate at least 8 channels of audio.
	Call ::NTV2DeviceGetMaxAudioChannels to determine the maximum number of audio channels that a device’s <b>Audio Systems</b> can handle.
	Call CNTV2Card::GetNumberAudioChannels to determine how many audio channels a device <b>Audio System</b> is currently configured for.
	Modern AJA devices will accommodate up to 16 channels. Older AJA devices defaulted to 6 channels at power-up — these should be
	configured to use 8 channels.
	Call CNTV2Card::SetNumberAudioChannels to change the number of audio channels a device <b>Audio System</b> is configured to use.

	@note	AJA recommendeds configuring the <b>Audio System</b> to use the maximum number of audio channels the device is capable of.

	The audio <b>Sample Rate</b> on all AJA devices is fixed at 48 kHz. All NTV2 devices implement a 48 kHz <b>Audio Clock</b> through the
	::kRegAud1Counter register. This register is reset to zero at power-on and PCIe reset, and increments every 20.833… µs. It’s used
	for precise timing purposes for AutoCirculate in FRAME_STAMP::acAudioClockTimeStamp, FRAME_STAMP::acAudioClockCurrentTime,
	AUTOCIRCULATE_STATUS::acAudioClockStartTime and AUTOCIRCULATE_STATUS::acAudioClockCurrentTime.

	Each <b>Audio System</b> uses an 8 MB contiguous block of memory located in the upper part of SDRAM:

	@image	html	hwref-fig2-audiobuffers.png

	An NTV2 device will use one of these two memory configurations for its <b>Audio System</b>s’ buffers:
	-	“Stacked” — The first <b>Audio System</b>’s 8 MB chunk starts at the very top of SDRAM,
		such that the last byte of <b>Audio System</b> 1’s <b>Input Buffer</b> coincides with the last addressable
		byte of SDRAM. Subsequent Audio Systems’ buffers stack downward from there, 8 MB each.
	-	“Non-stacked” — These devices use the last one or two video frames for audio storage.
		The first byte of the last <b>Audio System</b>’s <b>Output Buffer</b> coincides with the first byte
		of the last frame buffer in device memory. Previous <b>Audio System</b> buffers, if any, start
		at the next-lower 8MB frame buffer.
	-	Call ::NTV2DeviceCanDoStackedAudio to determine if the device uses the “stacked” arrangement or not.

	The first (lower address) and last (higher address) 4 MB of the <b>Audio System</b>’s 8 MB chunk is used
	for <b>Audio Output</b> and <b>Audio Input</b>, respectively. Each Output or Input aspect of the
	<b>Audio System</b> operate independently, each being in one of two states: <b>Running</b> or <b>Stopped</b>
	(a.k.a. the “Reset” state). When the Input or Output of the <b>Audio System</b> is Running, eight or sixteen
	channels (see CNTV2Card::GetNumberAudioChannels) of audio are always written/read to/from this memory,
	regardless of whether all 8 or 16 channels are used.

	See \ref audioformats for a details on the format of the audio data in the buffer.

	@warning	It is easy to write video data into an audio buffer and vice-versa, which leads to noisy,
				garbled audio and/or bad video frame(s). SDK clients must take precautions to ensure that frame
				buffers used by your application never coincide with any of the audio buffers.


	<hr size="50px">
	@subsection	audiocapture		Audio Capture

	Incoming audio is de-embedded from incoming audio HANC packets (SMPTE 299M for HD, SMPTE 272M for SD).
	For HD, each audio sample consists of 24 bits of sample data (normally PCM).
	For SD, each audio sample consists of 20 bits of sample data (normally PCM) -- audio extended packets are ignored.

	Call CNTV2Card::IsAudioInputRunning to determine if the capture side of the <b>Audio System</b> is running or not.
	Call CNTV2Card::StartAudioInput to start the capture side of the <b>Audio System</b> running.
	Call CNTV2Card::StopAudioInput to stop the capture side of the <b>Audio System</b> running.

	When the <b>Audio System</b> is running, each 24-bit sample is copied as-is into the most-significant 3 bytes of each 4-byte sample word
	in the <b>Audio Input Buffer</b> in device memory at the address specified by the <b>Audio System</b>’s Audio Input Last Address register (i.e.,
	the <b>Record Head</b> or “write head”). Call CNTV2Card::ReadAudioLastIn to obtain the current <b>Record Head</b> position. Audio data continues to
	be written into the <b>Input Buffer</b> until filled, whereupon the <b>Record Head</b> wraps back to the start of the buffer, where writing continues.
	The least-significant byte of each 32-bit sample word in the <b>Audio Input Buffer</b> is always set to zero. (Note that for SD, because
	extended packets are ignored, an extra 4-bit nibble in each 32-bit sample word will also be zero.)

	@image	html	hwref-fig3-audiorecordplay.png

	Audio data can be transferred from the <b>Audio Input Buffer</b> in device memory to a host audio buffer via DMA by calling CNTV2Card::DMAReadAudio.
	While the offset to the Input portion of the device Audio Buffer is typically fixed at 4 MB, to be absolutely safe should this ever change,
	call CNTV2Card::GetAudioReadOffset to obtain the actual offset being used by the driver and SDK.

	If AutoCirculate is used for capture, AutoCirculate completely and automatically runs the <b>Audio System</b>.
	When CNTV2Card::AutoCirculateInitForInput is called with a valid ::NTV2AudioSystem, and then CNTV2Card::AutoCirculateStart is called,
	AutoCirculate starts the <b>Audio System</b>. CNTV2Card::AutoCirculateTransfer automatically transfers the correct number of captured
	audio samples from the device Audio System’s <b>Input Buffer</b> that are associated with the video frame being transferred.
	AUTOCIRCULATE_TRANSFER::GetCapturedAudioByteCount will return the exact number of transferred audio bytes for the frame that was just
	transferred to the host. See \ref autocirculatecapture for more information.

	If the Embedded Audio Group packet (containing two audio channel pairs) is not present in the data stream, its samples in the buffer
	will be set to zero (silence). The firmware notes which audio group packets are present and which are missing, and coalesces this
	information into a hardware register. Client software can query this information by calling CNTV2Card::GetDetectedAudioChannelPairs.

	Upstream equipment may indicate one or more audio channel pairs is not carrying PCM data (e.g., Dolby-E) via certain bits in the AES
	header in the audio stream. On newer AJA devices (see ::NTV2DeviceCanDoPCMDetection), the <b>Audio System</b>’s de-embedder makes this
	information available in a hardware register, and client software can query it by calling CNTV2Card::GetInputAudioChannelPairsWithoutPCM
	or CNTV2Card::InputAudioChannelPairHasPCM.

	Generally, each <b>Audio System</b>’s <b>Input Source</b> is selectable, to receive samples from any of the device’s video (and possibly audio)
	Input Sources, including embedded SDI, HDMI, external AES and analog inputs (see CNTV2Card::SetAudioSystemInputSource).
	For devices that support 3Gb Level B inputs, the audio can be taken from data stream 1 or 2.

	Newer AJA hardware firmware implements an adjustable input delay that can be applied while samples are being written into the
	<b>Audio Input Buffer</b>. Call ::NTV2DeviceCanDoAudioDelay to determine if this feature is available. Call CNTV2Card::GetAudioInputDelay
	to obtain the current delay value. Call CNTV2Card::SetAudioInputDelay to change it.

	Audio input clocking for the running <b>Audio System</b> is ordinarily obtained from the input signal being used (SDI, HDMI, Analog, etc.).
	AJA’s older devices, however, derived the audio input clock from the Device Reference by default (see ::NTV2ReferenceSource) and had to be
	explicitly configured to use the input signal by passing ::NTV2_EMBEDDED_AUDIO_CLOCK_VIDEO_INPUT to CNTV2Card::SetEmbeddedAudioClock.
	If this wasn't done, and the board reference was ::NTV2_REFERENCE_FREERUN or some other timebase that differed from the input video signal,
	the audio would eventually drift from the video. (See also ::NTV2DeviceCanChangeEmbeddedAudioClock.)


	<hr size="50px">
	@subsection	audioplayout		Audio Playout

	If the device supports SDI playout, each <b>Audio System</b> has an output embedder that generates audio packets (per SMPTE 299M for HD
	and SMPTE 272M for SD) and inserts them into the HANC area of the outgoing SDI data stream.
	-	Audio channels 1 & 2 are transmitted on Embedded Group 1, channels 1 & 2.
	-	Audio channels 3 & 4 are transmitted on Embedded Group 1, channels 3 & 4.
	-	Audio channels 5 & 6 are transmitted on Embedded Group 2, channels 1 & 2.
	-	Audio channels 7 & 8 are transmitted on Embedded Group 2, channels 3 & 4.
	-	In 16-channel mode (see CNTV2Card::GetNumberAudioChannels), the remaining 8 channels are distributed in Embedded Groups 3 and 4
	in a similar fashion.

	There is currently no provision for enabling or disabling specific audio groups.

	The SDI output embedder always inserts audio packets unless it’s been disabled (see CNTV2Card::SetAudioOutputEmbedderState).

	Call CNTV2Card::IsAudioOutputRunning to determine if the playout side of the <b>Audio System</b> is running or not.
	Call CNTV2Card::StartAudioOutput to start the playout side of the <b>Audio System</b> running.
	Call CNTV2Card::StopAudioOutput to stop the playout side of the <b>Audio System</b> running.

	When the <b>Audio System</b> is stopped, the output embedder will either embed silence (zeroes) into the data stream, or,
	if ::NTV2AudioLoopBack mode is enabled, it will embed audio samples obtained (through a FIFO) from its input de-embedder
	(see CNTV2Card::SetAudioLoopBack).

	When the <b>Audio System</b> is running, each 24-bit audio sample is copied from the most-significant 3 bytes of each 32-bit longword
	in the device audio buffer (the least-significant byte is ignored). Note, however, for SD, only the most-significant 20 bits are
	used (since the embedder does not create extended audio packets).

	During playout, the output embedder pulls audio samples from the <b>Audio Output Buffer</b> in device memory at the address specified by the
	<b>Audio System</b>’s <b>Audio Output Last Address</b> register (i.e., the <b>Play Head</b> or “read head”). Call CNTV2Card::ReadAudioLastOut to get the
	current <b>Play Head</b> position. Audio data continues to be read from the <b>Output Buffer</b> until the end is reached, whereupon the
	<b>Play Head</b> wraps back to the start of the buffer, where reading continues.

	Newer AJA hardware firmware implements an adjustable <b>Output Delay</b> that can be applied while samples are being read from the
	<b>Audio Output Buffer</b>. Call ::NTV2DeviceCanDoAudioDelay to determine if this feature is available. Call CNTV2Card::GetAudioOutputDelay
	to obtain the current delay value. Call CNTV2Card::SetAudioOutputDelay to change it.

	The playout engine has an optional <b>Erase Mode</b>, in which it will automatically clear (zero) the <b>Output Buffer</b> memory immediately behind
	the <b>Play Head</b> as it runs. If the host application fails to transfer new samples into the <b>Audio Output Buffer</b>, the buffer will eventually
	contain all zeroes, and the output embedder will thereafter only transmit silence. Use the CNTV2Card::SetAudioOutputEraseMode function
	to configure this feature.

	Audio data can be transferred from the host to the device audio buffer via DMA by calling CNTV2Card::DMAWriteAudio. The last address
	written into the <b>Audio Output Buffer</b> (via DMA) is latched and available for readback at <b>Audio Output Last Address</b> (within 256 bytes).
	If the output hardware <b>Play Head</b> pointer catches up to the <b>Audio Output Last Address</b>, the buffer will wrap, and audio/video
	synchronization will be lost.

	Note that if AutoCirculate is used for playout, AutoCirculate completely and automatically manages the <b>Audio System</b>.
	See \ref aboutautocirculate for more information.

	SDI output embedders can usually be driven by any Audio System (see CNTV2Card::SetSDIOutputAudioSystem and CNTV2Card::SetSDIOutputDS2AudioSystem).

	Downstream equipment can be told that the outgoing audio is not carrying PCM data, by setting the non-PCM indicator in the AES header.
	Older AJA devices can only do this on an audio-system-wide basis -- i.e., all outgoing audio groups are marked PCM or non-PCM.
	Use the simpler form of the CNTV2Card::SetAudioPCMControl function for these devices.

	Newer AJA devices can mark individual audio channel pairs as non-PCM (the ::NTV2DeviceCanDoPCMControl function returns true for
	devices that support this capability). Use one of the overloaded versions of CNTV2Card::SetAudioPCMControl that accepts either a
	single ::NTV2AudioChannelPair or an ::NTV2AudioChannelPairs set.

	Downstream equipment can also be told that the outgoing audio is <b>synchronous</b> — i.e. a fixed number of samples per frame.
	AJA NTV2 <b>Audio Systems</b> always operate in <b>asynchronous</b> mode — i.e. we won’t <i>guarantee</i> a fixed number of samples
	per frame — but overall, downstream equipment <i>will</i> receive the correct number of samples for a number of frames.
	The net effect is a <i>de facto</i> Sync Mode, even though the Sync Mode bit is not set in the AES header. Some downstream equipment
	may complain about the AES Sync Mode bit being clear. The <b>Audio System</b> can be told to set the Sync Mode bit in order to
	“fib” to downstream equipment (to stop them from complaining).
	-	Call CNTV2Card::GetAudioOutputAESSyncModeBit to see if the device is setting the Sync Mode bit.
	-	Call CNTV2Card::SetAudioOutputAESSyncModeBit to change the setting.


	<hr size="50px">
	@subsection	audiosamplecount	Correlating Audio Samples to Video Frames

	Because AJA devices use fixed audio sample rates (i.e. 48000 samples per second), some video frame rates will necessarily result
	in some frames having more audio samples than others. For example, the NTSC frame rate is exactly 30000/1001 frames per second — so by
	converting frames to samples, the expected number of audio samples at any given frame time can be calculated. This is what
	the ::GetAudioSamplesPerFrame utility function is for:
	@code{.cpp}
		//	Print the audio sample count cadence for NTSC 2997...
		for (ULWord frame(0);  frame < 60;  )
		{
			std::cout << DEC(::GetAudioSamplesPerFrame(NTV2_FRAMERATE_2997, NTV2_AUDIO_48K, frame));
			if (++frame < 60)
				std::cout << ", ";
			if (!(frame % 5))
				std::cout << std::endl;
		}
	@endcode

	-	<b>Capture</b>
		-	<b>Without AutoCirculate</b> — the number of audio samples to associate with the current frame is provided by the
			hardware’s <b>Record Head</b>. Just compare its new position with its old position from the previous frame.
		-	<b>With AutoCirculate</b> — Use the AUTOCIRCULATE_TRANSFER::GetCapturedAudioByteCount function.
	-	<b>Playout</b>
		-	<b>Without AutoCirculate</b> — Use ::GetAudioSamplesPerFrame to calculate the number of audio samples to write for
			the current frame.
		-	<b>With AutoCirculate</b> — Use ::GetAudioSamplesPerFrame to calculate the number of audio samples to write for
			the current frame.


	<hr size="50px">
	@subsection	audiohidden		Other “Hidden” Audio Systems

	Modern AJA devices intended for “retail” markets, particularly newer “KONA” and “Io” series devices, may have firmware that
	implements additional “hidden” audio systems that aren’t reported in the ordinary ::NTV2DeviceGetNumAudioSystems call:
	-	A <b>Host Audio System</b> for audio input/output to/from the host operating system (see ::NTV2DeviceGetHostAudioSystem);
	-	A “phantom” <b>Mixer Audio System</b> that uses only FIFOs (no audio buffer memory) in order to implement an \ref audiomixer
		(see CNTV2Card::DeviceCanDoAudioMixer and ::NTV2DeviceGetAudioMixerSystem).

	These additional audio systems help support AJA’s “retail” software (i.e. Adobe, Avid, Apple, Telestream, etc. plug-ins, AJA ControlRoom, etc).

	The <b>Host Audio System</b> is used to continuously deliver…
	-	SDI/HDMI/AES audio from the AJA KONA/Io device as input to the host computer’s primary audio system.
		For example, this would enable an audio capture program running on the host (e.g. Audacity) to capture audio from an SDI input signal on the KONA/Io device.
	-	Host audio output from the host OS’s primary system audio to the KONA/Io device’s SDI/HDMI/AES output.
		For example, this would enable audio from a web browser running on the host computer to playout through a KONA/Io device’s SDI output.

	The <b>Host Audio System</b> is started and operated by the AJA kernel driver in conjunction with the host computer system’s audio control panel.
	It allows host audio to operate independently of other audio systems on the device that may be used by AutoCirculate or other
	SDK client software.

	Since the <b>host audio system</b> uses audio buffer memory in device SDRAM, it’s susceptible to \ref audioclobber if an excessively
	large video buffer number is used by an active Frame Store.


	<hr size="50px">
	@subsection	audioclobber	Audio Buffer Corruption

	It’s possible (and quite easy) to configure a FrameStore to write video into audio buffer memory.
	For example:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signal at SDI Input 1
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1

			//	Which video frame is the first to contain audio system audio?
			//	You could just start incrementing frame numbers until you start getting bad audio.
			//	But here’s how to really do it...
			NTV2FrameGeometry		fg;
			NTV2FrameBufferFormat	fbf;
			device.GetFrameGeometry(fg, NTV2_CHANNEL1);
			device.GetFrameBufferFormat(NTV2_CHANNEL1, fbf);
			ULWord firstAudioFrameNum = ::NTV2DeviceGetNumberFrameBuffers(device.GetDeviceID(), fg, fbf);
			if (::NTV2DeviceCanDoStackedAudio(device.GetDeviceID()))
			{
				ULWord			chan1CtrlBits(0);
				mDevice.ReadRegister(kRegCh1Control, &chan1CtrlBits);
				ULWord			frameSizeMB (1 << (((chan1CtrlBits & kK2RegMaskFrameSize) >> 20) + 1));
				if (frameSizeMB < 8)
					frameSizeMB = 8;	//	No 2MB mode!
				const ULWord	maxRamBytes(::NTV2DeviceGetActiveMemorySize(device.GetDeviceID()));
				const ULWord	numAudioSystems(::NTV2DeviceGetNumAudioSystems(device.GetDeviceID()));
				const ULWord	totalAudioBytes(numAudioSystems * 8ULL*1024ULL*1024*ULL);	//	8MB per audio system
				firstAudioFrameNum = (maxRamBytes - totalAudioBytes) / frameSizeMB;
			}

			//	UH-OH:  This will cause video to be written into the audio buffers...
			device.SetInputFrame(NTV2_CHANNEL1, firstAudioFrameNum);	//	Write FrameStore 1 video into audio area
		}
	@endcode

	In the above example…
	-	On “stacked audio” devices, this will write video into the last audio system’s buffer memory.
	-	On older “non-stacked audio” devices, this will write video into the first audio system’s buffer memory.
	-	To notice the corruption, the affected audio system will need to be running (playout and/or capture).
	-	It’s more likely to be noticed in audio playout, since the output audio buffer starts at the top of the frame.
	-	Small frame geometries and pixel formats (e.g., 8-bit YUV 525i) are less likely to touch the audio capture
		buffer that starts 4MB into the frame.

	It’s also possible (and quite easy) to configure a FrameStore to playout SDI/HDMI video that’s been corrupted by
	audio-in-the-video. This would happen if the FrameStore is set for playout and it’s using a frame buffer that’s
	also being used by a running audio system.


	<hr size="50px">
	@subsection	audiomixer		Audio Mixer

	Some newer NTV2 devices have firmware that implements a three-multichannel-input <b>Audio Mixer</b>.
	To determine if a device can support this feature, call ::NTV2DeviceCanDoAudioMixer.
	To determine if the device actually has this feature in its running firmware, call CNTV2Card::DeviceCanDoAudioMixer.
	To determine the ::NTV2AudioSystem of the mixer, call ::NTV2DeviceGetAudioMixerSystem.

	The mixer supports three multichannel input sources:
	-	<b>Main</b> (primary) input (all audio channels);
	-	<b>Auxiliary 1</b> input (2 audio channels only);
	-	<b>Auxiliary 2</b> input (2 audio channels only).

	Each of the three mixer inputs can be sourced from the output of any <b>Audio System</b> on the device by making these calls:
	-	CNTV2Card::SetAudioMixerMainInputAudioSystem (all audio channels)
	-	CNTV2Card::SetAudioMixerAux1x2chInputAudioSystem (two audio channels only)
	-	CNTV2Card::SetAudioMixerAux2x2chInputAudioSystem (two audio channels only)

	Any of the mixer inputs can be disabled (muted) or enabled (unmuted) by making these calls:
	-	CNTV2Card::SetAudioMixerMainInputEnable
	-	CNTV2Card::SetAudioMixerAux1InputEnable
	-	CNTV2Card::SetAudioMixerAux2InputEnable

	Each mixer input has a separate gain control that’s controlled from these functions:
	-	CNTV2Card::SetAudioMixerMainInputGain
	-	CNTV2Card::SetAudioMixerAux1InputGain
	-	CNTV2Card::SetAudioMixerAux2InputGain



	<hr size="50px">
	@section	devicefirmware		Firmware

	NTV2 devices have an EEPROM (non-volatile memory) that stores its FPGA programming.
	This flash memory is commonly divided into a minimum of two logical partitions:
	-	the “main” partition — for the normal FPGA bitfile image;
	-	the “failsafe” boot — for a fallback FPGA bitfile image.

	Traditionally, the FPGA is only loaded from flash memory upon power-up.
	The “failsafe” bitfile only loads if the board’s “failsafe” button is held down while power is applied to the board.

	@note	Our newest boards — starting with the \ref kona5 — can be instructed to reload their FPGA upon PCIe reset
			without an intervening power-down.

	Some of our boards — like the \ref konaip — have, in addition to the normal FPGA hardware, a microprocessor, which requires
	an additional, separate firmware bitfile that bootstraps and operates it. This extra firmware is bundled into a “package” that is
	also stored in (and loaded from) a separate partition in the EEPROM.


	<hr size="50px">
	@subsection	dev-firmware-loading	Loading Firmware

	Loading the FPGA from EEPROM after power-up takes a finite amount of time.
	If this exceeds the amount of time allotted by the BIOS for PCIe devices to become ready, the AJA device
	won’t be detected by the BIOS, and thus won’t be probed by — or matched to — any device drivers.
	On Windows PCs, this is shown as an “<i>Unknown device</i>” in the Windows <b>Device Manager</b>.
	On Linux PCs, the ‘<b>lspci</b>’ command can help diagnose these issues.
	For example, here’s what ‘<b>lspci</b>’ should normally show when looking for devices with AJA’s PCIe vendor
	ID of \c 0xF1D0 (e.g. for a Corvid88):
	@code{.sh}
		$ lspci -d f1d0:
		03:00.0 Multimedia video controller: AJA Video Device eb0d
		$ lspci -n  -d f1d0:
		03:00.0 0400: f1d0:eb0d
		$ lspci -nn  -d f1d0:
		03:00.0 Multimedia video controller [0400]: AJA Video Device [f1d0:eb0d]
	@endcode

	@note	<b>Disable Fast-Boot Option:</b> On PCs running Windows or Linux, be sure to disable all fast-boot options in the BIOS.

	@note	<b>Disable Power-Saving Modes:</b> AJA’s NTV2 devices do not support PCIe power management.
			-	Be sure to disable any and all Energy-Saving features in the OS,
				particularly PCIe “Link State Power Management” (LSPM).
			-	<b>Windows</b> — This is in “Advanced Power Settings” ==≻ “Power Options” ==≻
				“PCI Express” ==≻ “Link State Power Management” ==≻ <b>Off</b>.
			-	<b>Linux</b> — Use the \c lspci command:
				@code{.sh}
					$ sudo lspci -vvv  -d f1d0:
				@endcode
				… and confirm that “LnkCtl: ASPM Disabled” is shown for each AJA device.
			-	On some motherboards, power management is controlled by the BIOS, in which case,
				try <b>disabling ASPM</b> under the BIOS’ <b>power options</b>.

	If, even after disabling “fast-boot”, the AJA device fails to show up, …
	-	Try “warm-booting” the PC. If the device is recognized after a warm-boot, then it’s likely a firmware load-time issue.
	-	Try installing the AJA board into a different PCIe slot on the motherboard. Some manufacturers employ chips that perform
		intermediate buffering on certain specific PCIe slots that can sometimes cause detection issues. Also beware that some
		manufacturers use a custom BIOS that has options for configuring PCIe slots, so be sure to check those BIOS settings
		and adjust them if needed.
	-	If the device still fails to show up, please <a href="https://sdksupport.aja.com/index.php?/Tickets/Submit">submit a Ticket</a>.


	<hr size="50px">
	@subsection	dev-firmware-flash		“Flashing” Firmware

	AJA provides two ways to “flash” — i.e. update — new firmware into the device’s EEPROM storage:
	-#	Using the <a href="https://sdksupport.aja.com/index.php?/Knowledgebase/Article/View/129">ntv2firmwareinstaller</a>
		command-line utility, described in \ref toolsandutilities.
	-#	Using the <b>AJA ControlPanel</b>, which is part of the “retail” software that can be downloaded from https://www.aja.com/.

	Once the new firmware has been written into the device EEPROM storage, it won’t “run” until the device FPGA gets reloaded.


	<hr size="50px">
	@subsection	dev-firmware-vers		Determining Firmware Version

	@note	The <b>currently-running firmware</b> could be different from the <b>currently-installed firmware</b> that’s stored
			in the EEPROM’s main partition. This can happen if the device wasn’t power-cycled after a firmware update installation,
			or if the device was booted using its “failsafe” firmware.

	There are three ways to determine what firmware is installed, and/or which firmware is running on an AJA device:
	-	the <a href="https://sdksupport.aja.com/index.php?/Knowledgebase/Article/View/129">ntv2firmwareinstaller</a> command line
		utility, using its <b>--info</b> option;
	-	the “Info” or “Firmware” panels of the <b>AJA ControlPanel</b> application (in AJA’s “retail” software);
	-	programmatically using certain SDK API calls (see below).

	Newer AJA devices (starting with the \ref corvid88) report their <b>currently-running firmware date</b> in register 88,
	which is made available as numeric date components or a standard string by calling CNTV2Card::GetRunningFirmwareDate.

	Older AJA devices prior to the introduction of the \ref corvid88 have no way of reporting their <b>currently-running firmware date</b>
	— they can only report the running firmware’s <i>revision number</i> (which was stored in a portion of register 48 and made
	available by the CNTV2Card::GetRunningFirmwareRevision function. To correlate the revision number to a date, it must be looked
	up on the device’s firmware page on the
	<a href="https://sdksupport.aja.com/index.php?/Knowledgebase/List/Index/25/ntv2-firmware">AJA SDK support site’s KnowledgeBase</a>
	(not very convenient).

	To determine if a device is capable of reporting its <b>currently-running firmware date</b>, call ::NTV2DeviceCanReportRunningFirmwareDate.

	To determine the <b>currently-installed firmware</b> date, the firmware header must be read out of flash memory and parsed.
	The CNTV2KonaFlashProgram class does this, and after parsing, the CNTV2KonaFlashProgram::GetDate method will provide the date.


	<hr size="50px">
	@subsection	dev-firmware-features	Determining Firmware Features

	NTV2, being an old and rather crude architecture, has no automatically-enforced linkage between the firmware and the SDK —
	i.e. the SDK is neither generated from the firmware, nor is the firmware generated from the SDK.
	Thus, the SDK cannot simply “query the board” to find out how many of a particular widget a device’s running firmware implements,
	or if a new widget or feature is present (by simply reading registers).
	Unfortunately, this puts the burden of feature inquiry entirely into software, and onto the authors of NTV2 client applications.

	AJA will do its best to ensure that the “CanDo” functions are correct for the specific set of firmware bitfiles that have been
	qualified for a given SDK release. The release notes on the SDK download page will point out any firmware features added (or removed).
**/
