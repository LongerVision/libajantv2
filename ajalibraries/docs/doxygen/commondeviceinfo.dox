/**
	@page	ntv2devops		NTV2 Device Hardware Operation

	On this page:
	-	\ref ntv2devops-intro
	-	\ref devicesignalinputsoutputs
		-	\ref commonelectricalchars
		-	\ref hardwarecharacteristics
	-	\ref videooperation
		-	\ref vidop-fs
		-	\ref independentmode
		-	\ref vidop-fbaccess
		-	\ref deviceclockingandsync
		-	\ref fieldframeinterrupts
		-	\ref vidop-fbconflict
		-	\ref vidop-csc
		-	\ref vidop-lut
		-	\ref vidop-mixerkeyer
	-	\ref audiooperation
		-	\ref audiocapture
		-	\ref audioplayout
		-	\ref audiosamplecount
		-	\ref audiohidden
		-	\ref audioclobber
		-	\ref audiomixer
	-	\ref devicefirmware
		-	\ref dev-firmware-loading
		-	\ref dev-firmware-flash
		-	\ref dev-firmware-vers
		-	\ref dev-firmware-features



	<hr size="50px">
	@section	ntv2devops-intro	Introduction

	In simplest terms, NTV2 devices are essentially…
	-	a big chunk of SDRAM memory for buffering video frames and audio samples, which is tied to…
	-	an FPGA that determines what gets written or read to/from that memory (and where), plus…
	-	one or more video and/or audio signal inputs and/or outputs, and…
	-	a high-speed PCIe interface to a host computer, for rapidly reading or writing 32-bit registers,
		and transferring bulk data via DMA to/from the host.

	@image	html	hwref-fig0-blockdiagram.png

	In addition, the FPGA firmware implements “widgets“ that can process video data in a particular way
	(e.g., color correction, muxing/demuxing, etc.).

	All AJA NTV2 hardware devices minimally support the following:
	-	Capture or play to/from the host computer video and audio through at least one video connector.
	-	SD video formats: 525i 59.94fps, and 625i 50fps
	-	HD video formats: 720p 50/59.94/60, 1080i 50/59.94/60, 1080psf 23.98/24 and 1080p 23.98/24/29.97/30
	-	8-bit YCbCr or 10-bit YCbCr frame buffer formats.

	Beyond these common characteristics, AJA devices fan out into a diverse array of capabilities to suit many different applications.
	To determine the features of an AJA device, use the \ref ntv2devicefeatures.

	Most devices can capture and play video, but some may only capture, while others may only playout.
	-	To determine if a device can capture video, call ::NTV2DeviceCanDoCapture.
	-	To determine if a device can play video, call ::NTV2DeviceCanDoPlayback.



	<hr size="50px">
	@section	devicesignalinputsoutputs		Signal Inputs & Outputs

	@par	Breakout Boxes and Cables

	On some devices, certain signal connectors are accessible only through a breakout cable or breakout box.
	-	To determine if the device can support a breakout box, call ::NTV2DeviceCanDoBreakoutBox.
	-	To determine if a breakout box is connected, call CNTV2Card::GetBreakoutHardware.

	@par	SDI Connectors

	Most AJA devices have at least one SDI connector.
	-	To determine the number of SDI input jacks the device has, call ::NTV2DeviceGetNumVideoInputs.
	-	To determine the number of SDI output jacks the device has, call ::NTV2DeviceGetNumVideoOutputs.

	Some SDI connectors are permanently configured as inputs, others as outputs, but on some devices, they’re software-configurable.
	This means your application can instruct the device to reconfigure one of its SDI jacks from an input to an output (or vice-versa).
	-	To determine if a device has software-configurable SDI connectors, call ::NTV2DeviceHasBiDirectionalSDI.
	-	If a device has bi-directional SDI connectors, the ::NTV2DeviceGetNumVideoInputs and ::NTV2DeviceGetNumVideoOutputs will reflect
		the maximum possible number of inputs and outputs.
		-	For example, the \ref io4kquad has four bi-directional SDI jacks plus an additional monitor (output-only) jack,
			so for that device, ::NTV2DeviceGetNumVideoInputs returns 4 and ::NTV2DeviceGetNumVideoOutputs returns 5.
	-	To determine if an SDI connector is currently configured to transmit, call CNTV2Card::GetSDITransmitEnable.
	-	To change an SDI connector’s function to receive or transmit, call CNTV2Card::SetSDITransmitEnable.

		@note	When changing an SDI connector from ‘transmit’ to ‘receive’, it can take a while for the device input
				to lock to the incoming signal (when there is one). It’s best to delay several frames (or more) before
				calling CNTV2Card::GetInputVideoFormat or CNTV2Card::GetSDIInputVideoFormat to obtain an accurate
				determination of what signal is present.

	All SDI connectors on NTV2 devices can receive or transmit 1.5 Gbps signals, and almost all will handle 3Gbps.
	-	To determine if its SDI spigots can handle 6Gbps or 12Gbps, call ::NTV2DeviceCanDo12GSDI.

	To determine if there’s a signal present at an SDI input connector, and if so, what format it is…
	-	Call CNTV2Card::GetInputVideoFormat, specifying an ::NTV2InputSource …
		-	Use ::NTV2_INPUTSOURCE_SDI1, ::NTV2_INPUTSOURCE_SDI2, etc.
		-	Or use the result of ::GetNTV2InputSourceForIndex.
	-	Or call CNTV2Card::GetSDIInputVideoFormat, specifying the SDI input connector as an ::NTV2Channel value.
	-	Whichever function you use, if you are expecting <b>psf</b> video, pass ‘true’ for the ‘<i>inIsProgressive</i>’ parameter.

	@par	HDMI Connectors

	Many AJA devices have HDMI connectors, some for capture, most for playout.
	-	To determine the number of HDMI inputs the device has, call ::NTV2DeviceGetNumHDMIVideoInputs.
	-	To determine the number of HDMI outputs the device has, call ::NTV2DeviceGetNumHDMIVideoOutputs.
	-	HDMI capabilities depend on the physical HDMI hardware used on the device and the supporting firmware.
		To determine which HDMI hardware is present on the device, call ::NTV2DeviceGetHDMIVersion.
		(Note that this doesn’t return an HDMI protocol version — it’s strictly an unsigned integer that indicates
		which “generation” of HDMI hardware was used on the device.
	-	HDMI hardware capabilities chart:

	@image	html	hdmichart.png

	To determine if there’s a signal present at an HDMI input connector, and if so, what format it is…
	-	Call CNTV2Card::GetInputVideoFormat, specifying an ::NTV2InputSource …
		-	Use ::NTV2_INPUTSOURCE_HDMI1, ::NTV2_INPUTSOURCE_HDMI2, etc.
		-	Or use the result of ::GetNTV2InputSourceForIndex — specify ::NTV2_INPUTSOURCES_HDMI for the ‘<i>inKinds</i>’ parameter.
		-	If you are expecting <b>psf</b> video, pass ‘true’ for the ‘<i>inIsProgressive</i>’ parameter.
	-	Or call CNTV2Card::GetHDMIInputVideoFormat, specifying the HDMI input connector as an ::NTV2Channel value.
	-	If a DVI monitor is connected to the HDMI output connector, no audio will be transmitted (since DVI doesnʼt support audio).
	-	If an HDMI monitor is connected to the HDMI output connector, and it appears to be “DVI”, this is often caused by the firmware
		not correctly reading the monitor configuration (EDID), so it falls back to DVI.  To force the HDMI output to HDMI:
		-	Call CNTV2Card::SetHDMIOutProtocol and specify <tt>NTV2_HDMIProtocolHDMI</tt>, and…
		-	Call CNTV2Card::SetHDMIOutForceConfig and specify <tt>true</tt>.

	@par	Analog Video Connectors

	Some older AJA devices have analog video connectors (remember the old RCA component-level jacks?).
	-	To determine the number of analog video inputs the device has, call ::NTV2DeviceGetNumAnalogVideoInputs.
	-	To determine the number of analog video outputs the device has, call ::NTV2DeviceGetNumAnalogVideoOutputs.

	To determine if there’s a signal present at an analog video input connector, and if so, what format it is…
	-	Call CNTV2Card::GetInputVideoFormat, specifying an ::NTV2InputSource …
		-	Use ::NTV2_INPUTSOURCE_ANALOG1.
		-	Or use the result of ::GetNTV2InputSourceForIndex — specify ::NTV2_INPUTSOURCES_ANALOG for the ‘<i>inKinds</i>’ parameter.
		-	If you are expecting <b>psf</b> video, pass ‘true’ for the ‘<i>inIsProgressive</i>’ parameter.
	-	Or call CNTV2Card::GetAnalogInputVideoFormat.

	@par	Audio Connectors

	Some AJA devices have separate connectors for audio input and/or output, even analog audio on some older devices.
	-	To determine if the device is capable of analog audio input or output, call ::NTV2DeviceCanDoAnalogAudio.
	-	To determine how many AES inputs and/or outputs a device has, call ::NTV2DeviceGetNumAESAudioInputChannels
		and/or ::NTV2DeviceGetNumAESAudioOutputChannels, respectively.
	-	To determine how many analog audio inputs and/or outputs a device has, call ::NTV2DeviceGetNumAnalogAudioInputChannels
		and/or ::NTV2DeviceGetNumAnalogAudioOutputChannels, respectively.

	@par	Reference and LTC Connectors

	Most AJA devices have a single BNC connector that can be used for reference input or for analog LTC input.
	On other devices, there are separate reference and LTC input connectors. Some devices have output connectors
	for LTC or Reference.
	-	To determine the number of reference video inputs, call ::NTV2DeviceGetNumReferenceVideoInputs.
	-	To determine the number of LTC inputs, call ::NTV2DeviceGetNumLTCInputs.
	-	To determine if the device can be configured to receive LTC on its reference input port, call ::NTV2DeviceCanDoLTCInOnRefPort.
		If the device can receive LTC from its Reference input…
		-	Call CNTV2Card::GetLTCInputEnable to determine if the input is configured to receive analog LTC from its Reference port.
		-	Call CNTV2Card::SetLTCInputEnable to configure the Reference/LTC input:
			pass <b>true</b> to have it receive analog LTC;
			pass <b>false</b> to have it receive Reference.
	-	To determine if a valid LTC signal is present at the connector, call CNTV2Card::GetLTCInputPresent.
	-	To determine the number of LTC outputs, call ::NTV2DeviceGetNumLTCOutputs.

	@par	Serial Ports (RS-422)

	Most AJA devices have a single RS-422 connector that can be used to control tape deck transports and for other purposes.
	-	To determine the number of serial ports on a device, call ::NTV2DeviceGetNumSerialPorts.
	-	To determine if the serial port is programmable (for baud rate, parity, etc.), call ::NTV2DeviceCanDoProgrammableRS422.
		-	To determine the current baud rate, call CNTV2Card::GetRS422BaudRate. To change the baud rate, call CNTV2Card::SetRS422BaudRate.
		-	To determine the current parity configuration, call CNTV2Card::GetRS422Parity. To change the baud rate, call CNTV2Card::SetRS422Parity.

	@image	html	rs422pinout400.png


	@subsection	commonelectricalchars		Common Electrical Characteristics

	Unless otherwise noted, physical and electrical characteristics of inputs and outputs — SDI, HDMI, analog video, analog audio, reference,
	LTC, etc. — are generally identical across all AJA devices.

	<b>SDI Input(s)</b>
	-	AC-coupled input terminated with 75Ω to ground
	-	SMPTE 292 compliant — 800mV peak-to-peak ±10%

	<b>SDI Output(s)</b>
	-	AC-coupled output terminated with 75Ω to ground
	-	<b>Output Level:</b>  800mV peak-to-peak ±10%, terminated into 75Ω

	<b>Video Reference Input(s)</b>
	-	Analog video reference, NTSC, PAL, or tri-level sync
	-	Input terminated by 75Ω to ground
	-	<b>Input level:</b>  0.5 Volts peak-to-peak to 2.0 Volts peak-to-peak
	-	Tri-level sync:
		-	Analog Color Black (700 mV sync nominal, plus burst)
		-	Composite Sync (700 mV sync nominal, plus burst and video)
		-	HD Tri-Level Sync (±700 mV sync)

	<b>Analog LTC Input(s)</b>
	-	Designed to work with inverted or non-inverted inputs
	-	Input impedence 75Ω, coax or other single-ended connection is recommended
	-	There is no differential termination on these inputs, so a balanced connection may not be reliable
	-	Designed to meet SMPTE spec, 0.5V to 4.5Vp-p

	<b>HDMI Input, Output</b>
	-	Connector: Type-A (unless otherwise noted)

	<b>AES Input(s)</b>
	-	DC-coupled input terminated with 75Ω to ground
	-	<b>Minimum input level:</b>  100 mV peak-to-peak

	<b>AES Output(s)</b>
	-	AC-coupled output terminated with 75Ω to ground
	-	<b>Output level:</b>  1.55 Volts peak-to-peak, +/- 10%, terminated into 75Ω

	<b>Analog Video Output(s)</b>
	-	12-bit precision DAC output
	-	<b>Luma Bandwidth:</b> 12.5 MHz (SD) or 30 MHz (HD)
	-	<b>Chroma Bandwidth:</b> 5.8 MHz (SD) or 13.75 MHz (HD)

	<b>Audio Output</b>
	-	<b>Connector:</b>  DB-25
	-	<b>Maximum Level, unclipped:</b>  +12dBu, +15dBu, +18dBu, +24dBu (selectable)


	@subsection	hardwarecharacteristics	Hardware Characteristics

	@par		PCI Interface

	All NTV2 devices utilize Peripheral Component Interconnect (PCI) or Peripheral Component Interconnect Express (PCIe) to communicate with the host
	computer system (or with other PCI/PCIe peers on the same host).

	@par		PCI Vendor ID

	All AJA NTV2 devices have the same PCI vendor ID.
	-	PCI vendor ID:  <b>0xF1D0</b>

	@par		Data Transfer

	Direct Memory Access (DMA) is the only supported method of moving data between host memory
	and the hardware. All NTV2 devices have at least one DMA engine.
	(Programmed Input/Output, a.k.a. PIO is no longer supported.)
	-	To determine the number of DMA engines for a device, call ::NTV2DeviceGetNumDMAEngines.

	@par		Device Frame Buffer

	All NTV2 devices have a fixed amount of Synchronous Dynamic Random Access Memory (SDRAM).
	The FPGA is the SDRAM controller, which controls the output of video (and audio and anc)
	from RAM, the input of video (and audio and anc) into RAM, the PCI interface to/from RAM,
	and RAM refresh.

	@par		Frame Buffer Layout

	The device’s SDRAM is partitioned into a number of equal-sized video <b>frames</b>. The video
	<b>frame size</b> is always a multiple of 8MB — i.e. 8MB, 16MB or 32MB. On older devices, it’s
	automatically set by the firmware based on ::NTV2VideoFormat, ::NTV2FrameBufferFormat and
	::NTV2VANCMode. This legacy behavior is retained in newer devices, but can be overridden
	programmatically.
	-	To determine if the ::NTV2Framesize can be changed programmatically,
		call ::NTV2DeviceSoftwareCanChangeFrameBufferSize.
	-	To determine the SDRAM that the device has for storing video and audio data,
		call ::NTV2DeviceGetActiveMemorySize.
	-	To determine the current ::NTV2Framesize for the device,
		call CNTV2Card::GetFrameBufferSize. The returned ::NTV2Framesize can be converted
		into a byte count using ::NTV2FramesizeToByteCount.
	-	To change (override) the current ::NTV2Framesize for the device,
		call CNTV2Card::SetFrameBufferSize.

	@image	html	hwref-fig1-sdramfblayout.png

	Video frames are indexed using a zero-based index number. The first byte of the first frame
	(frame zero) starts at the lowest SDRAM address, and subsequent frames are located at higher
	addresses from there, as a byte-multiple of the current ::NTV2Framesize. Obviously, larger
	rasters (e.g. ::NTV2_FG_1920x1080 versus ::NTV2_FG_720x486) and/or deeper frame buffer formats
	(e.g. ::NTV2_FBF_48BIT_RGB versus ::NTV2_FBF_8BIT_YCBCR) will necessarily result in half as many
	available frame buffers … while 4K/UHD frames will result in a fourth as many frames.
	-	To determine the minimum number of 8MB chunks to safely accommodate a given ::NTV2FrameGeometry
		and ::NTV2FrameBufferFormat, call ::Get8MBFrameSizeFactor.

	@warning	On multi-channel devices, changing a Frame Store’s ::NTV2FrameBufferFormat and/or
				::NTV2VideoFormat (and/or ::NTV2VANCMode) that results in a 8MB/16MB frame size
				change (or vice-versa) while another channel is ingesting or playing video will
				result in at least one bad frame of video in the stream once the device’s memory
				layout is changed. It can even cause the “start” and “end” frames being
				AutoCirculated to refer to frames that no longer exist on the device. To prevent
				this, call CNTV2Card::SetFrameBufferSize to pre-configure the device to use the
				largest expected ::NTV2Framesize when your application starts.

	Video data in the device frame buffer is always stored full-frame. Interlaced video is
	always stored in the frame buffer with the first line of Field 1 (F1L1) at the top of the
	buffer, followed by the first line of Field 2 (F2L1), then F1L2, F2L2, F1L3, F2L3, etc.,
	alternating to the end of the frame. An exception to this is NTSC SD 525i, which starts
	with Field 2 at the top of the buffer (F2L1, F1L1, F2L2, F1L2, etc.).

	@note	A very <i>very</i> long time ago, AJA had devices that stored all of F1’s lines in
			the top half of the buffer, and all of F2’s lines in the bottom half. These devices
			and buffer formats are no longer supported.



	<hr size="50px">
	@section	videooperation		Video System Operation

	This section describes how the Video System operates.

	@subsection	vidop-fs		Frame Store Operation

	A <b>Frame Store</b> is a device widget implemented in FPGA firmware that uses several
	registers to monitor and control its principal properties:
	-	<b>Enable/Disable State</b> — When <b>Disabled</b>, the widget will not access SDRAM.
		Call CNTV2Card::IsChannelEnabled to determine if a Frame Store is enabled or not.
		Calling CNTV2Card::EnableChannel or CNTV2Card::DisableChannel will change it.
		Note that AutoCirculate sets this for you, but won’t “un-set” it.
	-	<b>Mode</b> — This correlates to the ::NTV2Mode enumeration in the SDK.
		In ::NTV2_MODE_DISPLAY, it will <b>read</b> video data for playout from SDRAM;
		in ::NTV2_MODE_CAPTURE, it will <b>write</b> video data into SDRAM. Call CNTV2Card::GetMode
		to obtain the Frame Store’s current mode;  calling CNTV2Card::SetMode will set it.
		Note that AutoCirculate sets this for you, but doesn’t “un-set” it.
	-	<b>Frame Buffer Format</b> — This coincides with the ::NTV2FrameBufferFormat enumeration
		in the SDK. Call CNTV2Card::GetFrameBufferFormat to determine the current format;
		calling CNTV2Card::SetFrameBufferFormat will change it. See \ref devicefbformats for details.
		AutoCirculate users must set this.
	-	<b>Video Format</b> — This correlates to the ::NTV2VideoFormat enumeration in the SDK,
		and implies a ::NTV2FrameGeometry, ::NTV2Standard and ::NTV2FrameRate.
		Call CNTV2Card::GetVideoFormat to determine the current format;
		call CNTV2Card::SetVideoFormat to change it.
		AutoCirculate users must set this.
	-	<b>Input Frame</b> — This is a zero-based index number that identifies the specific Frame
		Buffer in SDRAM that will be continually written with video frame data <b>if</b>…
		-	the Frame Store is Enabled;
		-	its Mode is Capture;
		-	and a signal is routed to its input crosspoint(s).
	
		Call CNTV2Card::GetInputFrame to determine the current <b>Input Frame</b> buffer number.
		Call CNTV2Card::SetInputFrame to change it.
		Note that AutoCirculate manages this for you.
	-	<b>Output Frame</b> — This is a zero-based index number that identifies the specific Frame
		Buffer in SDRAM that will continuously be read from <b>if</b>…
		-	the Frame Store is Enabled;
		-	its Mode is Display. (The output video can be monitored <b>if</b> the Frame Store’s
			output signal is routed to a video output widget, and a monitor is connected to that
			output connector.)
		
		Call CNTV2Card::GetOutputFrame to determine the current <b>Output Frame</b> buffer number.
		Call CNTV2Card::SetOutputFrame to change it.
		Note that AutoCirculate manages this for you.
	-	<b>VANC Mode</b> — The ::NTV2VANCMode setting determines if a “tall” or “taller” frame geometry
		is in effect. The ::NTV2_VANCMODE_TALL geometry incorporates several extra lines of video that
		precede the first visible line in the raster into the Frame Store’s frame buffer memory.
		::NTV2_VANCMODE_TALLER was added to firmware when it was found that additional useful ancillary
		data was found on additional lines ahead of the first line in ::NTV2_VANCMODE_TALL mode.
		Call CNTV2Card::GetVANCMode to determine the current <b>VANC Mode</b> setting.
		Call CNTV2Card::SetVANCMode to change it.
	-	<b>VANC Data Shift Mode</b> — The ::NTV2VANCDataShiftMode determines if the firmware will automatically
		right-shift incoming (or left-shift outgoing) data words by 2 bits in the VANC lines in 8-bit YCbCr
		frame buffers (e.g. ::NTV2_FBF_8BIT_YCBCR ), making it easy to parse (or write) ancillary data
		packets in the frame buffer.
		Call CNTV2Card::GetVANCShiftMode to determine the current <b>VANC Data Shift Mode</b> setting.
		Call CNTV2Card::SetVANCShiftMode to change it.
	-	<b>Frame Buffer Orientation</b> — The ::NTV2FBOrientation (a.k.a. ::NTV2FrameBufferOrientation
		a.k.a. ::NTV2VideoFrameBufferOrientation) determines the direction that firmware will write or
		read video lines into or out of SDRAM, either normal ::NTV2_FRAMEBUFFER_ORIENTATION_TOPDOWN,
		or ::NTV2_FRAMEBUFFER_ORIENTATION_BOTTOMUP (reverse). 
		Call CNTV2Card::GetFrameBufferOrientation to determine the current <b>Frame Buffer Orientation</b>
		setting. Call CNTV2Card::SetFrameBufferOrientation to change it.

	Some AJA devices have only one Frame Store, so that device is limited to Capturing or Playing
	one single stream of video at a time.

	Some older AJA devices with two Frame Stores dedicate the first to ::NTV2_MODE_CAPTURE and the other
	to ::NTV2_MODE_DISPLAY.

	@note	In NTV2 parlance, the terms <b>Channel</b> and <b>Frame Store</b> are often used interchangeably.

	Multi-channel devices can simultaneously and independently ingest or playout video, and have
	independent control of which SDRAM frame(s) will be read or writen with video.

	In the SDK, Frame Stores are identified by an ::NTV2Channel enumeration and sometimes by a zero-based
	unsigned integer value, where zero corresponds to ::NTV2_CHANNEL1.
	-	Call ::NTV2DeviceGetNumFrameStores to determine the number of Frame Stores on a given device.
		This will tell you how many Channels are available for simultaneous Capture and/or Playout streams.


	@subsection	independentmode		Multi-Format / “Independent” Mode

	<b>Multi-Format Mode</b>, also known as “Independent” mode, is a device capability in which it can
	simultaneously operate more than one stream, with each having a different video format.
	Devices having this capability that are in this mode are able to use a different ::NTV2VideoFormat
	on each Frame Store.

	This differs from prior device capability. For example, assuming there was sufficient DMA and processor
	bandwidth on the host, the \ref corvid24 could simultaneously ingest two video streams, and playout
	another two video streams — but all four streams must have the identical ::NTV2VideoFormat.

	In <b>Multi-Format Mode</b>, for example, assuming sufficient PCIe and host processor bandwidth,
	the \ref corvid44 could simultaneously ingest ::NTV2_FORMAT_720p_5000 and ::NTV2_FORMAT_525_5994 while
	playing ::NTV2_FORMAT_1080p_2997 and ::NTV2_FORMAT_720p_5994.

	The relevant SDK calls:
	-	Call ::NTV2DeviceCanDoMultiFormat to determine if a device is capable of simultaneously streaming
		multiple, different video formats.
	-	Call CNTV2Card::GetMultiFormatMode to find out if the device is currently operating in Multi-Format
		Mode or not.
	-	Call CNTV2Card::SetMultiFormatMode to change the mode.

	@note	This “Independent Mode” doesn’t mean that the FrameStores cannot interfere with each other’s
			frame buffer memory. FrameStores have equal access to any frame buffer in device SDRAM.
			Therefore, if you use frame buffers 0…5 for Channel 1, you must take care to <i>not</i> use
			frames 0…5 for any other channel on the device (unless you have good reason to do so).
			See \ref vidop-fbconflict (below) for more information.

	@note	In <b>Multi-Format Mode</b>, because NTV2 devices only have one hardware clock for driving the
			outputs, all <i>output</i> video formats must be in the same <b>Clock Family</b>.
			Call ::IsMultiFormatCompatible(const NTV2VideoFormat, const NTV2VideoFormat) to find out if two
			video formats are multi-format compatible.
			Call ::IsMultiFormatCompatible(const NTV2FrameRate, const NTV2FrameRate) to see if two frame
			rates are multi-format compatible.
			Call ::GetFrameRateFamily to determine the <b>Clock Family</b> that a given ::NTV2FrameRate
			belongs to. See \ref deviceclockingandsync for more details (below).


	@subsection	vidop-fbaccess		Frame Buffer Access

	Data can be transferred to or from the device at any time using the DMA API in the CNTV2Card class.

	Remember that <b>the host computer always has access to frame memory</b>. Therefore
	it’s important to synchronize or gate transfers to/from the host using the vertical blanking
	interrupt (e.g., CNTV2Card::WaitForOutputVerticalInterrupt, CNTV2Card::WaitForOutputFieldID,
	CNTV2Card::WaitForInputVerticalInterrupt, CNTV2Card::WaitForInputFieldID, etc.).

	The device’s current line counter could also be used (i.e., by monitoring the ::kRegLineCount register
	via CNTV2Card::ReadLineCount), but that value reflects the read/write line position of Frame Store 1.
	Other Frame Stores do not have Line Counters.

	There are several DMA API functions for transferring data between host memory and device SDRAM.
	They are <b>frame-centric</b> in that they all require a zero-based frame number to calculate
	where to start reading or writing in device SDRAM. The actual byte offset into device SDRAM
	depends on the device’s current <b>Frame Size</b> — whether 8MB, 16MB, or larger.

	-	Call CNTV2Card::DMAReadFrame or CNTV2Card::DMAWriteFrame to transfer frame data from or to
		device SDRAM (respectively).
	-	<b>Frame Number</b> — If non-zero, it will index into device SDRAM by ::NTV2Framesize frames.
		See the <b>Frame Buffer Layout</b> discussion in the \ref hardwarecharacteristics
		section for more information.
	-	<b>Byte Count:</b>
		-	Should be even, or evenly divisible by 4, or ideally a power of two.
		-	Small transfers can sometimes be problematic for certain DMA engine firmware in combination
			with certain host hardware and OS platforms.  To avoid this, AJA recommends transferring at
			least 4096 bytes of data. Try smaller values if necessary, but test thoroughly with the
			devices and hardware you intend to support.
		-	It can be larger than a frame. For example, if the device frame size is 8MB, and the
			requested byte count is 16MB, two frames will be transferred.
	-	CNTV2Card::DMARead and CNTV2Card::DMAWrite are similar, but also accept a <b>Byte Offset</b>,
		which…
		-	Should be even, or evenly divisible by 4, or ideally a power of two.
		-	<b>Hint:</b> All device SDRAM can be accessed by using a zero <b>Frame Number</b> and
			using any offset value needed (up to 4GB minus the <b>Byte Count</b>).

	@warning	Calling CNTV2Card::DMAWriteFrame at a fraction of frame time <i>after</i>
				the VBI to write the same frame on the device that’s being read for the currently-playing
				video frame will likely look torn or distorted.
				Likewise for the opposite — i.e., calling CNTV2Card::DMAReadFrame at a
				fraction of frame time after or before the VBI to read the same frame being written
				by the Frame Store from the currently incoming video frame would result in some lines
				having pixel data from the new, incoming frame, while the remaining lines would contain
				old pixel data.

	@note	DMA transfer speeds may be affected by the amount of video data being accessed by
			the device to transmit video. If a channel is in display mode, it is always playing
			video, and therefore reading from SDRAM, consuming SDRAM bandwidth… the amount consumed
			determined by the amount of data being read from frame memory… which depends on Frame
			Buffer Format and Frame Geometry. <b>In some cases, DMA speeds can be increased by
			disabling unused channels</b> (see CNTV2Card::DisableChannel). Disabling unused channels
			is especially useful when using larger video & frame buffer formats, which use significant
			SDRAM bandwidth to read frame data for playout. In addition to the fact that more data is
			moved in, say, 48-bit RGB (than YUV8), the transfer of that data may also proceed at a
			slightly slower rate.

	@warning	Accessing memory addresses that are beyond the end of device SDRAM is not recommended,
				and will result in unexpected behavior — e.g. wrapping around and continuing from the
				start of device SDRAM.


	@subsection	deviceclockingandsync		Device Clocking and Synchronization

	-	NTV2 devices have <i>one</i> output clock that drives <i>all</i> SDI outputs.
	-	When SDI output(s) are routed and connected, then device/output synchronization <i>must</i> be considered.

	@subsubsection  devclock-capture	“Capture-Only”

	On multiformat-capable devices (see ::NTV2DeviceCanDoMultiFormat) in <b>Capture</b> mode, the device firmware will calculate each input
	signal’s timing independently. If these signals are routed to FrameStores that are operating in
	<b>Capture</b> mode, the FrameStores will each signal VBIs independently at the correct time.
	For example:
	@image	html	hwref-inputtiming.png
	-	Repeated calls to <tt>CNTV2Card::WaitForInputVerticalInterrupt(NTV2_CHANNEL2)</tt> will occur at 50Hz;
	-	Repeated calls to <tt>CNTV2Card::WaitForInputVerticalInterrupt(NTV2_CHANNEL3)</tt> will occur at 24Hz.

	On older, uniformat devices, the input signals can still be captured independently, but they must be
	in the same frame rate “family” (i.e. <b>Clock Family</b>) as the overall device video format:<br>
	<b>Related Clock Families:</b>
	-	24 / 48
	-	25 / 50 (PAL)
	-	29.97 / 59.94 (NTSC)
	-	30 / 60 / 120

	@subsubsection  devclock-inout		“Capture &amp; Playout”

	Add a route from FrameStore4 to SDIOut4, configuring the FrameStore for 1080i2997 playout:
	@image	html	hwref-inputoutputsync.png
	In this scenario, there are now three output synchronization options:
	-#	Clock the output signal independently of the inputs and any other reference using the device’s
		internal clock. In this case, call CNTV2Card::SetReference with ::NTV2_REFERENCE_FREERUN.
	-#	Sync the outputs to a 29.97Hz (or 59.94Hz) external reference. For this case, call
	 	CNTV2Card::SetReference with ::NTV2_REFERENCE_EXTERNAL.
	-#	Sync the outputs to one of the SDI inputs. But note that this option is not viable in this
		example, because none of the input signals have 2997 or 5994 timing.

	If multiple input signals from the same <b>Clock Family</b> are feeding the device, it’s probably
	impossible to lock to them all, unless they’re all sync’d to a common timebase (often called “house
	reference”) … otherwise, the signals will all drift over time with respect to each other.
	For example, one signal may just be starting a new frame, while another is already half-way through
	its frame. Since the device clock can’t lock to more than one of them, ::NTV2_REFERENCE_FREERUN must
	be used, to clock the outputs from the device’s own internal clock source. Note that setting “free
	run” isn’t technically necessary — the application would run just as well locked to one of the input
	signals, with the only difference being when the output signals would actually come out of the BNCs.

	@subsubsection  devclock-ee			“End-to-End” (“E-E”)

	Add a route from SDIIn2 to SDIOut4 (assume this route is actually implemented in the firmware):
	@image	html	hwref-ee-sync.png
	This can be done either directly, as shown, or indirectly (for example, through a Mixer/Keyer widget).
	This requires the device’s output timing to be locked to the input signal. In this case, call
	CNTV2Card::SetReference with ::NTV2_REFERENCE_INPUT2.

	When the reference source is set to an SDI input, the output signal(s) will be locked to the same
	timebase as that of the designated source’s signal. For this to work, the output video format must
	have a frame rate in the same <b>Clock Family</b> as that being received at the SDI input. The actual
	output signal will exit the BNCs with about 2~3 lines of delay due to signal propagation through
	device circuitry, but the important point is that the phase relationship between the reference
	input signal and the output signal will be fixed, and will not drift.

	@note	For historical reasons, if SDI Input 1 is used for input and a signal is present,
			its signal frame rate dictates the <b>Clock Family</b> for all SDI outputs. When operating
			the device in multiformat mode, it’s therefore best to always use NTV2_CHANNEL1 as
			an output/playout channel, and use the other channels for input, as they don’t have
			the <b>Clock Family</b> restriction or any effect on the outputs.

	@subsubsection  devclock-extern		External Reference

	If the device’s output(s) must have a given timing (e.g., to feed a switcher), then applications
	can pass ::NTV2_REFERENCE_EXTERNAL to CNTV2Card::SetReference, which will lock the device to an
	analog or tri-level sync signal connected to the device’s external reference input.

	To determine the video format of the signal being applied to the reference input, call
	CNTV2Card::GetReferenceVideoFormat.

	@note	When configured for ::NTV2_REFERENCE_EXTERNAL, the device output will internally revert
			to Free-Run if the reference signal disappears or is incompatible with the output video
			format. When there’s no signal detected at the external reference connector, AJA
			recommends setting the device reference to ::NTV2_REFERENCE_FREERUN.


	@subsection	fieldframeinterrupts	Field/Frame Interrupts

	Many device hardware registers are updated on the video frame sync (i.e. the VBI associated with
	the start of a new frame). This is determined by the FrameStore’s ::NTV2RegisterWriteMode and is
	normally set to ::NTV2_REGWRITE_SYNCTOFRAME.

	For example, CNTV2Card::SetInputFrame is called by the client application to instruct the device’s
	FrameStore to write the next video frame that arrives into a specific frame buffer number in device
	memory. The function call immediately changes the Frame Store’s input frame register, but internally,
	the device firmware ensures that the FrameStore uses the new frame number value at the next ::NTV2_FIELD0
	(first field in time) sync pulse. (To avoid a race condition, though, the client application must wait
	for the VBI, which gives it an entire frame time to update hardware registers and configure the
	device widget settings that are required for the next frame to be processed.)

	For interlaced video, where the frame is transmitted as two fields, each field contains every other line
	of the frame. For HD video, the first field in time contains the first active line of the frame (i.e. the
	“top field” <i>a.k.a.</i> ::NTV2_FIELD0 <i>a.k.a.</i> <b>F1</b>); the second field contains the last
	active line of the frame (i.e. the “bottom field” <i>a.k.a.</i> ::NTV2_FIELD1 <i>a.k.a.</i> <b>F2</b>).
	Each field starts with a video sync — however, normally, in ::NTV2_REGWRITE_SYNCTOFRAME mode, the hardware
	registers are only updated at the ::NTV2_FIELD0 sync. Each of the syncs (::NTV2_FIELD0 and ::NTV2_FIELD1 )
	signals an interrupt to the driver, but CNTV2Card::WaitForInputFieldID (or CNTV2Card::WaitForOutputFieldID)
	check a hardware register and return only when the requested ::NTV2FieldID is detected.

	The FrameStore can alternatively be configured for <b>Field Mode</b> by passing ::NTV2_REGWRITE_SYNCTOFIELD
	into CNTV2Card::SetRegisterWriteMode, which causes calls to CNTV2Card::SetInputFrame or CNTV2Card::SetOutputFrame
	to take effect at the next <b>field</b> interrupt. In this mode of operation, the client application must wait
	for the next field interrupt – not frame interrupt – which gives it half the frame time to prepare/configure
	the device for the next field to be processed.

	For progressive video, all syncs are flagged by the hardware as ::NTV2_FIELD0 syncs, so registers
	are updated for the next frame and the CNTV2Card::WaitForInputFieldID (or CNTV2Card::WaitForOutputFieldID)
	work as expected.

	To wait for an event (such as a VBI) from a particular FrameStore, your application should subscribe
	to it by calling CNTV2Card::SubscribeInputVerticalEvent or CNTV2Card::SubscribeOutputVerticalEvent.

	Once subscribed, to efficiently wait for an input vertical interrupt, call CNTV2Card::WaitForInputFieldID or
	CNTV2Card::WaitForInputVerticalInterrupt, referencing the Frame Store that’s configured for capture,
	and that’s routed (directly or indirectly) from an input that has a valid video signal.

	To efficiently wait for an output vertical interrupt, call CNTV2Card::WaitForOutputFieldID or
	CNTV2Card::WaitForOutputVerticalInterrupt, referencing the Frame Store that’s configured for playout.

	The number of input or output vertical events that have successfully been waited on and fired can be obtained
	by calling CNTV2Card::GetInputVerticalEventCount or CNTV2Card::GetOutputVerticalEventCount.
	By calling either of these methods before and after calling the “wait for input/output” function, you
	can determine if indeed the interrupt event actually triggered. Call CNTV2Card::SetInputVerticalEventCount
	or CNTV2Card::SetOutputVerticalEventCount to reset the tally counter.

	Normally it’s not necessary to explicitly unsubscribe the CNTV2Card instance’s event subscriptions, as
	its destructor automatically calls CNTV2Card::Close.

	@note	On the <b>Windows</b> platform, the AJA NTV2 driver supplies a finite number of event subscription handles
			to client applications, which get consumed when subscribed (via CNTV2Card::SubscribeInputVerticalEvent,
			CNTV2Card::SubscribeOutputVerticalEvent, CNTV2Card::SubscribeEvent). They’re made available
			again to other clients when unsubscribed (via CNTV2Card::UnsubscribeInputVerticalEvent,
			CNTV2Card::UnsubscribeOutputVerticalEvent, CNTV2Card::UnsubscribeEvent), and automatically when
			the CNTV2Card object is closed or destroyed (via CNTV2Card::Close). However, abnormal program
			terminations, crashes, or force-quitting from a debugger will prevent this handle clean-up,
			which, after many repetitions of this, can result in their exhaustion. The are three ways to
			recover from this: 1) Reboot the machine. 2) Manually disabling and re-enabling the AJA driver
			(after closing all running NTV2 client applications, including the AJA Service. 3) Set virtual
			register kVRegClearAllSubscriptions to a non-zero value (this can be easily done in NTV2Watcher’s
			\ref inspectorregs ).


	@subsection	vidop-fbconflict	When Frame Stores Access the Same Frame Buffer Memory

	Note that it’s possible (and quite easy) to have two or more Frame Stores accessing the same
	frame buffer memory.

	Here’s an example where this would be really bad:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signals at SDI Inputs 1 and 2
			//	(same video format, different content)...
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.SetInputFrame(NTV2_CHANNEL1, 0);	//	Write FrameStore 1 video into frame buffer 0

			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_CAPTURE);	//	Set FrameStore 2 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL2, false);	//	Set SDI connector 2 to capture
			device.Connect(NTV2_XptFrameBuffer2Input, NTV2_XptSDIIn2);	//	Connect SDI In 2 to FrameStore 2
			device.SetInputFrame(NTV2_CHANNEL2, 0);	//	Write FrameStore 2 video into frame buffer 0
		}
	@endcode
	In this case, there are two video signals fighting to write video rasters into the same frame memory on the device.
	If this frame were to be transferred to host memory, the image would look torn, a bad mixture of frames from SDI inputs 1 and 2.

	On the other hand, Frame Stores sharing the same frame buffer memory can be beneficial, for example, as a <b>Frame Synchronizer</b>.
	Here’s an example of how to synchronize an SDI signal with the AJA device’s free-running output clock:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has a valid video signal at SDI Input 1:
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.SetInputFrame(NTV2_CHANNEL1, 0);	//	Write FrameStore 1 video into frame buffer 0

			device.SetReference(NTV2_REFERENCE_FREERUN);	//	Free run the outputs
			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_DISPLAY);	//	Set FrameStore 2 to playout mode
			device.SetOutputFrame(NTV2_CHANNEL2, 0);	//	Read FrameStore 2 video from frame buffer 0
			device.SetSDITransmitEnable(NTV2_CHANNEL3, true);	//	Set SDI connector 3 to output
			device.Connect(NTV2_XptSDIOut3Input, NTV2_XptFrameBuffer2YUV);	//	Connect FrameStore 2’s output to SDI Out 3
		}
	@endcode

	When AutoCirculate is used, AutoCirculate manages the Frame Store’s InputFrame register (capture) or OutputFrame register (playout),
	repeatedly circulating it from the <b>Start Frame</b> to the <b>End Frame</b> (e.g., 0 thu 6).
	Another Frame Store can very easily write into any of the frames involved in another Frame Store’s AutoCirculate frame range.
	For example:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signals at SDI Inputs 1 and 2
			//	(same video format, different content)...
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1
			device.AutoCirculateInitForInput(NTV2_CHANNEL1, 0, NTV2_AUDIOSYSTEM_INVALID, 0, 1, 0, 6);	//	AutoCirculate capture into FBs 0/1/2/3/4/5/6
			device.AutoCirculateStart(NTV2_CHANNEL1);	//	Start AutoCirculate (assume another thread calls AutoCirculateTransfer)

			//	UH-OH:  This code block will cause 1 of every 7 frames captured via AutoCirculate
			//			on NTV2_CHANNEL1 to be corrupted by video from SDI Input 2...
			device.EnableChannel(NTV2_CHANNEL2);	//	Enable FrameStore 2
			device.SetMode(NTV2_CHANNEL2, NTV2_MODE_CAPTURE);	//	Set FrameStore 2 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL2, false);	//	Set SDI connector 2 to capture
			device.Connect(NTV2_XptFrameBuffer2Input, NTV2_XptSDIIn2);	//	Connect SDI In 2 to FrameStore 2
			device.SetInputFrame(NTV2_CHANNEL2, 3);	//	Write FrameStore 2 video into frame buffer 3
		}
	@endcode


	<hr size="50px">
	@subsection	vidop-csc		Color Space Converter Operation

	A <b>Color Space Converter</b> (a.k.a. <b>CSC</b>) is a device widget implemented in FPGA firmware that converts YCbCr values
	into RGB[A] values, or vice-versa. It uses several registers to configure its conversion properties.

	-	Generally, there is one CSC for every SDI connector. ::NTV2DeviceGetNumCSCs can be used to determine the number
		of CSCs on a given device, which should match ::NTV2DeviceGetNumVideoInputs or ::NTV2DeviceGetNumVideoOutputs (whichever is larger).
	-	CSC widgets are identified by ::NTV2_WgtCSC1, ::NTV2_WgtCSC2, etc.,
		but are normally identified in SDK calls by an ::NTV2Channel value that represents a zero-based index number.
	-	Each CSC has two inputs:
		-	<b>Video Input</b>:  This input should be routed to another widget’s output that produces…
			-	YCbCr video — in which case the CSC will produce valid RGB[A] data at its <b>RGB Video</b> output.
			-	RGB[A] video — in which case the CSC will produce valid YCbCr video at its <b>YUV Video</b> output,
				and alpha channel video at its <b>Key YUV</b> output.
		-	<b>Key Input</b>:  This supplies alpha channel data for the CSC’s <b>RGB Video</b> output. When used,
			it should always be sourced with YCbCr video (never RGB).
	-	Each CSC has 3 outputs:
		-	<b>YUV Video</b>:  This produces valid YCbCr video data only when the CSC’s <b>Video Input</b> is receiving RGB[A] video.
		-	<b>RGB Video</b>: This produces valid RGB[A] video data only when the CSC’s <b>Video Input</b> is receiving YCbCr video.
		-	<b>Key YUV</b>:  This produces valid YCbCr key data only when the CSC’s <b>Video Input</b> is receiving RGB[A] video.
	-	Routing instructions are in the \ref widget_csc section in the \ref ntv2signalrouting section.
	-	The CSC’s conversion coefficients are adjusted based on “SMPTE” versus “Full” range.
		-	The conversion range is represented in the SDK as the ::NTV2RGBBlackRange or ::NTV2_CSC_RGB_Range data types.
		-	Full range is represented by the ::NTV2_CSC_RGB_RANGE_FULL or ::NTV2_RGBBLACKRANGE_0_0x3FF enumerations.
			-	8-bit Full Range has 256 possible values (0 thru 255)
			-	10-bit Full Range has 1024 possible values (0 thru 1023).
		-	SMPTE range is represented by the ::NTV2_CSC_RGB_RANGE_SMPTE or ::NTV2_RGBBLACKRANGE_0x40_0x3C0 enumerations.
			-	8-bit SMPTE-range has 220 possible values (16 thru 235).
			-	10-bit SMPTE-range has 877 possible values (64 thru 940).
		-	Call CNTV2Card::GetColorSpaceRGBBlackRange to determine the current range setting for a CSC.
		-	Call CNTV2Card::SetColorSpaceRGBBlackRange to change a CSC’s range setting.
	-	The CSC’s conversion matrix can be set to “Rec. 601” (SD) or “Rec. 709” (HD).
		-	The conversion matrix type is represented in the SDK by the ::NTV2ColorSpaceMatrixType data type.
		-	Rec. 601 is represented by the ::NTV2_Rec601Matrix enumeration constant.
		-	Rec. 709 is represented by the ::NTV2_Rec709Matrix enumeration constant.
		-	Call CNTV2Card::GetColorSpaceMatrixSelect to determine the current matrix selection for a CSC.
		-	Call CNTV2Card::SetColorSpaceMatrixSelect to change a CSC’s matrix selection.

	@par	YCbCr to RGB Conversion

	-	When the CSC’s <b>Video Input</b> is connected to a YUV video source, it will convert and provide RGB data on
		its “RGB” output crosspoint.
	-	In addition to the YCbCr-to-RGB value conversion, the CSC also performs the necessary 4:2:2 up-sampling to fill the
		“missing” pixels in the outgoing RGB raster.
	-	The CSC will produce an <i>opaque</i> alpha channel by default.
	-	It can produce alpha channel data from YCbCr video supplied to its <b>Key Input</b> (using just the luma channel) —
		provided it’s configured to do so:
		-	Call CNTV2Card::GetColorSpaceMakeAlphaFromKey to determine if the CSC will use its <b>Key Input</b> to generate
			alpha channel data.
		-	Call CNTV2Card::SetColorSpaceMakeAlphaFromKey to enable or disable the setting.
		-	When “Make Alpha From Key” is enabled, call CNTV2Card::GetColorSpaceVideoKeySyncFail to query if the CSC’s
			<b>Key Input</b> is synchronized with its <b>Video Input</b>. Sync failure will occur if the Key and Video
			signals have unrelated frame rates, or are significantly out of phase with each other.

	The conversion formulæ:
	@code{.cpp}
		// Full-range 8-bit “Rec 601” (SD) conversion:
		R = 1.164384 * y  +  0.000000 * cb  +  1.596027 * cr;
		G = 1.164384 * y  -  0.391762 * cb  -  0.812968 * cr;
		B = 1.164384 * y  +  2.017232 * cb  +  0.000000 * cr;

		// SMPTE-range 8-bit “Rec 601” (SD) conversion:
		R = 1.000000 * y  +  0.000000 * cb  +  1.370705 * cr;
		R = 1.000000 * y  -  0.336455 * cb  -  0.698196 * cr;
		R = 1.000000 * y  +  1.732446 * cb  +  0.000000 * cr;

		// Full-range 10-bit “Rec 601” (SD) conversion:
		R = 1.167808 * y  +  0.000000 * cb  +  1.600721 * cr;
		G = 1.167808 * y  -  0.392915 * cb  -  0.815359 * cr;
		B = 1.167808 * y  +  2.023165 * cb  +  0.000000 * cr;

		// SMPTE-range 10-bit “Rec 601” (SD) conversion:
		R = 1.0000008 * y  +  0.000000 * cb  +  1.370705 * cr;
		G = 1.0000008 * y  -  0.336455 * cb  -  0.698196 * cr;
		B = 1.0000008 * y  +  1.732446 * cb  +  0.000000 * cr;

		// Full-range 10-bit “Rec 709” (HD) conversion:
		R = 1.167808 * y  +  0.000000 * cb  +  1.798014 * cr;
		G = 1.167808 * y  -  0.213876 * cb  -  0.534477 * cr;
		B = 1.167808 * y  +  2.118615 * cb  +  0.000000 * cr;

		// SMPTE-range 10-bit “Rec 709” (HD) conversion:
		R = 1.000000 * y  +  0.000000 * cb  +  1.539648 * cr;
		G = 1.000000 * y  -  0.183143 * cb  -  0.457675 * cr;
		B = 1.000000 * y  +  1.814180 * cb  +  0.000000 * cr;
	@endcode

	@note	The 8-bit and 10-bit coefficients are NOT the same, since the RGB 10-bit white point (1023)
			is not simply 4 × the 8-bit RGB white point (255).

	@par	RGB to YCbCr Conversion

	-	When the CSC’s <b>Video Input</b> is fed RGB[A] video, it will convert and provide YUV data on
		its “Video” and “Key” output crosspoints.
	-	In addition to the RGB-to-YCbCr value conversion, it also performs the necessary 4:2:2 down-sampling
		(implemented as a low-pass filter) for the fewer samples in the outgoing YUV raster.
	-	The <b>Key Output</b> luma channel data is scaled appropriately from the incoming alpha channel data.
		Its outgoing Cb and Cr component values are fixed at <tt>0x200</tt>.

	The conversion formulæ:
	@code{.cpp}
		// Full-range 10-bit “Rec 601” (SD) conversion:
		Y  =  0.25604 * r  +  0.50265 * g  +  0.09762 * b;
		Cb = -0.14779 * r  -  0.29014 * g  +  0.43793 * b;
		Cr =  0.43793 * r  -  0.36671 * g  -  0.07122 * b;

		// SMPTE-range 10-bit “Rec 601” (SD) conversion:
		Y  =  0.29900 * r  +  0.58700 * g  +  0.11400 * b;
		Cb = -0.17259 * r  -  0.33883 * g  +  0.51142 * b;
		Cr =  0.51142 * r  -  0.42825 * g  -  0.08317 * b;

		// Full-range 10-bit “Rec 709” (HD) conversion:
		Y  =  0.18205 * r  +  0.61243 * g  +  0.06183 * b;
		Cb = -0.10035 * r  -  0.33758 * g  +  0.43793 * b;
		Cr =  0.43793 * r  -  0.39777 * g  -  0.04016 * b;

		// SMPTE-range 10-bit “Rec 709” (HD) conversion:
		Y  =  0.21260 * r  +  0.71520 * g  +  0.07220 * b;
		Cb = -0.11719 * r  -  0.39423 * g  +  0.51142 * b;
		Cr =  0.51142 * r  -  0.46452 * g  -  0.04689 * b;
	@endcode

	@par	Enhanced CSCs

	Some AJA devices support “enhanced” CSC firmware that is used to override the default Rec 601 and Rec 709 conversion
	offsets and coefficients.  Call ::NTV2DeviceCanDoEnhancedCSC to determine if the device has the enhanced CSC firmware.


	<hr size="50px">
	@subsection	vidop-lut		LUT Operation

	A color <b>Look Up Table</b> (a.k.a. <b>LUT</b>) is a device widget implemented in FPGA firmware that converts specific
	input RGB values into other corresponding RGB values. It uses several registers to configure its conversion properties
	and a contiguous bank of registers for reading or writing the conversion table.

	@note	<b>LUT</b>s only work with RGB video, not YCbCr.

	-	For devices that have <b>LUT</b>s, there is usually one <b>LUT</b> for every Frame Store and/or SDI Input (or Output).
		Call ::NTV2DeviceGetNumLUTs to obtain the number of available <b>LUT</b>s.
	-	<b>LUT</b> widgets are identified by ::NTV2_WgtLUT1, ::NTV2_WgtLUT2, …, but are normally identified in SDK calls
		by ::NTV2Channel, a zero-based, unsigned index number.
	-	Each <b>LUT</b> widget has one input that only accepts RGB video.
	-	Each <b>LUT</b> widget has two outputs — <b>YUV</b> and <b>RGB</b> — that carry the converted video.
		The <b>YUV</b> output carries the luminance of the converted video in the <b>Y</b> channel.
	-	The ::NTV2DeviceGetLUTVersion function returns the version number of the <b>LUT</b> widget firmware implementation.
	-	The conversion is performed on a per-component basis using 10 bits of precision.
	-	The 10-bit Red, Green, or Blue component value (<tt>0x000</tt> thru <tt>0x3FF</tt>) is used as the index into
		the respective R, G, or B table to fetch the converted output value, another 10-bit value in the range
		<tt>0x000</tt> thru <tt>0x3FF</tt>.
	-	<b>LUT</b>s have two independent banks, only one of which is actively converting input video.
		-	A bank is identified by an integer value — <b>0</b> or <b>1</b>.
		-	To determine which bank is currently active for a given LUT, call CNTV2Card::GetColorCorrectionOutputBank.
		-	To switch the active LUT bank, call CNTV2Card::SetColorCorrectionOutputBank.
	-	There is currently no API call that reads the Red, Green and/or Blue conversion table values for a particular bank
		of a given LUT. (It can be done, but a control register must be configured before and after calling CNTV2Card::ReadLUTTables.)
	-	To change the Red, Green and/or Blue conversion table values for a particular bank:
		-	Build a 1,024-element <tt>std::vector</tt> of <b>UWord</b> or <b>double</b> values for each R, G and/or B
			component. Each value in the array should be in the range <tt>0 - 1023</tt> or <tt>0.00 - 1023.00</tt>, respectively.
		-	Call CNTV2Card::DownloadLUTToHW. The array values will automatically be clamped to the legal range <tt>0x000</tt>
			thru <tt>0x3FF</tt> prior to being written to the device.
	-	Some newer device firmware supports 12-bit LUTs. In 12-bit mode, the LUT table is expanded in size to 4,096 values
		per component, and the legal (output) values assume the range <tt>0x000 - 0xFFF</tt>.
	-	See \ref widget_lut for a discussion on how to route signals to and from <b>LUT</b> widgets.
	-	The NTV2Watcher toolʼs \ref inspectorlut can be used to inspect and/or modify <b>LUT</b> configuration.

	@note	The reading and writing of any 10-bit “version 2” LUT bank table data flows through registers 512-2047,
			with host access controlled by register 376 (<tt>kRegLUTV2Control</tt>). There is no software mutex
			guarding access to this register, so calls to read or write the tables are not thread-safe.

	<hr size="50px">
	@subsection	vidop-mixerkeyer		Mixer/Keyer Operation

	A <b>Mixer/Keyer</b> is a device widget implemented in FPGA firmware that mixes or “keys” YCbCr video.
	It uses a pair of registers for configuring its mixing/keying properties.

	@note	Mixer/Keyer widgets can only process YCbCr video — not RGB[A].

	-	Generally, there is one mixer/keyer for every 2 Frame Stores and/or SDI Inputs (or SDI Outputs).
		Call ::NTV2DeviceGetNumMixers to obtain the number of Mixer/Keyer widgets that are available.
	-	Mixer/Keyer widgets are identified by ::NTV2_WgtMixer1, ::NTV2_WgtMixer2, …,
		but are normally identified in SDK calls by a zero-based, unsigned 16-bit index number.
	-	Each Mixer/Keyer has two outputs — <b>Video</b> and <b>Key</b> — that contain the mixed/keyed output video.
	-	Each Mixer/Keyer has four inputs:
		-	two <b>Foreground</b> inputs — <b>Video</b> and <b>Key</b> — and…
		-	two <b>Background</b> inputs — <b>Video</b> and <b>Key</b>.
		-	<b>Key Input</b>s only utilize Y-channel data — the Cb and Cr components are ignored.
		-	<b>IMPORTANT:</b> The Mixer’s foreground and background inputs must be closely synchronized
			or the Mixer won’t be able to mix them. If the Mixer is unlocked, its outputs will send unclocked
			(garbage) video.
			-	Call CNTV2Card::GetMixerSyncStatus to determine if the Mixer is locked to both of its inputs,
				and therefore if its output is valid.
	-	Each Mixer/Keyer has the following configuration parameters:
		-	::NTV2MixerKeyerMode — Primary operating mode:
			-	Use ::NTV2MIXERMODE_FOREGROUND_ON to exclusively pass the <b>foreground</b> video and key to the Mixer output.
			-	Use ::NTV2MIXERMODE_FOREGROUND_OFF to exclusively pass the <b>background</b> video and key to the Mixer output.
			-	Use ::NTV2MIXERMODE_MIX to overlay the foreground video on top of the background video. Foreground or background
				<b>Flat Matte</b> (see below), if enabled, will be mixed instead of its respective input raster.
			-	Call CNTV2Card::GetMixerMode to determine the Mixer’s current mode.
			-	Call CNTV2Card::SetMixerMode to change its mode.
		-	::NTV2MixerKeyerInputControl — input control mode, one for foreground input, one for background input:
			-	::NTV2MIXERINPUTCONTROL_FULLRASTER ignores the input key.
			-	::NTV2MIXERINPUTCONTROL_SHAPED uses the input key as a mask.
			-	Call CNTV2Card::GetMixerFGInputControl to discover the foreground input’s current control value.
			-	Call CNTV2Card::SetMixerFGInputControl to change the foreground input’s control value.
			-	Call CNTV2Card::GetMixerBGInputControl to discover the background input’s current control value.
			-	Call CNTV2Card::SetMixerBGInputControl to change the background input’s control value.
		-	<b>Mix Coefficient</b> — an unsigned, 16-bit integer that determines the transparency of the foreground mask/key.
			-	Call CNTV2Card::GetMixerCoefficient to determine the current mix coefficient value.
			-	Call CNTV2Card::SetMixerCoefficient to change its value.
		-	<b>Output VANC Source</b> — The Mixer’s output video VANC can be sourced from the foreground
			or background input video.
			-	Call CNTV2Card::GetMixerVancOutputFromForeground to determine if the output VANC is currently
				being sourced from the foreground video input.
			-	Call CNTV2Card::SetMixerVancOutputFromForeground to change the output VANC source.
		-	<b>Flat Matte</b> — The Mixer’s foreground or background raster can be set to a flat matte of any
			10-bit YCbCr color. This matte will override any respective video input to the Mixer.
				-	Call CNTV2Card::GetMixerFGMatteEnabled to determine if the foreground matte is enabled or not.
				-	Call CNTV2Card::SetMixerFGMatteEnabled to enable or disable using the foreground matte.
				-	Call CNTV2Card::GetMixerBGMatteEnabled to determine if the background matte is enabled or not.
				-	Call CNTV2Card::SetMixerBGMatteEnabled to enable or disable using the background matte.
				-	Do not enable <b>Flat Matte</b> on both foreground and background — use one or the other, or neither.
				-	Call CNTV2Card::GetMixerMatteColor to determine the current matte color.
				-	Call CNTV2Card::SetMixerMatteColor to change the matte color.
				-	Note that to retain sync and enable its video output, the Mixer still requires a foreground
					video source if background matte is enabled, or a background video source if foreground
					matte is enabled.
	-	For information on how to route signals to and from the Mixer, see \ref widget_mixkey.
	-	The \ref usingntv2watcher tool’s \ref inspectormixerkeyer allows you to interactively view each Mixer/Keyer
		widget’s current configuration, as well as make changes to it.



	<hr size="50px">
	@section	audiooperation		Audio System Operation

	<b>Audio Systems</b>
	-	NTV2-compatible devices have a minimum of one <b>Audio System</b> (sometimes referred to as an <b>Audio Engine</b>).
	-	An <b>Audio System</b> makes it possible to stream audio, whether in <b>Capture</b> (Record) mode,
		or <b>Playout</b> mode, or both.
	-	Call ::NTV2DeviceGetNumAudioSystems to determine the number of <b>Audio System</b>s on a device.

	<b>Firmware Implementation</b>
	-	An <b>Audio System</b> is implemented in FPGA firmware using several hardware registers,
		which together perform the following functions:
		-	If it has any SDI, HDMI, analog, or AES inputs (see ::NTV2DeviceCanDoCapture):
			-	It continually de-embeds 20/24-bit AES audio samples. For SDI inputs, these will come from SMPTE 272M/299M HANC packets
				detected in the SDI input stream.
			-	If the <b>Capture</b> aspect of the <b>Audio System</b> is <i>Running</i>, it will write the de-embedded
				audio samples into its input audio buffer in device SDRAM.
			-	The audio samples can always be piped through a FIFO to source an <b>Audio System</b>’s output audio
				embedder for “loopback” play-through.
		-	If it has any SDI, HDMI, analog or AES outputs (see ::NTV2DeviceCanDoPlayback):
			-	Unless its embedder is disabled, it will continually embed 20/24-bit AES audio samples into SMPTE 272M/292M
				HANC packets into its SDI output stream.
			-	When its <b>Playout</b> aspect is <i>Running</i>, it will read from its output audio buffer in device
				SDRAM the audio samples to be embedded.
			-	When its <b>Playout</b> side is not running…
				-	If configured for “loopback” play-through, it obtains audio samples from an
					<b>Audio System</b>’s input audio de-embedder.
				-	Otherwise, it will embed silence (audio packets that contain all-zero sample values).

	<b>Audio Channels</b>
	-	Each <b>Audio System</b> can accommodate at least 8 channels of audio.
	-	Call ::NTV2DeviceGetMaxAudioChannels to determine the maximum number of audio channels that a device’s
		<b>Audio Systems</b> can handle.
	-	Call CNTV2Card::GetNumberAudioChannels to determine how many audio channels a device <b>Audio System</b>
		is currently configured for.
		-	Modern AJA devices will accommodate up to 16 channels.
		-	Very old AJA devices defaulted to 6 channels at power-up — these should be
			configured to use 8 channels.
	-	Call CNTV2Card::SetNumberAudioChannels to change the number of audio channels a device <b>Audio System</b>
		is configured to use.
		@note	AJA recommends configuring the <b>Audio System</b> to use the maximum number of audio channels the
				device is capable of.
	-	<b>HDMI Audio</b> — The HDMI standard supports a minimum baseline of 2 audio channels up to a maximum of 8.
	-	<b>AES/EBU Audio</b> — The AES/EBU connectors (on cables or breakout boxes) support 8 audio channels.
	-	<b>Analog Audio</b> — Analog audio supports 2 audio channels.
	-	The firmware automatically ensures that excess unused audio channels will capture silence or be ignored for
		playout. For example, an <b>Audio System</b> that’s been configured for 16 channels and is recording 2 HDMI
		audio channels will carry the HDMI audio in channels 1 and 2, and contain silence in channels 3 thru 16.
	-	Note that some SDI video formats have substantially reduced HANC capacity, and thus can only carry 8 audio
		channels (e.g. 2K×1080@2997, 2K×1080@30, 4K@29.97, 4K@30). Again, the <b>Audio System</b> can still operate
		in 16-channel mode, but will capture and/or playout silence in channels 9-16.



	<b>Audio Sample Rate</b>
	-	The <b>Sample Rate</b> on all AJA devices is fixed at 48 kHz.
	-	All NTV2 devices implement a 48 kHz <b>Audio Clock</b> that can be sampled through the ::kRegAud1Counter register.
		-	This register is reset to zero at power-on and PCIe reset, and increments every 20.833… µs.
		-	It’s used by \ref aboutautocirculate for precise timing purposes in FRAME_STAMP::acAudioClockTimeStamp,
			FRAME_STAMP::acAudioClockCurrentTime, AUTOCIRCULATE_STATUS::acAudioClockStartTime
			and AUTOCIRCULATE_STATUS::acAudioClockCurrentTime.

	<b>Audio Buffers</b>
	-	Each <b>Audio System</b> uses an 8 MB contiguous block of memory located in the upper part of SDRAM:
		@image	html	hwref-fig2-audiobuffers.png
	-	An NTV2 device will use one of these two memory configurations for its <b>Audio System</b>s’ buffers:
		-	“Stacked” — The first <b>Audio System</b>’s 8 MB chunk starts at the very top of SDRAM,
			such that the last byte of <b>Audio System</b> 1’s <b>Input Buffer</b> coincides with the last addressable
			byte of SDRAM. Subsequent Audio Systems’ buffers stack downward from there, 8 MB each.
		-	“Non-stacked” — These devices use the last one or two video frames for audio storage.
			The first byte of the last <b>Audio System</b>’s <b>Output Buffer</b> coincides with the first byte
			of the last frame buffer in device memory. Previous <b>Audio System</b> buffers, if any, start
			at the next-lower 8MB frame buffer.
	-	Call ::NTV2DeviceCanDoStackedAudio to determine if the device uses the “stacked” arrangement or not.
	-	The first (lower address) 4 MB of the <b>Audio System</b>’s 8 MB chunk is for <b>Audio Output</b>.
	-	The last (higher address) 4 MB of the <b>Audio System</b>’s 8 MB chunk is used for <b>Audio Input</b>.
	-	Each Output or Input aspect of the <b>Audio System</b> operate independently, each being in one of two states:
		-	<b>Stopped</b> — a.k.a. the “Reset” state.
		-	<b>Running</b> — When the Input or Output aspect of the <b>Audio System</b> is Running,
			eight or sixteen channels (see CNTV2Card::GetNumberAudioChannels) of audio are always
			written/read to/from this memory, regardless of whether all 8 or 16 channels are used.
	-	See \ref audioformats for details on the format of the audio data in the buffer.

	@warning	It is easy to write video data into an audio buffer and vice-versa, which leads to noisy,
				garbled audio and/or bad video frame(s). SDK clients must take precautions to ensure that frame
				buffers used by your application never coincide with any of the audio buffers.


	<hr size="50px">
	@subsection	audiocapture		Audio Capture

	Incoming audio is de-embedded from incoming audio HANC packets (SMPTE 299M for HD, SMPTE 272M for SD).
	For HD, each audio sample consists of 24 bits of sample data (normally PCM).
	For SD, each audio sample consists of 20 bits of sample data (normally PCM) — audio extended packets are ignored.

	Call CNTV2Card::IsAudioInputRunning to determine if the capture side of the <b>Audio System</b> is running or not.
	Call CNTV2Card::StartAudioInput to start the capture side of the <b>Audio System</b> running.
	Call CNTV2Card::StopAudioInput to stop the capture side of the <b>Audio System</b> running.

	When the <b>Audio System</b> is running, each 24-bit sample is copied as-is into the most-significant 3 bytes of each 4-byte sample word
	in the <b>Audio Input Buffer</b> in device memory at the address specified by the <b>Audio System</b>’s Audio Input Last Address register (i.e.,
	the <b>Record Head</b> or “write head”). Call CNTV2Card::ReadAudioLastIn to obtain the current <b>Record Head</b> position. Audio data continues to
	be written into the <b>Input Buffer</b> until filled, whereupon the <b>Record Head</b> wraps back to the start of the buffer, where writing continues.
	The least-significant byte of each 32-bit sample word in the <b>Audio Input Buffer</b> is always set to zero. (Note that for SD, because
	extended packets are ignored, an extra 4-bit nibble in each 32-bit sample word will also be zero.)

	@image	html	hwref-fig3-audiorecordplay.png

	Audio data can be transferred from the <b>Audio Input Buffer</b> in device memory to a host audio buffer via DMA
	by calling CNTV2Card::DMAReadAudio.  While the offset to the Input portion of the device Audio Buffer is typically
	fixed at 4 MB, to be absolutely safe should this ever change, call CNTV2Card::GetAudioReadOffset to obtain the
	actual offset being used by the driver and SDK.

	If AutoCirculate is used for capture, AutoCirculate completely and automatically runs the <b>Audio System</b>.
	When CNTV2Card::AutoCirculateInitForInput is called with a valid ::NTV2AudioSystem, and then CNTV2Card::AutoCirculateStart is called,
	AutoCirculate starts the <b>Audio System</b>. CNTV2Card::AutoCirculateTransfer automatically transfers the correct number of captured
	audio samples from the device Audio System’s <b>Input Buffer</b> that are associated with the video frame being transferred.
	AUTOCIRCULATE_TRANSFER::GetCapturedAudioByteCount will return the exact number of transferred audio bytes for the frame that was just
	transferred to the host. See \ref autocirculatecapture for more information.

	If the Embedded Audio Group packet (containing two audio channel pairs) is not present in the data stream, its samples in the buffer
	will be set to zero (silence). The firmware notes which audio group packets are present and which are missing, and coalesces this
	information into a hardware register. Client software can query this information by calling CNTV2Card::GetDetectedAudioChannelPairs.

	Upstream equipment may indicate one or more audio channel pairs is not carrying PCM data (e.g., Dolby-E) via certain bits in the AES
	header in the audio stream. On newer AJA devices (see ::NTV2DeviceCanDoPCMDetection), the <b>Audio System</b>’s de-embedder makes this
	information available in a hardware register, and client software can query it by calling CNTV2Card::GetInputAudioChannelPairsWithoutPCM
	or CNTV2Card::InputAudioChannelPairHasPCM.

	@note	<b>Dolby AC-3</b>, for example, per SMPTE ST-337, is transported as non-PCM data in the SDI AES stream.
			The AC-3 data is located in the PCM audio sample words of a channel pair — see \ref audioformats .
			The formatting of the AC-3 data into the channel pairs is quite flexible, but usually a channel pair (e.g. 5&amp;6) is considered a single AC-3 stream.
			The specification allows AC-3 data to be carried in 16, 20 or 24 bits of the PCM sample.
			This flexibility requires the application to know how the source has formatted the data into the AES samples.

	Generally, each <b>Audio System</b>’s <b>Input Source</b> is selectable, to receive samples from any of the device’s video
	(and possibly audio) Input Sources, including embedded SDI, HDMI, external AES and analog inputs
	(see CNTV2Card::SetAudioSystemInputSource). For devices that support 3Gb Level B inputs, the audio can be taken from data
	stream 1 or 2. HDMI inputs can be configured to supply 2 or 8 audio channels (see CNTV2Card::GetHDMIInputAudioChannels ).

	Newer AJA hardware firmware implements an adjustable input delay that can be applied while samples are being written into the
	<b>Audio Input Buffer</b>. Call ::NTV2DeviceCanDoAudioDelay to determine if this feature is available. Call CNTV2Card::GetAudioInputDelay
	to obtain the current delay value. Call CNTV2Card::SetAudioInputDelay to change it.

	Audio input clocking for the running <b>Audio System</b> is ordinarily obtained from the input signal being used (SDI, HDMI, Analog, etc.).
	AJA’s older devices, however, derived the audio input clock from the Device Reference by default (see ::NTV2ReferenceSource) and had to be
	explicitly configured to use the input signal by passing ::NTV2_EMBEDDED_AUDIO_CLOCK_VIDEO_INPUT to CNTV2Card::SetEmbeddedAudioClock.
	If this wasn’t done, and the board reference was ::NTV2_REFERENCE_FREERUN or some other timebase that differed from the input video signal,
	the audio would eventually drift from the video. (See also ::NTV2DeviceCanChangeEmbeddedAudioClock.)


	<hr size="50px">
	@subsection	audioplayout		Audio Playout

	If the device supports SDI playout, each <b>Audio System</b> has an output embedder that generates audio packets (per SMPTE 299M for HD
	and SMPTE 272M for SD) and inserts them into the HANC area of the outgoing SDI data stream.
	-	Audio channels 1 & 2 are transmitted on Embedded Group 1, channels 1 & 2.
	-	Audio channels 3 & 4 are transmitted on Embedded Group 1, channels 3 & 4.
	-	Audio channels 5 & 6 are transmitted on Embedded Group 2, channels 1 & 2.
	-	Audio channels 7 & 8 are transmitted on Embedded Group 2, channels 3 & 4.
	-	In 16-channel mode (see CNTV2Card::GetNumberAudioChannels), the remaining 8 channels are distributed in Embedded Groups 3 and 4
	in a similar fashion.

	There is currently no provision for enabling or disabling specific audio groups.

	The SDI output embedder always inserts audio packets unless it’s been disabled (see CNTV2Card::SetAudioOutputEmbedderState).

	Call CNTV2Card::IsAudioOutputRunning to determine if the playout side of the <b>Audio System</b> is running or not.
	Call CNTV2Card::StartAudioOutput to start the playout side of the <b>Audio System</b> running.
	Call CNTV2Card::StopAudioOutput to stop the playout side of the <b>Audio System</b> running.

	When the <b>Audio System</b> is stopped, the output embedder will either embed silence (zeroes) into the data stream, or,
	if ::NTV2AudioLoopBack mode is enabled, it will embed audio samples obtained (through a FIFO) from its input de-embedder
	(see CNTV2Card::SetAudioLoopBack).

	When the <b>Audio System</b> is running, each 24-bit audio sample is copied from the most-significant 3 bytes of each 32-bit longword
	in the device audio buffer (the least-significant byte is ignored). Note, however, for SD, only the most-significant 20 bits are
	used (since the embedder does not create extended audio packets).

	During playout, the output embedder pulls audio samples from the <b>Audio Output Buffer</b> in device memory at the address specified by the
	<b>Audio System</b>’s <b>Audio Output Last Address</b> register (i.e., the <b>Play Head</b> or “read head”). Call CNTV2Card::ReadAudioLastOut to get the
	current <b>Play Head</b> position. Audio data continues to be read from the <b>Output Buffer</b> until the end is reached, whereupon the
	<b>Play Head</b> wraps back to the start of the buffer, where reading continues.

	<b>Startup Delay:</b> Ordinarily, when playout starts, the Audio System immediately starts pulling samples from the <b>Audio Output Buffer</b>,
	encoding them into audio packets and embedding those first several packets into the current outgoing video frame, often mid-frame, preceded by
	a number of packets containing silence. This makes it difficult for applications to precisely determine the location of frame breaks in the
	<b>Audio Output Buffer</b>. Starting in SDK 15.6, and using newer AJA hardware and firmware (see CNTV2Card::CanDoAudioWaitForVBI),
	CNTV2Card::StartAudioOutput has an optional “<i>waitForVBI</i>” parameter that if set <tt>True</tt>, causes the firmware to delay starting
	Audio Playout until the next output VBI, so that the first samples from the <b>Audio Output Buffer</b> end up in the first audio packets
	in the next outgoing video frame.

	<b>Output Delay:</b> Newer AJA hardware firmware implements an adjustable <b>Output Delay</b> that can be applied while samples are
	being read from the <b>Audio Output Buffer</b>. Call ::NTV2DeviceCanDoAudioDelay to determine if this feature is available.
	Call CNTV2Card::GetAudioOutputDelay to obtain the current delay value. Call CNTV2Card::SetAudioOutputDelay to change it.

	<b>Erase Mode:</b> The playout engine has an optional <b>Erase Mode</b>, in which it will automatically clear (zero) the
	<b>Output Buffer</b> memory immediately behind the <b>Play Head</b> as it runs. If the host application fails to transfer
	new samples into the <b>Audio Output Buffer</b>, the buffer will eventually contain all zeroes, and the output embedder
	will thereafter only transmit silence. Use the CNTV2Card::SetAudioOutputEraseMode function to configure this feature.

	<b>DMA Transfer:</b> Audio data can be transferred from the host to the device audio buffer via DMA by calling
	CNTV2Card::DMAWriteAudio. The last address written into the <b>Audio Output Buffer</b> (via DMA) is latched and
	available for readback at <b>Audio Output Last Address</b> (within 256 bytes). If the output hardware <b>Play Head</b>
	pointer catches up to the <b>Audio Output Last Address</b>, the buffer will wrap, and audio/video synchronization will be lost.

	If \ref autocirculateplayout is being used, AutoCirculate completely and automatically runs the <b>Audio System</b>.
	When CNTV2Card::AutoCirculateInitForOutput is called with a valid ::NTV2AudioSystem, and then CNTV2Card::AutoCirculateStart
	is called, AutoCirculate starts the <b>Audio System</b>. Youʼll need to transfer the correct number of audio samples via
	AUTOCIRCULATE_TRANSFER::SetAudioBuffer or AUTOCIRCULATE_TRANSFER::acAudioBuffer before calling CNTV2Card::AutoCirculateTransfer.
	See \ref audiosamplecount (below) on how to calculate the correct number of audio samples for the current outgoing frame.

	<b>SDI Output:</b> SDI output embedders can ordinarily be driven by any <b>Audio System</b>.
	-	Call CNTV2Card::GetSDIOutputAudioSystem to determine which Audio System is currently driving Data Stream 1.
	-	Call CNTV2Card::SetSDIOutputAudioSystem to change DS1’s Audio System.
	-	On devices that have 3G/6G/12G SDI connectors that support Dual Link output:
		-	Call CNTV2Card::GetSDIOutputDS2AudioSystem to determine the Audio System that’s currently driving Data Stream 2.
		-	Call CNTV2Card::SetSDIOutputDS2AudioSystem to change DS2’s Audio System.

	<b>HDMI Output:</b> The HDMI standard supports a minimum baseline of 2 audio channels up to a maximum of 8.
	If the NTV2 device has an HDMI output (see ::NTV2DeviceGetNumHDMIVideoOutputs ), it can be configured
	to transmit audio from any <b>Audio System</b>:
	-	To transmit 2 audio channels, call CNTV2Card::SetHDMIOutAudioSource2Channel :
		-	Specify the ::NTV2AudioSystem that will drive the HDMI outputʼs audio;
		-	Specify the ::NTV2AudioChannelPair that will determine which two of the
			Audio Systemʼs 8 (or 16) audio channels will be used.
	-	To transmit 8 audio channels, call CNTV2Card::SetHDMIOutAudioSource8Channel :
		-	Specify the ::NTV2AudioSystem that will drive the HDMI outputʼs audio;
		-	Specify the ::NTV2Audio8ChannelSelect that will determine which group of 8
			contiguous channels will be used from the Audio Systemʼs (presumably) 16 channels.

	<b>AES/EBU Output:</b> For devices that support AES/EBU output through a breakout box or cable (see ::NTV2DeviceCanDoBreakoutBox
	and ::NTV2DeviceGetNumAESAudioOutputChannels functions), the output BNCs will automatically carry the same per-audio-channel
	samples being played/embedded from <b>Audio Sytem 1</b> (::NTV2_AUDIOSYSTEM_1).  This can be changed to use a different
	set of 4 audio channels, even from a different <b>Audio System</b> (if available).
	-	Call CNTV2Card::GetAESOutputSource to determine the current ::NTV2AudioSystem and ::NTV2Audio4ChannelSelect
		(a contiguous band of 4 audio channels) being used for a given set of 4 AES audio channels.
	-	Call CNTV2Card::SetAESOutputSource to set the 4 audio channels and/or ::NTV2AudioSystem to be used for a given set
		of 4 AES audio channels.

	<b>Non-PCM Data:</b><br>

	Downstream equipment can be told that the outgoing audio is not carrying PCM data, by setting the non-PCM indicator in the AES header.
	Older AJA devices can only do this on an audio-system-wide basis — i.e., all outgoing audio groups are marked PCM or non-PCM.
	Use the simpler form of the CNTV2Card::SetAudioPCMControl function for these devices.

	Newer AJA devices can mark individual audio channel pairs as non-PCM (the ::NTV2DeviceCanDoPCMControl function returns true for
	devices that support this capability). Use one of the overloaded versions of CNTV2Card::SetAudioPCMControl that accepts either a
	single ::NTV2AudioChannelPair or an ::NTV2AudioChannelPairs set.

	<b>AES Sync-Mode Bit:</b><br>

	By default, the embedder clears the <b>Sync Mode bit</b> in the <b>AES header</b> in the <b>Audio Control Packet</b>s, which tells
	downstream equipment that the outgoing audio is <b>asynchronous</b>, even though overall, the correct total number of audio samples
	over a span of several frames always get transmitted. This is particularly relevant for 29.97/59.94 frame rates, in which the number
	of 48 kHz audio samples varies with each frame … yet is constant/fixed over a 5-frame sequence.

	If downstream equipment expects <b>synchronous</b> audio, and is alarming about the <b>asynchronous</b> audio, the output embedder
	can be told to set the <b>Sync Mode bit</b>, but note that this is “fibbing”:
	-	Call CNTV2Card::GetAudioOutputAESSyncModeBit to see if the device is setting the Sync Mode bit.
	-	Call CNTV2Card::SetAudioOutputAESSyncModeBit to change the setting.

	@note	When the embedder is configured to “fib” — i.e. set the <b>Sync Mode bit</b> in the <b>AES header</b> in the <b>Audio
			Control Packet</b> — audio and video are synchronized in time, but the resulting audio doesn’t exactly follow the
			definition of “synchronized” in SMPTE 299 § 7.2.1.3, because the embedder doesn’t set the <b>Frame Sequence Number</b>
			in the <b>AES header</b>. SMPTE 299, however, stipulates that receivers should correctly receive audio even from
			equipment that doesn’t fully conform to § 7.2.1.3.


	<hr size="50px">
	@subsection	audiosamplecount	Correlating Audio Samples to Video Frames

	Because AJA devices use fixed audio sample rates (i.e. 48000 samples per second), some video frame rates will necessarily result
	in some frames having more audio samples than others. For example, the NTSC frame rate is exactly 30000/1001 frames per second — so by
	converting frames to samples, the expected number of audio samples at any given frame time can be calculated. This is what
	the ::GetAudioSamplesPerFrame utility function is for:
	@code{.cpp}
		//	Print the audio sample count cadence for NTSC 2997...
		for (ULWord frame(0);  frame < 60;  )
		{
			std::cout << DEC(::GetAudioSamplesPerFrame(NTV2_FRAMERATE_2997, NTV2_AUDIO_48K, frame));
			if (++frame < 60)
				std::cout << ", ";
			if (!(frame % 5))
				std::cout << std::endl;
		}
	@endcode

	-	<b>Capture</b>
		-	<b>Without AutoCirculate</b> — the number of audio samples to associate with the current frame is provided by the
			hardware’s <b>Record Head</b>. Just compare its new position with its old position from the previous frame.
		-	<b>With AutoCirculate</b> — Use the AUTOCIRCULATE_TRANSFER::GetCapturedAudioByteCount function.
	-	<b>Playout</b>
		-	<b>With or Without AutoCirculate</b> — Use ::GetAudioSamplesPerFrame to calculate the number of audio samples to write for
			the current frame.


	<hr size="50px">
	@subsection	audiohidden		Other “Hidden” Audio Systems

	Modern AJA devices intended for “retail” markets, particularly newer “KONA” and “Io” series devices, may have firmware that
	implements additional “hidden” <b>Audio System</b>s that aren’t reported by the ::NTV2DeviceGetNumAudioSystems function:
	-	A <b>Host Audio System</b> for audio input/output to/from the host operating system (see ::NTV2DeviceGetHostAudioSystem);
	-	A “phantom” <b>Mixer Audio System</b> that uses only FIFOs (no audio buffer memory) in order to implement an \ref audiomixer
		(see CNTV2Card::DeviceCanDoAudioMixer and ::NTV2DeviceGetAudioMixerSystem).

	These additional <b>Audio System</b>s help support AJA’s “retail” software (i.e. Adobe, Avid, Apple, Telestream, etc.
	plug-ins, AJA ControlRoom, etc).

	The <b>Host Audio System</b> is used to continuously deliver…
	-	SDI/HDMI/AES audio from the AJA KONA/Io device as input to the host computer’s primary audio system.
		For example, this would enable an audio capture program running on the host (e.g. Audacity) to capture audio from an SDI input signal on the KONA/Io device.
	-	Host audio output from the host OS’s primary system audio to the KONA/Io device’s SDI/HDMI/AES output.
		For example, this would enable audio from a web browser running on the host computer to playout through a KONA/Io device’s SDI output.

	The <b>Host Audio System</b> is started and operated by the AJA kernel driver in conjunction with the host computer system’s audio control panel.
	It allows host audio to operate independently of other <b>Audio System</b>s on the device that may be used by AutoCirculate or other
	SDK client software.

	Since the <b>host audio system</b> uses audio buffer memory in device SDRAM, it’s susceptible to \ref audioclobber if an excessively
	large video buffer number is used by an active Frame Store.


	<hr size="50px">
	@subsection	audioclobber	Audio Buffer Corruption

	It’s possible (and quite easy) to configure a FrameStore to write video into audio buffer memory.
	For example:
	@code{.cpp}
		CNTV2Card device;
		if (CNTV2DeviceScanner::GetFirstDeviceFromArgument("0", device))
		{
			//	Assume this device has valid video signal at SDI Input 1
			device.ClearRouting();	//	Clear all existing connections
			device.EnableChannel(NTV2_CHANNEL1);	//	Enable FrameStore 1
			device.SetMode(NTV2_CHANNEL1, NTV2_MODE_CAPTURE);	//	Set FrameStore 1 to capture mode
			device.SetSDITransmitEnable(NTV2_CHANNEL1, false);	//	Set SDI connector 1 to capture
			device.Connect(NTV2_XptFrameBuffer1Input, NTV2_XptSDIIn1);	//	Connect SDI In 1 to FrameStore 1

			//	Which video frame is the first to contain audio system audio?
			//	You could just start incrementing frame numbers until you start getting bad audio.
			//	But here’s how to really do it...
			NTV2FrameGeometry		fg;
			NTV2FrameBufferFormat	fbf;
			device.GetFrameGeometry(fg, NTV2_CHANNEL1);
			device.GetFrameBufferFormat(NTV2_CHANNEL1, fbf);
			ULWord firstAudioFrameNum = ::NTV2DeviceGetNumberFrameBuffers(device.GetDeviceID(), fg, fbf);
			if (::NTV2DeviceCanDoStackedAudio(device.GetDeviceID()))
			{
				ULWord			chan1CtrlBits(0);
				mDevice.ReadRegister(kRegCh1Control, &chan1CtrlBits);
				ULWord			frameSizeMB (1 << (((chan1CtrlBits & kK2RegMaskFrameSize) >> 20) + 1));
				if (frameSizeMB < 8)
					frameSizeMB = 8;	//	No 2MB mode!
				const ULWord	maxRamBytes(::NTV2DeviceGetActiveMemorySize(device.GetDeviceID()));
				const ULWord	numAudioSystems(::NTV2DeviceGetNumAudioSystems(device.GetDeviceID()));
				const ULWord	totalAudioBytes(numAudioSystems * 8ULL*1024ULL*1024*ULL);	//	8MB per audio system
				firstAudioFrameNum = (maxRamBytes - totalAudioBytes) / frameSizeMB;
			}

			//	UH-OH:  This will cause video to be written into the audio buffers...
			device.SetInputFrame(NTV2_CHANNEL1, firstAudioFrameNum);	//	Write FrameStore 1 video into audio area
		}
	@endcode

	In the above example…
	-	On “stacked audio” devices, this will write video into the last <b>Audio System</b>’s buffer memory.
	-	On older “non-stacked audio” devices, this will write video into the first <b>Audio System</b>’s buffer memory.
	-	To notice the corruption, the affected <b>Audio System</b> will need to be running (playout and/or capture).
	-	It’s more likely to be noticed in audio playout, since the output audio buffer starts at the top of the frame.
	-	Small frame geometries and pixel formats (e.g., 8-bit YUV 525i) are less likely to touch the audio capture
		buffer that starts 4MB into the frame.

	It’s also possible (and quite easy) to configure a FrameStore to playout SDI/HDMI video that’s been corrupted by
	audio-in-the-video. This would happen if the FrameStore is set for playout and it’s using a frame buffer that’s
	also being used by a running <b>Audio System</b>.


	<hr size="50px">
	@subsection	audiomixer		Audio Mixer

	Some newer NTV2 devices have firmware that implements a three-multichannel-input <b>Audio Mixer</b>.
	-	To determine if a device supports this feature, call ::NTV2DeviceCanDoAudioMixer.
	-	To determine if the device actually has this feature in its running firmware, call CNTV2Card::DeviceCanDoAudioMixer.
	-	To determine the ::NTV2AudioSystem of the mixer, call ::NTV2DeviceGetAudioMixerSystem.

	The <b>Audio Mixer</b> firmware supports up to three two-channel (stereo) audio inputs:
	-	<b>Main</b> — can utilize any audio channel pair from any <b>Audio System</b>:
	-	<b>Auxiliary 1</b> — the first two audio channels from any <b>Audio System</b>:
	-	<b>Auxiliary 2</b> — the first two audio channels from any <b>Audio System</b>:
	-	To discover which <b>Audio System</b>’s output is feeding any given mixer input,
		call CNTV2Card::GetAudioMixerInputAudioSystem. To change it, call CNTV2Card::SetAudioMixerInputAudioSystem.
	-	To discover which audio channel pair is currently feeding any given mixer input,
		call CNTV2Card::GetAudioMixerInputChannelSelect. To change it, call CNTV2Card::SetAudioMixerInputChannelSelect.

	The resulting mixed audio is inserted onto the audio channel pair selected for the mix from the Main input,
	and the rest of that <b>Audio System</b>’s channel pairs are passed through to that same <b>Audio System</b>’s output
	(unless they’ve been muted).

	Any of the <b>Audio Mixer</b>’s inputs can be disabled (muted) or enabled (unmuted).
	-	Call CNTV2Card::GetAudioMixerInputChannelsMute to determine which audio channels of
		an <b>Audio Mixer</b>’s input are enabled or muted.
	-	Call CNTV2Card::SetAudioMixerInputChannelsMute to change them.

	Each <b>Audio Mixer</b> input has a gain control.
	-	Call CNTV2Card::GetAudioMixerInputGain to determine an input’s current gain setting.
	-	Call CNTV2Card::SetAudioMixerInputGain to change the setting.

	Each audio channel of the <b>Audio Mixer</b>’s output (up to 16 channels) can be individually muted.
	-	Call CNTV2Card::GetAudioMixerOutputChannelsMute to discover which mixer output audio channels are muted/disabled,
		and which are enabled/unmuted.
	-	Call CNTV2Card::SetAudioMixerOutputChannelsMute to mute or unmute the output audio channels.

	The <b>Audio Mixer</b>’s audio levels can be monitored:
	-	Call CNTV2Card::GetAudioMixerInputLevels to get the current levels of any specific audio channels of an input.
	-	The sample count the firmware uses for calculating audio levels is configurable:
		-	Call CNTV2Card::GetAudioMixerLevelsSampleCount to get the current sample count in use.
		-	Call CNTV2Card::SetAudioMixerLevelsSampleCount to change the setting.



	<hr size="50px">
	@section	devicefirmware		Firmware

	NTV2 devices have an EEPROM (non-volatile memory) that stores its FPGA programming.
	This flash memory is commonly divided into a minimum of two logical partitions:
	-	the “main” partition — for the normal FPGA bitfile image;
	-	the “failsafe” boot — for a fallback FPGA bitfile image.

	Traditionally, the FPGA is only loaded from flash memory upon power-up.
	The “failsafe” bitfile only loads if the board’s “failsafe” button is held down while power is applied to the board.

	Some AJA devices — like the \ref konaip — have, in addition to the normal FPGA hardware, a microprocessor, which requires
	an additional, separate firmware bitfile that bootstraps and operates it. This extra firmware is bundled into a “package” that is
	also stored in (and loaded from) a separate partition in the EEPROM.

	All NTV2 devices have two on-board LEDs that indicate readiness:
	-#	<b>Power</b> — If the board has power, this will indicate <b>Green</b>; otherwise it won’t be lit.
	-#	<b>FPGA Load State:</b>
		-	<b>Green</b> — Normal firmware bitfile loaded successfully.
		-	<b>Amber</b> — Fail-safe firmware bitfile loaded.
		-	<b>Red</b> — FPGA not programmed; firmware load failed.

	When operating normally, both LEDs will be <b>Green</b>.

	@note	On the Io and T-Tap products, the LEDs are hidden inside the chassis and can’t be seen.
 
	<hr size="50px">
	@subsection	dev-firmware-loading	Loading Firmware

	Loading the FPGA from EEPROM after power-up takes a finite amount of time.
	If this exceeds the amount of time allotted by the BIOS for PCIe devices to become ready, the AJA device
	won’t be detected by the BIOS, and thus won’t be probed by — or matched to — any device drivers.
	-	On Windows PCs, this is shown as an “<i>Unknown device</i>” in the Windows <b>Device Manager</b>.
	-	On Linux PCs, the ‘<b>lspci</b>’ command can help diagnose these issues.
		For example, here’s what ‘<b>lspci</b>’ should normally show when looking for devices with AJA’s PCIe vendor
		ID of \c 0xF1D0 (e.g. for a Corvid88):
		@code{.sh}
			$ lspci -d f1d0:
			03:00.0 Multimedia video controller: AJA Video Device eb0d
			$ lspci -n  -d f1d0:
			03:00.0 0400: f1d0:eb0d
			$ lspci -nn  -d f1d0:
			03:00.0 Multimedia video controller [0400]: AJA Video Device [f1d0:eb0d]
		@endcode

	<b>Disable Fast-Boot Option:</b><br />
	On PCs running Windows or Linux, be sure to disable all fast-boot options in the BIOS.

	<b>Disable Power-Saving Modes:</b><br />
	AJA’s NTV2 devices do not support PCIe power management.
	-	Be sure to disable any and all Energy-Saving features in the OS,
		particularly PCIe “Link State Power Management” (LSPM).
	-	<b>Windows</b> — This is in “Advanced Power Settings” ==≻ “Power Options” ==≻
		“PCI Express” ==≻ “Link State Power Management” ==≻ <b>Off</b>.
	-	<b>Linux</b> — Use the \c lspci command:
		@code{.sh}
			$ sudo lspci -vvv  -d f1d0:
		@endcode
		… and confirm that “LnkCtl: ASPM Disabled” is shown for each AJA device.
	-	On some motherboards, power management is controlled by the BIOS, in which case,
		try <b>disabling ASPM</b> under the BIOS’ <b>power options</b>.

	If, even after disabling “fast-boot”, the AJA device fails to show up, …
	-	Try “warm-booting” the PC. If the device is recognized after a warm-boot, then it’s likely a firmware load-time issue.
	-	Try installing the AJA board into a different PCIe slot on the motherboard. Some manufacturers employ chips that perform
		intermediate buffering on certain specific PCIe slots that can sometimes cause detection issues. Also beware that some
		manufacturers use a custom BIOS that has options for configuring PCIe slots, so be sure to check those BIOS settings
		and adjust them if needed.
	-	If the device still fails to show up, please <a href="https://sdksupport.aja.com/index.php?/Tickets/Submit">submit a Ticket</a>.

	<b>“Warm Boot” Reload</b><br />
	Some newer AJA devices are capable of reloading the FPGA upon a <b>PCIe Reset</b> — aka a “warm boot”.
	-	To test if the device can do a “warm boot” FPGA reload, call CNTV2Card::CanWarmBootFPGA.
	-	Note that AJA devices with Thunderbolt ports (e.g. \ref io4kplus ), or AJA boards installed on Thunderbolt PCIe
		card-cages receive a <b>PCIe Reset</b> when the Thunderbolt cable is unplugged and subsequently reconnected.


	<hr size="50px">
	@subsection	dev-firmware-flash		“Flashing” Firmware

	AJA provides two ways to “flash” — i.e. update — new firmware into the device’s EEPROM storage:
	-#	Using the <a href="https://sdksupport.aja.com/index.php?/Knowledgebase/Article/View/129">ntv2firmwareinstaller</a>
		command-line utility, described in \ref toolsandutilities.
	-#	Using the <b>AJA ControlPanel</b>, which is part of the “retail” software that can be downloaded from https://www.aja.com/.

	Once the new firmware has been written into the device EEPROM storage, it won’t “run” until the device FPGA gets reloaded
	(see \ref dev-firmware-loading above).


	<hr size="50px">
	@subsection	dev-firmware-vers		Determining Firmware Version

	@note	The <b>currently-running firmware</b> could be different from the <b>currently-installed firmware</b> that’s stored
			in the EEPROM’s main partition. This can happen if the device wasn’t power-cycled after a firmware update installation,
			or if the device was booted using its “failsafe” firmware.

	There are three ways to determine what firmware is installed, and/or which firmware is running on an AJA device:
	-	the <a href="https://sdksupport.aja.com/index.php?/Knowledgebase/Article/View/129">ntv2firmwareinstaller</a> command line
		utility, using its <b>--info</b> option;
	-	the “Info” or “Firmware” panels of the <b>AJA ControlPanel</b> application (in AJA’s “retail” software);
	-	programmatically using certain SDK API calls (described below).

	Newer AJA devices (starting with the \ref corvid88) report their <b>currently-running firmware date</b> in register 88,
	which is made available as numeric date components or a <tt>std::string</tt> by calling CNTV2Card::GetRunningFirmwareDate.

	Older AJA devices prior to the introduction of the \ref corvid88 have no way of reporting their <b>currently-running firmware date</b>
	— they can only report the running firmware’s <i>revision number</i> (which was stored in a portion of register 48 and made
	available by the CNTV2Card::GetRunningFirmwareRevision function. To correlate the revision number to a date, it must be looked
	up on the device’s firmware page on the
	<a href="https://sdksupport.aja.com/index.php?/Knowledgebase/List/Index/25/ntv2-firmware">AJA SDK support site’s KnowledgeBase</a>
	(not very convenient).

	-	To determine if a device is capable of reporting its <b>currently-running firmware date</b>, call ::NTV2DeviceCanReportRunningFirmwareDate.
	-	To determine the <b>currently-installed firmware</b> date, call CNTV2Card::GetInstalledBitfileInfo.
	-	To test if the fail-safe firmware is currently loaded, call CNTV2Card::IsFailSafeBitfileLoaded.


	<hr size="50px">
	@subsection	dev-firmware-features	Determining Firmware Features

	NTV2, being an old and rather crude architecture, has no automatically-enforced linkage between the firmware and the SDK —
	i.e. the SDK is neither generated from the firmware, nor is the firmware generated from the SDK.
	Thus, the SDK cannot simply “query the board” to find out how many of a particular widget a device’s running firmware implements,
	or if a new widget or feature is present (by simply reading registers).
	Unfortunately, this puts the burden of feature inquiry entirely into software, and onto the authors of NTV2 client applications.

	AJA will do its best to ensure that the “CanDo” functions are correct for the specific set of firmware bitfiles that have been
	qualified for a given SDK release. The release notes on the SDK download page will point out any firmware features added (or removed).


	<hr size="50px">
	@subsection	dev-bitfile-switching	Fast Bitfile Switching

	New 8K and 12-bit workflows have made it extremely difficult to simultaneously fit FrameStores, CSCs, LUTs, and Mixers into
	even the much larger modern FPGAs. This has made it necessary to enable the ability to rapidly switch between different
	workflow-based bitfiles.

	There’s a new API in the CNTV2Card class that adds support for this capability:
	-	To determine if the device supports fast dynamic loading of bitfiles, call CNTV2Card::IsDynamicDevice.
	-	To determine what device IDs are available for fast dynamic loading on the current device, call CNTV2Card::GetDynamicDeviceIDs.
	-	To determine if a particular ::NTV2DeviceID can be loaded on the current device, call CNTV2Card::CanLoadDynamicDevice.
	-	To quickly and dynamically load a specific ::NTV2DeviceID bitfile onto the current device, call CNTV2Card::LoadDynamicDevice.
	-	To add a specific bitfile to the cache of known bitfiles, call CNTV2Card::AddDynamicBitfile.
	-	To add multiple bitfiles inside a host file directory (folder) to the cache of known bitfiles, call CNTV2Card::AddDynamicDirectory.

	These new API calls make use of a new ::CNTV2BitfileManager singleton class that caches and manages the available bitfiles for
	various AJA devices. It can be used if finer control is needed over the basic functionality in CNTV2Card.
**/
